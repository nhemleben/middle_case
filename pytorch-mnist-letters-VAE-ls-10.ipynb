{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "batch_size = 10**3\n",
    "Z_dim = 10\n",
    "# Extended MNIST Dataset\n",
    "train_dataset = datasets.EMNIST(root='./emnist_data/', split= 'byclass', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.EMNIST(root='./emnist_data/', split= 'byclass', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=Z_dim)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()\n",
    "    model = vae.to('cuda')\n",
    "    print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (fc4): Linear(in_features=10, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/697932 (0%)]\tLoss: 545.294813\n",
      "Train Epoch: 0 [100000/697932 (14%)]\tLoss: 246.911891\n",
      "Train Epoch: 0 [200000/697932 (29%)]\tLoss: 209.786125\n",
      "Train Epoch: 0 [300000/697932 (43%)]\tLoss: 183.399391\n",
      "Train Epoch: 0 [400000/697932 (57%)]\tLoss: 176.643594\n",
      "Train Epoch: 0 [500000/697932 (72%)]\tLoss: 174.316750\n",
      "Train Epoch: 0 [600000/697932 (86%)]\tLoss: 166.943187\n",
      "====> Epoch: 0 Average loss: 200.2486\n",
      "====> Test set loss: 165.3917\n",
      "Train Epoch: 1 [0/697932 (0%)]\tLoss: 165.851828\n",
      "Train Epoch: 1 [100000/697932 (14%)]\tLoss: 165.746656\n",
      "Train Epoch: 1 [200000/697932 (29%)]\tLoss: 161.329875\n",
      "Train Epoch: 1 [300000/697932 (43%)]\tLoss: 160.009062\n",
      "Train Epoch: 1 [400000/697932 (57%)]\tLoss: 157.065812\n",
      "Train Epoch: 1 [500000/697932 (72%)]\tLoss: 160.393266\n",
      "Train Epoch: 1 [600000/697932 (86%)]\tLoss: 156.700437\n",
      "====> Epoch: 1 Average loss: 160.0402\n",
      "====> Test set loss: 156.7404\n",
      "Train Epoch: 2 [0/697932 (0%)]\tLoss: 153.672125\n",
      "Train Epoch: 2 [100000/697932 (14%)]\tLoss: 156.642469\n",
      "Train Epoch: 2 [200000/697932 (29%)]\tLoss: 156.513234\n",
      "Train Epoch: 2 [300000/697932 (43%)]\tLoss: 155.068172\n",
      "Train Epoch: 2 [400000/697932 (57%)]\tLoss: 152.409844\n",
      "Train Epoch: 2 [500000/697932 (72%)]\tLoss: 155.090516\n",
      "Train Epoch: 2 [600000/697932 (86%)]\tLoss: 153.856406\n",
      "====> Epoch: 2 Average loss: 154.6109\n",
      "====> Test set loss: 153.0518\n",
      "Train Epoch: 3 [0/697932 (0%)]\tLoss: 151.385156\n",
      "Train Epoch: 3 [100000/697932 (14%)]\tLoss: 151.803094\n",
      "Train Epoch: 3 [200000/697932 (29%)]\tLoss: 152.716344\n",
      "Train Epoch: 3 [300000/697932 (43%)]\tLoss: 151.514984\n",
      "Train Epoch: 3 [400000/697932 (57%)]\tLoss: 152.613000\n",
      "Train Epoch: 3 [500000/697932 (72%)]\tLoss: 153.398000\n",
      "Train Epoch: 3 [600000/697932 (86%)]\tLoss: 151.278141\n",
      "====> Epoch: 3 Average loss: 151.8122\n",
      "====> Test set loss: 150.9172\n",
      "Train Epoch: 4 [0/697932 (0%)]\tLoss: 150.977781\n",
      "Train Epoch: 4 [100000/697932 (14%)]\tLoss: 148.813406\n",
      "Train Epoch: 4 [200000/697932 (29%)]\tLoss: 149.311109\n",
      "Train Epoch: 4 [300000/697932 (43%)]\tLoss: 151.715531\n",
      "Train Epoch: 4 [400000/697932 (57%)]\tLoss: 151.536063\n",
      "Train Epoch: 4 [500000/697932 (72%)]\tLoss: 148.195500\n",
      "Train Epoch: 4 [600000/697932 (86%)]\tLoss: 147.985578\n",
      "====> Epoch: 4 Average loss: 150.0122\n",
      "====> Test set loss: 149.4431\n",
      "Train Epoch: 5 [0/697932 (0%)]\tLoss: 148.954219\n",
      "Train Epoch: 5 [100000/697932 (14%)]\tLoss: 150.690703\n",
      "Train Epoch: 5 [200000/697932 (29%)]\tLoss: 148.289187\n",
      "Train Epoch: 5 [300000/697932 (43%)]\tLoss: 149.197250\n",
      "Train Epoch: 5 [400000/697932 (57%)]\tLoss: 148.581234\n",
      "Train Epoch: 5 [500000/697932 (72%)]\tLoss: 149.369531\n",
      "Train Epoch: 5 [600000/697932 (86%)]\tLoss: 148.687813\n",
      "====> Epoch: 5 Average loss: 148.7149\n",
      "====> Test set loss: 148.3459\n",
      "Train Epoch: 6 [0/697932 (0%)]\tLoss: 147.714812\n",
      "Train Epoch: 6 [100000/697932 (14%)]\tLoss: 146.871906\n",
      "Train Epoch: 6 [200000/697932 (29%)]\tLoss: 148.858656\n",
      "Train Epoch: 6 [300000/697932 (43%)]\tLoss: 146.702969\n",
      "Train Epoch: 6 [400000/697932 (57%)]\tLoss: 147.477297\n",
      "Train Epoch: 6 [500000/697932 (72%)]\tLoss: 147.131375\n",
      "Train Epoch: 6 [600000/697932 (86%)]\tLoss: 147.994656\n",
      "====> Epoch: 6 Average loss: 147.7207\n",
      "====> Test set loss: 147.3706\n",
      "Train Epoch: 7 [0/697932 (0%)]\tLoss: 145.411859\n",
      "Train Epoch: 7 [100000/697932 (14%)]\tLoss: 144.725453\n",
      "Train Epoch: 7 [200000/697932 (29%)]\tLoss: 146.007719\n",
      "Train Epoch: 7 [300000/697932 (43%)]\tLoss: 146.696719\n",
      "Train Epoch: 7 [400000/697932 (57%)]\tLoss: 145.812813\n",
      "Train Epoch: 7 [500000/697932 (72%)]\tLoss: 146.495688\n",
      "Train Epoch: 7 [600000/697932 (86%)]\tLoss: 147.081719\n",
      "====> Epoch: 7 Average loss: 146.9177\n",
      "====> Test set loss: 146.7488\n",
      "Train Epoch: 8 [0/697932 (0%)]\tLoss: 144.169750\n",
      "Train Epoch: 8 [100000/697932 (14%)]\tLoss: 148.403609\n",
      "Train Epoch: 8 [200000/697932 (29%)]\tLoss: 146.779578\n",
      "Train Epoch: 8 [300000/697932 (43%)]\tLoss: 146.225313\n",
      "Train Epoch: 8 [400000/697932 (57%)]\tLoss: 145.470906\n",
      "Train Epoch: 8 [500000/697932 (72%)]\tLoss: 147.759766\n",
      "Train Epoch: 8 [600000/697932 (86%)]\tLoss: 147.685234\n",
      "====> Epoch: 8 Average loss: 146.3032\n",
      "====> Test set loss: 146.2796\n",
      "Train Epoch: 9 [0/697932 (0%)]\tLoss: 145.903344\n",
      "Train Epoch: 9 [100000/697932 (14%)]\tLoss: 144.914016\n",
      "Train Epoch: 9 [200000/697932 (29%)]\tLoss: 145.705656\n",
      "Train Epoch: 9 [300000/697932 (43%)]\tLoss: 145.251234\n",
      "Train Epoch: 9 [400000/697932 (57%)]\tLoss: 144.916656\n",
      "Train Epoch: 9 [500000/697932 (72%)]\tLoss: 142.761422\n",
      "Train Epoch: 9 [600000/697932 (86%)]\tLoss: 144.937187\n",
      "====> Epoch: 9 Average loss: 145.7610\n",
      "====> Test set loss: 145.8456\n",
      "Train Epoch: 10 [0/697932 (0%)]\tLoss: 145.219359\n",
      "Train Epoch: 10 [100000/697932 (14%)]\tLoss: 144.182344\n",
      "Train Epoch: 10 [200000/697932 (29%)]\tLoss: 147.733719\n",
      "Train Epoch: 10 [300000/697932 (43%)]\tLoss: 145.451547\n",
      "Train Epoch: 10 [400000/697932 (57%)]\tLoss: 145.897250\n",
      "Train Epoch: 10 [500000/697932 (72%)]\tLoss: 144.540391\n",
      "Train Epoch: 10 [600000/697932 (86%)]\tLoss: 145.854312\n",
      "====> Epoch: 10 Average loss: 145.2909\n",
      "====> Test set loss: 145.3496\n",
      "Train Epoch: 11 [0/697932 (0%)]\tLoss: 145.619344\n",
      "Train Epoch: 11 [100000/697932 (14%)]\tLoss: 146.081000\n",
      "Train Epoch: 11 [200000/697932 (29%)]\tLoss: 144.719625\n",
      "Train Epoch: 11 [300000/697932 (43%)]\tLoss: 144.847047\n",
      "Train Epoch: 11 [400000/697932 (57%)]\tLoss: 146.764641\n",
      "Train Epoch: 11 [500000/697932 (72%)]\tLoss: 145.947109\n",
      "Train Epoch: 11 [600000/697932 (86%)]\tLoss: 146.217297\n",
      "====> Epoch: 11 Average loss: 144.9045\n",
      "====> Test set loss: 145.0120\n",
      "Train Epoch: 12 [0/697932 (0%)]\tLoss: 145.693641\n",
      "Train Epoch: 12 [100000/697932 (14%)]\tLoss: 145.076156\n",
      "Train Epoch: 12 [200000/697932 (29%)]\tLoss: 145.089797\n",
      "Train Epoch: 12 [300000/697932 (43%)]\tLoss: 146.227703\n",
      "Train Epoch: 12 [400000/697932 (57%)]\tLoss: 144.302469\n",
      "Train Epoch: 12 [500000/697932 (72%)]\tLoss: 145.436844\n",
      "Train Epoch: 12 [600000/697932 (86%)]\tLoss: 141.739766\n",
      "====> Epoch: 12 Average loss: 144.5860\n",
      "====> Test set loss: 144.7203\n",
      "Train Epoch: 13 [0/697932 (0%)]\tLoss: 143.231703\n",
      "Train Epoch: 13 [100000/697932 (14%)]\tLoss: 145.549234\n",
      "Train Epoch: 13 [200000/697932 (29%)]\tLoss: 143.021750\n",
      "Train Epoch: 13 [300000/697932 (43%)]\tLoss: 144.274438\n",
      "Train Epoch: 13 [400000/697932 (57%)]\tLoss: 142.507859\n",
      "Train Epoch: 13 [500000/697932 (72%)]\tLoss: 143.595016\n",
      "Train Epoch: 13 [600000/697932 (86%)]\tLoss: 143.392625\n",
      "====> Epoch: 13 Average loss: 144.2753\n",
      "====> Test set loss: 144.3749\n",
      "Train Epoch: 14 [0/697932 (0%)]\tLoss: 142.109500\n",
      "Train Epoch: 14 [100000/697932 (14%)]\tLoss: 144.453703\n",
      "Train Epoch: 14 [200000/697932 (29%)]\tLoss: 142.513734\n",
      "Train Epoch: 14 [300000/697932 (43%)]\tLoss: 143.587547\n",
      "Train Epoch: 14 [400000/697932 (57%)]\tLoss: 146.325063\n",
      "Train Epoch: 14 [500000/697932 (72%)]\tLoss: 145.516344\n",
      "Train Epoch: 14 [600000/697932 (86%)]\tLoss: 143.399766\n",
      "====> Epoch: 14 Average loss: 144.0303\n",
      "====> Test set loss: 144.3283\n",
      "Train Epoch: 15 [0/697932 (0%)]\tLoss: 143.216125\n",
      "Train Epoch: 15 [100000/697932 (14%)]\tLoss: 142.690547\n",
      "Train Epoch: 15 [200000/697932 (29%)]\tLoss: 144.232297\n",
      "Train Epoch: 15 [300000/697932 (43%)]\tLoss: 143.450750\n",
      "Train Epoch: 15 [400000/697932 (57%)]\tLoss: 142.443984\n",
      "Train Epoch: 15 [500000/697932 (72%)]\tLoss: 144.387656\n",
      "Train Epoch: 15 [600000/697932 (86%)]\tLoss: 143.941219\n",
      "====> Epoch: 15 Average loss: 143.7882\n",
      "====> Test set loss: 144.0254\n",
      "Train Epoch: 16 [0/697932 (0%)]\tLoss: 143.605687\n",
      "Train Epoch: 16 [100000/697932 (14%)]\tLoss: 144.315937\n",
      "Train Epoch: 16 [200000/697932 (29%)]\tLoss: 143.580813\n",
      "Train Epoch: 16 [300000/697932 (43%)]\tLoss: 143.342031\n",
      "Train Epoch: 16 [400000/697932 (57%)]\tLoss: 145.448609\n",
      "Train Epoch: 16 [500000/697932 (72%)]\tLoss: 145.049953\n",
      "Train Epoch: 16 [600000/697932 (86%)]\tLoss: 142.827953\n",
      "====> Epoch: 16 Average loss: 143.5608\n",
      "====> Test set loss: 143.8374\n",
      "Train Epoch: 17 [0/697932 (0%)]\tLoss: 143.237891\n",
      "Train Epoch: 17 [100000/697932 (14%)]\tLoss: 143.654422\n",
      "Train Epoch: 17 [200000/697932 (29%)]\tLoss: 141.909766\n",
      "Train Epoch: 17 [300000/697932 (43%)]\tLoss: 143.367031\n",
      "Train Epoch: 17 [400000/697932 (57%)]\tLoss: 143.900922\n",
      "Train Epoch: 17 [500000/697932 (72%)]\tLoss: 142.459625\n",
      "Train Epoch: 17 [600000/697932 (86%)]\tLoss: 144.434687\n",
      "====> Epoch: 17 Average loss: 143.3667\n",
      "====> Test set loss: 143.6595\n",
      "Train Epoch: 18 [0/697932 (0%)]\tLoss: 144.226375\n",
      "Train Epoch: 18 [100000/697932 (14%)]\tLoss: 142.508594\n",
      "Train Epoch: 18 [200000/697932 (29%)]\tLoss: 143.132031\n",
      "Train Epoch: 18 [300000/697932 (43%)]\tLoss: 142.881094\n",
      "Train Epoch: 18 [400000/697932 (57%)]\tLoss: 143.702594\n",
      "Train Epoch: 18 [500000/697932 (72%)]\tLoss: 142.461312\n",
      "Train Epoch: 18 [600000/697932 (86%)]\tLoss: 141.740875\n",
      "====> Epoch: 18 Average loss: 143.2029\n",
      "====> Test set loss: 143.4499\n",
      "Train Epoch: 19 [0/697932 (0%)]\tLoss: 143.865391\n",
      "Train Epoch: 19 [100000/697932 (14%)]\tLoss: 142.570328\n",
      "Train Epoch: 19 [200000/697932 (29%)]\tLoss: 143.815750\n",
      "Train Epoch: 19 [300000/697932 (43%)]\tLoss: 144.575250\n",
      "Train Epoch: 19 [400000/697932 (57%)]\tLoss: 143.360875\n",
      "Train Epoch: 19 [500000/697932 (72%)]\tLoss: 139.886172\n",
      "Train Epoch: 19 [600000/697932 (86%)]\tLoss: 142.593969\n",
      "====> Epoch: 19 Average loss: 143.0195\n",
      "====> Test set loss: 143.3961\n",
      "Train Epoch: 20 [0/697932 (0%)]\tLoss: 142.853781\n",
      "Train Epoch: 20 [100000/697932 (14%)]\tLoss: 142.496344\n",
      "Train Epoch: 20 [200000/697932 (29%)]\tLoss: 142.868625\n",
      "Train Epoch: 20 [300000/697932 (43%)]\tLoss: 142.266516\n",
      "Train Epoch: 20 [400000/697932 (57%)]\tLoss: 142.166016\n",
      "Train Epoch: 20 [500000/697932 (72%)]\tLoss: 141.809031\n",
      "Train Epoch: 20 [600000/697932 (86%)]\tLoss: 144.156000\n",
      "====> Epoch: 20 Average loss: 142.8675\n",
      "====> Test set loss: 143.1773\n",
      "Train Epoch: 21 [0/697932 (0%)]\tLoss: 140.992375\n",
      "Train Epoch: 21 [100000/697932 (14%)]\tLoss: 142.140578\n",
      "Train Epoch: 21 [200000/697932 (29%)]\tLoss: 140.686781\n",
      "Train Epoch: 21 [300000/697932 (43%)]\tLoss: 142.365125\n",
      "Train Epoch: 21 [400000/697932 (57%)]\tLoss: 141.948844\n",
      "Train Epoch: 21 [500000/697932 (72%)]\tLoss: 142.211219\n",
      "Train Epoch: 21 [600000/697932 (86%)]\tLoss: 142.854125\n",
      "====> Epoch: 21 Average loss: 142.7059\n",
      "====> Test set loss: 143.2928\n",
      "Train Epoch: 22 [0/697932 (0%)]\tLoss: 144.164047\n",
      "Train Epoch: 22 [100000/697932 (14%)]\tLoss: 141.481375\n",
      "Train Epoch: 22 [200000/697932 (29%)]\tLoss: 142.350766\n",
      "Train Epoch: 22 [300000/697932 (43%)]\tLoss: 142.371406\n",
      "Train Epoch: 22 [400000/697932 (57%)]\tLoss: 142.870125\n",
      "Train Epoch: 22 [500000/697932 (72%)]\tLoss: 143.364328\n",
      "Train Epoch: 22 [600000/697932 (86%)]\tLoss: 143.508266\n",
      "====> Epoch: 22 Average loss: 142.5884\n",
      "====> Test set loss: 142.9936\n",
      "Train Epoch: 23 [0/697932 (0%)]\tLoss: 141.252156\n",
      "Train Epoch: 23 [100000/697932 (14%)]\tLoss: 143.060906\n",
      "Train Epoch: 23 [200000/697932 (29%)]\tLoss: 141.433703\n",
      "Train Epoch: 23 [300000/697932 (43%)]\tLoss: 144.062750\n",
      "Train Epoch: 23 [400000/697932 (57%)]\tLoss: 143.338812\n",
      "Train Epoch: 23 [500000/697932 (72%)]\tLoss: 145.031875\n",
      "Train Epoch: 23 [600000/697932 (86%)]\tLoss: 143.093625\n",
      "====> Epoch: 23 Average loss: 142.4662\n",
      "====> Test set loss: 142.8630\n",
      "Train Epoch: 24 [0/697932 (0%)]\tLoss: 142.919125\n",
      "Train Epoch: 24 [100000/697932 (14%)]\tLoss: 142.757000\n",
      "Train Epoch: 24 [200000/697932 (29%)]\tLoss: 141.985469\n",
      "Train Epoch: 24 [300000/697932 (43%)]\tLoss: 142.971313\n",
      "Train Epoch: 24 [400000/697932 (57%)]\tLoss: 140.746875\n",
      "Train Epoch: 24 [500000/697932 (72%)]\tLoss: 144.287297\n",
      "Train Epoch: 24 [600000/697932 (86%)]\tLoss: 139.310016\n",
      "====> Epoch: 24 Average loss: 142.3262\n",
      "====> Test set loss: 142.7130\n",
      "Train Epoch: 25 [0/697932 (0%)]\tLoss: 141.504328\n",
      "Train Epoch: 25 [100000/697932 (14%)]\tLoss: 140.583313\n",
      "Train Epoch: 25 [200000/697932 (29%)]\tLoss: 142.147359\n",
      "Train Epoch: 25 [300000/697932 (43%)]\tLoss: 141.932016\n",
      "Train Epoch: 25 [400000/697932 (57%)]\tLoss: 141.813063\n",
      "Train Epoch: 25 [500000/697932 (72%)]\tLoss: 142.690297\n",
      "Train Epoch: 25 [600000/697932 (86%)]\tLoss: 142.173937\n",
      "====> Epoch: 25 Average loss: 142.2347\n",
      "====> Test set loss: 142.5074\n",
      "Train Epoch: 26 [0/697932 (0%)]\tLoss: 140.605063\n",
      "Train Epoch: 26 [100000/697932 (14%)]\tLoss: 141.604437\n",
      "Train Epoch: 26 [200000/697932 (29%)]\tLoss: 140.220812\n",
      "Train Epoch: 26 [300000/697932 (43%)]\tLoss: 141.488063\n",
      "Train Epoch: 26 [400000/697932 (57%)]\tLoss: 144.467359\n",
      "Train Epoch: 26 [500000/697932 (72%)]\tLoss: 144.149734\n",
      "Train Epoch: 26 [600000/697932 (86%)]\tLoss: 144.487281\n",
      "====> Epoch: 26 Average loss: 142.1173\n",
      "====> Test set loss: 142.5792\n",
      "Train Epoch: 27 [0/697932 (0%)]\tLoss: 144.032469\n",
      "Train Epoch: 27 [100000/697932 (14%)]\tLoss: 144.708469\n",
      "Train Epoch: 27 [200000/697932 (29%)]\tLoss: 141.305344\n",
      "Train Epoch: 27 [300000/697932 (43%)]\tLoss: 143.307078\n",
      "Train Epoch: 27 [400000/697932 (57%)]\tLoss: 142.768922\n",
      "Train Epoch: 27 [500000/697932 (72%)]\tLoss: 143.742656\n",
      "Train Epoch: 27 [600000/697932 (86%)]\tLoss: 143.188500\n",
      "====> Epoch: 27 Average loss: 142.0277\n",
      "====> Test set loss: 142.4218\n",
      "Train Epoch: 28 [0/697932 (0%)]\tLoss: 141.888266\n",
      "Train Epoch: 28 [100000/697932 (14%)]\tLoss: 141.848781\n",
      "Train Epoch: 28 [200000/697932 (29%)]\tLoss: 141.908062\n",
      "Train Epoch: 28 [300000/697932 (43%)]\tLoss: 142.730297\n",
      "Train Epoch: 28 [400000/697932 (57%)]\tLoss: 142.318906\n",
      "Train Epoch: 28 [500000/697932 (72%)]\tLoss: 143.263344\n",
      "Train Epoch: 28 [600000/697932 (86%)]\tLoss: 141.391797\n",
      "====> Epoch: 28 Average loss: 141.9316\n",
      "====> Test set loss: 142.5305\n",
      "Train Epoch: 29 [0/697932 (0%)]\tLoss: 141.570953\n",
      "Train Epoch: 29 [100000/697932 (14%)]\tLoss: 142.210406\n",
      "Train Epoch: 29 [200000/697932 (29%)]\tLoss: 141.768219\n",
      "Train Epoch: 29 [300000/697932 (43%)]\tLoss: 141.013781\n",
      "Train Epoch: 29 [400000/697932 (57%)]\tLoss: 142.242281\n",
      "Train Epoch: 29 [500000/697932 (72%)]\tLoss: 142.081187\n",
      "Train Epoch: 29 [600000/697932 (86%)]\tLoss: 141.318625\n",
      "====> Epoch: 29 Average loss: 141.8311\n",
      "====> Test set loss: 142.2411\n",
      "Train Epoch: 30 [0/697932 (0%)]\tLoss: 141.282094\n",
      "Train Epoch: 30 [100000/697932 (14%)]\tLoss: 141.047531\n",
      "Train Epoch: 30 [200000/697932 (29%)]\tLoss: 142.920516\n",
      "Train Epoch: 30 [300000/697932 (43%)]\tLoss: 140.883703\n",
      "Train Epoch: 30 [400000/697932 (57%)]\tLoss: 141.386516\n",
      "Train Epoch: 30 [500000/697932 (72%)]\tLoss: 139.775688\n",
      "Train Epoch: 30 [600000/697932 (86%)]\tLoss: 141.252219\n",
      "====> Epoch: 30 Average loss: 141.7605\n",
      "====> Test set loss: 142.2990\n",
      "Train Epoch: 31 [0/697932 (0%)]\tLoss: 142.529391\n",
      "Train Epoch: 31 [100000/697932 (14%)]\tLoss: 143.166875\n",
      "Train Epoch: 31 [200000/697932 (29%)]\tLoss: 142.435703\n",
      "Train Epoch: 31 [300000/697932 (43%)]\tLoss: 142.082000\n",
      "Train Epoch: 31 [400000/697932 (57%)]\tLoss: 141.069609\n",
      "Train Epoch: 31 [500000/697932 (72%)]\tLoss: 143.010281\n",
      "Train Epoch: 31 [600000/697932 (86%)]\tLoss: 141.027531\n",
      "====> Epoch: 31 Average loss: 141.6630\n",
      "====> Test set loss: 142.0476\n",
      "Train Epoch: 32 [0/697932 (0%)]\tLoss: 141.056656\n",
      "Train Epoch: 32 [100000/697932 (14%)]\tLoss: 139.640969\n",
      "Train Epoch: 32 [200000/697932 (29%)]\tLoss: 142.255906\n",
      "Train Epoch: 32 [300000/697932 (43%)]\tLoss: 142.324469\n",
      "Train Epoch: 32 [400000/697932 (57%)]\tLoss: 141.723594\n",
      "Train Epoch: 32 [500000/697932 (72%)]\tLoss: 141.373813\n",
      "Train Epoch: 32 [600000/697932 (86%)]\tLoss: 141.731219\n",
      "====> Epoch: 32 Average loss: 141.5816\n",
      "====> Test set loss: 142.0531\n",
      "Train Epoch: 33 [0/697932 (0%)]\tLoss: 140.605109\n",
      "Train Epoch: 33 [100000/697932 (14%)]\tLoss: 142.785063\n",
      "Train Epoch: 33 [200000/697932 (29%)]\tLoss: 140.522453\n",
      "Train Epoch: 33 [300000/697932 (43%)]\tLoss: 140.430438\n",
      "Train Epoch: 33 [400000/697932 (57%)]\tLoss: 141.633156\n",
      "Train Epoch: 33 [500000/697932 (72%)]\tLoss: 141.847281\n",
      "Train Epoch: 33 [600000/697932 (86%)]\tLoss: 142.025703\n",
      "====> Epoch: 33 Average loss: 141.5375\n",
      "====> Test set loss: 142.0184\n",
      "Train Epoch: 34 [0/697932 (0%)]\tLoss: 141.661812\n",
      "Train Epoch: 34 [100000/697932 (14%)]\tLoss: 141.843953\n",
      "Train Epoch: 34 [200000/697932 (29%)]\tLoss: 140.604781\n",
      "Train Epoch: 34 [300000/697932 (43%)]\tLoss: 143.568734\n",
      "Train Epoch: 34 [400000/697932 (57%)]\tLoss: 141.433844\n",
      "Train Epoch: 34 [500000/697932 (72%)]\tLoss: 140.619812\n",
      "Train Epoch: 34 [600000/697932 (86%)]\tLoss: 140.470047\n",
      "====> Epoch: 34 Average loss: 141.4526\n",
      "====> Test set loss: 141.9386\n",
      "Train Epoch: 35 [0/697932 (0%)]\tLoss: 140.679578\n",
      "Train Epoch: 35 [100000/697932 (14%)]\tLoss: 141.582859\n",
      "Train Epoch: 35 [200000/697932 (29%)]\tLoss: 141.536188\n",
      "Train Epoch: 35 [300000/697932 (43%)]\tLoss: 141.583703\n",
      "Train Epoch: 35 [400000/697932 (57%)]\tLoss: 141.381937\n",
      "Train Epoch: 35 [500000/697932 (72%)]\tLoss: 139.647406\n",
      "Train Epoch: 35 [600000/697932 (86%)]\tLoss: 141.878609\n",
      "====> Epoch: 35 Average loss: 141.3805\n",
      "====> Test set loss: 141.9558\n",
      "Train Epoch: 36 [0/697932 (0%)]\tLoss: 143.916281\n",
      "Train Epoch: 36 [100000/697932 (14%)]\tLoss: 140.535516\n",
      "Train Epoch: 36 [200000/697932 (29%)]\tLoss: 140.639656\n",
      "Train Epoch: 36 [300000/697932 (43%)]\tLoss: 142.826687\n",
      "Train Epoch: 36 [400000/697932 (57%)]\tLoss: 141.528094\n",
      "Train Epoch: 36 [500000/697932 (72%)]\tLoss: 139.779266\n",
      "Train Epoch: 36 [600000/697932 (86%)]\tLoss: 138.991859\n",
      "====> Epoch: 36 Average loss: 141.3133\n",
      "====> Test set loss: 141.9014\n",
      "Train Epoch: 37 [0/697932 (0%)]\tLoss: 139.782844\n",
      "Train Epoch: 37 [100000/697932 (14%)]\tLoss: 140.710797\n",
      "Train Epoch: 37 [200000/697932 (29%)]\tLoss: 140.688375\n",
      "Train Epoch: 37 [300000/697932 (43%)]\tLoss: 141.178031\n",
      "Train Epoch: 37 [400000/697932 (57%)]\tLoss: 143.675844\n",
      "Train Epoch: 37 [500000/697932 (72%)]\tLoss: 140.337672\n",
      "Train Epoch: 37 [600000/697932 (86%)]\tLoss: 139.982656\n",
      "====> Epoch: 37 Average loss: 141.2665\n",
      "====> Test set loss: 141.6899\n",
      "Train Epoch: 38 [0/697932 (0%)]\tLoss: 140.567109\n",
      "Train Epoch: 38 [100000/697932 (14%)]\tLoss: 141.743984\n",
      "Train Epoch: 38 [200000/697932 (29%)]\tLoss: 140.702797\n",
      "Train Epoch: 38 [300000/697932 (43%)]\tLoss: 142.340000\n",
      "Train Epoch: 38 [400000/697932 (57%)]\tLoss: 139.049187\n",
      "Train Epoch: 38 [500000/697932 (72%)]\tLoss: 141.708297\n",
      "Train Epoch: 38 [600000/697932 (86%)]\tLoss: 141.700844\n",
      "====> Epoch: 38 Average loss: 141.1906\n",
      "====> Test set loss: 141.6723\n",
      "Train Epoch: 39 [0/697932 (0%)]\tLoss: 140.307594\n",
      "Train Epoch: 39 [100000/697932 (14%)]\tLoss: 141.452219\n",
      "Train Epoch: 39 [200000/697932 (29%)]\tLoss: 142.145641\n",
      "Train Epoch: 39 [300000/697932 (43%)]\tLoss: 139.190281\n",
      "Train Epoch: 39 [400000/697932 (57%)]\tLoss: 141.265891\n",
      "Train Epoch: 39 [500000/697932 (72%)]\tLoss: 140.536500\n",
      "Train Epoch: 39 [600000/697932 (86%)]\tLoss: 141.859531\n",
      "====> Epoch: 39 Average loss: 141.1607\n",
      "====> Test set loss: 141.5851\n",
      "Train Epoch: 40 [0/697932 (0%)]\tLoss: 141.135266\n",
      "Train Epoch: 40 [100000/697932 (14%)]\tLoss: 140.253719\n",
      "Train Epoch: 40 [200000/697932 (29%)]\tLoss: 142.244563\n",
      "Train Epoch: 40 [300000/697932 (43%)]\tLoss: 142.483313\n",
      "Train Epoch: 40 [400000/697932 (57%)]\tLoss: 140.219469\n",
      "Train Epoch: 40 [500000/697932 (72%)]\tLoss: 140.911828\n",
      "Train Epoch: 40 [600000/697932 (86%)]\tLoss: 141.292391\n",
      "====> Epoch: 40 Average loss: 141.0824\n",
      "====> Test set loss: 141.6517\n",
      "Train Epoch: 41 [0/697932 (0%)]\tLoss: 140.562156\n",
      "Train Epoch: 41 [100000/697932 (14%)]\tLoss: 140.546219\n",
      "Train Epoch: 41 [200000/697932 (29%)]\tLoss: 141.530672\n",
      "Train Epoch: 41 [300000/697932 (43%)]\tLoss: 139.805828\n",
      "Train Epoch: 41 [400000/697932 (57%)]\tLoss: 140.689672\n",
      "Train Epoch: 41 [500000/697932 (72%)]\tLoss: 142.340859\n",
      "Train Epoch: 41 [600000/697932 (86%)]\tLoss: 143.253312\n",
      "====> Epoch: 41 Average loss: 141.0360\n",
      "====> Test set loss: 141.5791\n",
      "Train Epoch: 42 [0/697932 (0%)]\tLoss: 140.563219\n",
      "Train Epoch: 42 [100000/697932 (14%)]\tLoss: 140.836359\n",
      "Train Epoch: 42 [200000/697932 (29%)]\tLoss: 138.165531\n",
      "Train Epoch: 42 [300000/697932 (43%)]\tLoss: 140.550172\n",
      "Train Epoch: 42 [400000/697932 (57%)]\tLoss: 140.500016\n",
      "Train Epoch: 42 [500000/697932 (72%)]\tLoss: 142.440828\n",
      "Train Epoch: 42 [600000/697932 (86%)]\tLoss: 139.332313\n",
      "====> Epoch: 42 Average loss: 140.9909\n",
      "====> Test set loss: 141.4597\n",
      "Train Epoch: 43 [0/697932 (0%)]\tLoss: 143.055734\n",
      "Train Epoch: 43 [100000/697932 (14%)]\tLoss: 141.774281\n",
      "Train Epoch: 43 [200000/697932 (29%)]\tLoss: 140.638937\n",
      "Train Epoch: 43 [300000/697932 (43%)]\tLoss: 141.317828\n",
      "Train Epoch: 43 [400000/697932 (57%)]\tLoss: 140.845922\n",
      "Train Epoch: 43 [500000/697932 (72%)]\tLoss: 142.392313\n",
      "Train Epoch: 43 [600000/697932 (86%)]\tLoss: 141.567484\n",
      "====> Epoch: 43 Average loss: 140.9314\n",
      "====> Test set loss: 141.4844\n",
      "Train Epoch: 44 [0/697932 (0%)]\tLoss: 139.114547\n",
      "Train Epoch: 44 [100000/697932 (14%)]\tLoss: 139.993156\n",
      "Train Epoch: 44 [200000/697932 (29%)]\tLoss: 140.049688\n",
      "Train Epoch: 44 [300000/697932 (43%)]\tLoss: 140.453781\n",
      "Train Epoch: 44 [400000/697932 (57%)]\tLoss: 141.416016\n",
      "Train Epoch: 44 [500000/697932 (72%)]\tLoss: 140.284219\n",
      "Train Epoch: 44 [600000/697932 (86%)]\tLoss: 140.944813\n",
      "====> Epoch: 44 Average loss: 140.8886\n",
      "====> Test set loss: 141.3861\n",
      "Train Epoch: 45 [0/697932 (0%)]\tLoss: 141.572156\n",
      "Train Epoch: 45 [100000/697932 (14%)]\tLoss: 141.172000\n",
      "Train Epoch: 45 [200000/697932 (29%)]\tLoss: 140.351594\n",
      "Train Epoch: 45 [300000/697932 (43%)]\tLoss: 139.346281\n",
      "Train Epoch: 45 [400000/697932 (57%)]\tLoss: 141.110422\n",
      "Train Epoch: 45 [500000/697932 (72%)]\tLoss: 139.520109\n",
      "Train Epoch: 45 [600000/697932 (86%)]\tLoss: 140.618969\n",
      "====> Epoch: 45 Average loss: 140.8303\n",
      "====> Test set loss: 141.4837\n",
      "Train Epoch: 46 [0/697932 (0%)]\tLoss: 141.369375\n",
      "Train Epoch: 46 [100000/697932 (14%)]\tLoss: 139.202125\n",
      "Train Epoch: 46 [200000/697932 (29%)]\tLoss: 140.426281\n",
      "Train Epoch: 46 [300000/697932 (43%)]\tLoss: 139.891094\n",
      "Train Epoch: 46 [400000/697932 (57%)]\tLoss: 142.989313\n",
      "Train Epoch: 46 [500000/697932 (72%)]\tLoss: 140.146625\n",
      "Train Epoch: 46 [600000/697932 (86%)]\tLoss: 141.104422\n",
      "====> Epoch: 46 Average loss: 140.7968\n",
      "====> Test set loss: 141.3770\n",
      "Train Epoch: 47 [0/697932 (0%)]\tLoss: 140.541547\n",
      "Train Epoch: 47 [100000/697932 (14%)]\tLoss: 139.433562\n",
      "Train Epoch: 47 [200000/697932 (29%)]\tLoss: 141.130313\n",
      "Train Epoch: 47 [300000/697932 (43%)]\tLoss: 139.633969\n",
      "Train Epoch: 47 [400000/697932 (57%)]\tLoss: 139.910734\n",
      "Train Epoch: 47 [500000/697932 (72%)]\tLoss: 140.993031\n",
      "Train Epoch: 47 [600000/697932 (86%)]\tLoss: 141.307344\n",
      "====> Epoch: 47 Average loss: 140.7386\n",
      "====> Test set loss: 141.2999\n",
      "Train Epoch: 48 [0/697932 (0%)]\tLoss: 140.131172\n",
      "Train Epoch: 48 [100000/697932 (14%)]\tLoss: 140.230969\n",
      "Train Epoch: 48 [200000/697932 (29%)]\tLoss: 138.344812\n",
      "Train Epoch: 48 [300000/697932 (43%)]\tLoss: 140.953078\n",
      "Train Epoch: 48 [400000/697932 (57%)]\tLoss: 141.067187\n",
      "Train Epoch: 48 [500000/697932 (72%)]\tLoss: 139.966672\n",
      "Train Epoch: 48 [600000/697932 (86%)]\tLoss: 139.651109\n",
      "====> Epoch: 48 Average loss: 140.7201\n",
      "====> Test set loss: 141.3300\n",
      "Train Epoch: 49 [0/697932 (0%)]\tLoss: 138.130375\n",
      "Train Epoch: 49 [100000/697932 (14%)]\tLoss: 140.689531\n",
      "Train Epoch: 49 [200000/697932 (29%)]\tLoss: 138.480250\n",
      "Train Epoch: 49 [300000/697932 (43%)]\tLoss: 140.579438\n",
      "Train Epoch: 49 [400000/697932 (57%)]\tLoss: 141.146797\n",
      "Train Epoch: 49 [500000/697932 (72%)]\tLoss: 141.777969\n",
      "Train Epoch: 49 [600000/697932 (86%)]\tLoss: 140.358141\n",
      "====> Epoch: 49 Average loss: 140.6673\n",
      "====> Test set loss: 141.2252\n",
      "Train Epoch: 50 [0/697932 (0%)]\tLoss: 141.912563\n",
      "Train Epoch: 50 [100000/697932 (14%)]\tLoss: 140.762406\n",
      "Train Epoch: 50 [200000/697932 (29%)]\tLoss: 142.583906\n",
      "Train Epoch: 50 [300000/697932 (43%)]\tLoss: 140.546750\n",
      "Train Epoch: 50 [400000/697932 (57%)]\tLoss: 141.947344\n",
      "Train Epoch: 50 [500000/697932 (72%)]\tLoss: 141.027562\n",
      "Train Epoch: 50 [600000/697932 (86%)]\tLoss: 139.408406\n",
      "====> Epoch: 50 Average loss: 140.6272\n",
      "====> Test set loss: 141.1868\n",
      "Train Epoch: 51 [0/697932 (0%)]\tLoss: 142.909281\n",
      "Train Epoch: 51 [100000/697932 (14%)]\tLoss: 141.245297\n",
      "Train Epoch: 51 [200000/697932 (29%)]\tLoss: 141.455203\n",
      "Train Epoch: 51 [300000/697932 (43%)]\tLoss: 139.853813\n",
      "Train Epoch: 51 [400000/697932 (57%)]\tLoss: 139.951359\n",
      "Train Epoch: 51 [500000/697932 (72%)]\tLoss: 141.265750\n",
      "Train Epoch: 51 [600000/697932 (86%)]\tLoss: 139.264219\n",
      "====> Epoch: 51 Average loss: 140.5922\n",
      "====> Test set loss: 141.1679\n",
      "Train Epoch: 52 [0/697932 (0%)]\tLoss: 140.276062\n",
      "Train Epoch: 52 [100000/697932 (14%)]\tLoss: 140.063344\n",
      "Train Epoch: 52 [200000/697932 (29%)]\tLoss: 139.009219\n",
      "Train Epoch: 52 [300000/697932 (43%)]\tLoss: 141.537187\n",
      "Train Epoch: 52 [400000/697932 (57%)]\tLoss: 141.452016\n",
      "Train Epoch: 52 [500000/697932 (72%)]\tLoss: 140.182562\n",
      "Train Epoch: 52 [600000/697932 (86%)]\tLoss: 141.860078\n",
      "====> Epoch: 52 Average loss: 140.5368\n",
      "====> Test set loss: 141.0819\n",
      "Train Epoch: 53 [0/697932 (0%)]\tLoss: 139.747719\n",
      "Train Epoch: 53 [100000/697932 (14%)]\tLoss: 140.135250\n",
      "Train Epoch: 53 [200000/697932 (29%)]\tLoss: 141.960219\n",
      "Train Epoch: 53 [300000/697932 (43%)]\tLoss: 140.357469\n",
      "Train Epoch: 53 [400000/697932 (57%)]\tLoss: 140.469172\n",
      "Train Epoch: 53 [500000/697932 (72%)]\tLoss: 141.183875\n",
      "Train Epoch: 53 [600000/697932 (86%)]\tLoss: 140.166109\n",
      "====> Epoch: 53 Average loss: 140.4961\n",
      "====> Test set loss: 141.2092\n",
      "Train Epoch: 54 [0/697932 (0%)]\tLoss: 138.839000\n",
      "Train Epoch: 54 [100000/697932 (14%)]\tLoss: 141.656469\n",
      "Train Epoch: 54 [200000/697932 (29%)]\tLoss: 139.786641\n",
      "Train Epoch: 54 [300000/697932 (43%)]\tLoss: 139.353484\n",
      "Train Epoch: 54 [400000/697932 (57%)]\tLoss: 139.770125\n",
      "Train Epoch: 54 [500000/697932 (72%)]\tLoss: 139.210328\n",
      "Train Epoch: 54 [600000/697932 (86%)]\tLoss: 138.271656\n",
      "====> Epoch: 54 Average loss: 140.4808\n",
      "====> Test set loss: 141.1214\n",
      "Train Epoch: 55 [0/697932 (0%)]\tLoss: 139.505594\n",
      "Train Epoch: 55 [100000/697932 (14%)]\tLoss: 142.181844\n",
      "Train Epoch: 55 [200000/697932 (29%)]\tLoss: 139.444344\n",
      "Train Epoch: 55 [300000/697932 (43%)]\tLoss: 140.390922\n",
      "Train Epoch: 55 [400000/697932 (57%)]\tLoss: 140.932359\n",
      "Train Epoch: 55 [500000/697932 (72%)]\tLoss: 140.515344\n",
      "Train Epoch: 55 [600000/697932 (86%)]\tLoss: 140.571922\n",
      "====> Epoch: 55 Average loss: 140.4339\n",
      "====> Test set loss: 141.0092\n",
      "Train Epoch: 56 [0/697932 (0%)]\tLoss: 141.424750\n",
      "Train Epoch: 56 [100000/697932 (14%)]\tLoss: 141.497156\n",
      "Train Epoch: 56 [200000/697932 (29%)]\tLoss: 141.396813\n",
      "Train Epoch: 56 [300000/697932 (43%)]\tLoss: 139.794062\n",
      "Train Epoch: 56 [400000/697932 (57%)]\tLoss: 139.976078\n",
      "Train Epoch: 56 [500000/697932 (72%)]\tLoss: 140.519797\n",
      "Train Epoch: 56 [600000/697932 (86%)]\tLoss: 139.219500\n",
      "====> Epoch: 56 Average loss: 140.4153\n",
      "====> Test set loss: 140.9664\n",
      "Train Epoch: 57 [0/697932 (0%)]\tLoss: 138.810563\n",
      "Train Epoch: 57 [100000/697932 (14%)]\tLoss: 139.278406\n",
      "Train Epoch: 57 [200000/697932 (29%)]\tLoss: 140.574297\n",
      "Train Epoch: 57 [300000/697932 (43%)]\tLoss: 139.954641\n",
      "Train Epoch: 57 [400000/697932 (57%)]\tLoss: 139.563125\n",
      "Train Epoch: 57 [500000/697932 (72%)]\tLoss: 140.955453\n",
      "Train Epoch: 57 [600000/697932 (86%)]\tLoss: 140.321281\n",
      "====> Epoch: 57 Average loss: 140.3728\n",
      "====> Test set loss: 141.1194\n",
      "Train Epoch: 58 [0/697932 (0%)]\tLoss: 141.607953\n",
      "Train Epoch: 58 [100000/697932 (14%)]\tLoss: 140.177281\n",
      "Train Epoch: 58 [200000/697932 (29%)]\tLoss: 140.458875\n",
      "Train Epoch: 58 [300000/697932 (43%)]\tLoss: 141.403875\n",
      "Train Epoch: 58 [400000/697932 (57%)]\tLoss: 139.620297\n",
      "Train Epoch: 58 [500000/697932 (72%)]\tLoss: 140.165609\n",
      "Train Epoch: 58 [600000/697932 (86%)]\tLoss: 138.977172\n",
      "====> Epoch: 58 Average loss: 140.3439\n",
      "====> Test set loss: 140.9920\n",
      "Train Epoch: 59 [0/697932 (0%)]\tLoss: 139.830062\n",
      "Train Epoch: 59 [100000/697932 (14%)]\tLoss: 140.574062\n",
      "Train Epoch: 59 [200000/697932 (29%)]\tLoss: 141.119016\n",
      "Train Epoch: 59 [300000/697932 (43%)]\tLoss: 140.457562\n",
      "Train Epoch: 59 [400000/697932 (57%)]\tLoss: 139.425250\n",
      "Train Epoch: 59 [500000/697932 (72%)]\tLoss: 140.505562\n",
      "Train Epoch: 59 [600000/697932 (86%)]\tLoss: 140.676063\n",
      "====> Epoch: 59 Average loss: 140.3017\n",
      "====> Test set loss: 141.0334\n",
      "Train Epoch: 60 [0/697932 (0%)]\tLoss: 139.883375\n",
      "Train Epoch: 60 [100000/697932 (14%)]\tLoss: 139.177047\n",
      "Train Epoch: 60 [200000/697932 (29%)]\tLoss: 141.169203\n",
      "Train Epoch: 60 [300000/697932 (43%)]\tLoss: 141.613891\n",
      "Train Epoch: 60 [400000/697932 (57%)]\tLoss: 143.536078\n",
      "Train Epoch: 60 [500000/697932 (72%)]\tLoss: 140.111672\n",
      "Train Epoch: 60 [600000/697932 (86%)]\tLoss: 140.305000\n",
      "====> Epoch: 60 Average loss: 140.2791\n",
      "====> Test set loss: 140.9548\n",
      "Train Epoch: 61 [0/697932 (0%)]\tLoss: 140.052906\n",
      "Train Epoch: 61 [100000/697932 (14%)]\tLoss: 143.192953\n",
      "Train Epoch: 61 [200000/697932 (29%)]\tLoss: 141.072141\n",
      "Train Epoch: 61 [300000/697932 (43%)]\tLoss: 139.341297\n",
      "Train Epoch: 61 [400000/697932 (57%)]\tLoss: 139.336688\n",
      "Train Epoch: 61 [500000/697932 (72%)]\tLoss: 140.344828\n",
      "Train Epoch: 61 [600000/697932 (86%)]\tLoss: 140.364906\n",
      "====> Epoch: 61 Average loss: 140.2431\n",
      "====> Test set loss: 140.8871\n",
      "Train Epoch: 62 [0/697932 (0%)]\tLoss: 141.653016\n",
      "Train Epoch: 62 [100000/697932 (14%)]\tLoss: 138.958422\n",
      "Train Epoch: 62 [200000/697932 (29%)]\tLoss: 138.617594\n",
      "Train Epoch: 62 [300000/697932 (43%)]\tLoss: 139.555578\n",
      "Train Epoch: 62 [400000/697932 (57%)]\tLoss: 141.066500\n",
      "Train Epoch: 62 [500000/697932 (72%)]\tLoss: 138.771016\n",
      "Train Epoch: 62 [600000/697932 (86%)]\tLoss: 141.205750\n",
      "====> Epoch: 62 Average loss: 140.2122\n",
      "====> Test set loss: 140.8167\n",
      "Train Epoch: 63 [0/697932 (0%)]\tLoss: 139.975703\n",
      "Train Epoch: 63 [100000/697932 (14%)]\tLoss: 139.927703\n",
      "Train Epoch: 63 [200000/697932 (29%)]\tLoss: 139.567813\n",
      "Train Epoch: 63 [300000/697932 (43%)]\tLoss: 141.949172\n",
      "Train Epoch: 63 [400000/697932 (57%)]\tLoss: 140.259797\n",
      "Train Epoch: 63 [500000/697932 (72%)]\tLoss: 141.052922\n",
      "Train Epoch: 63 [600000/697932 (86%)]\tLoss: 136.761812\n",
      "====> Epoch: 63 Average loss: 140.1759\n",
      "====> Test set loss: 140.8389\n",
      "Train Epoch: 64 [0/697932 (0%)]\tLoss: 140.705187\n",
      "Train Epoch: 64 [100000/697932 (14%)]\tLoss: 138.371250\n",
      "Train Epoch: 64 [200000/697932 (29%)]\tLoss: 137.867703\n",
      "Train Epoch: 64 [300000/697932 (43%)]\tLoss: 140.734828\n",
      "Train Epoch: 64 [400000/697932 (57%)]\tLoss: 141.024750\n",
      "Train Epoch: 64 [500000/697932 (72%)]\tLoss: 139.477094\n",
      "Train Epoch: 64 [600000/697932 (86%)]\tLoss: 140.593125\n",
      "====> Epoch: 64 Average loss: 140.1652\n",
      "====> Test set loss: 140.9641\n",
      "Train Epoch: 65 [0/697932 (0%)]\tLoss: 137.908891\n",
      "Train Epoch: 65 [100000/697932 (14%)]\tLoss: 140.068094\n",
      "Train Epoch: 65 [200000/697932 (29%)]\tLoss: 138.650500\n",
      "Train Epoch: 65 [300000/697932 (43%)]\tLoss: 140.602438\n",
      "Train Epoch: 65 [400000/697932 (57%)]\tLoss: 140.822688\n",
      "Train Epoch: 65 [500000/697932 (72%)]\tLoss: 140.229609\n",
      "Train Epoch: 65 [600000/697932 (86%)]\tLoss: 138.583188\n",
      "====> Epoch: 65 Average loss: 140.1462\n",
      "====> Test set loss: 140.8989\n",
      "Train Epoch: 66 [0/697932 (0%)]\tLoss: 140.232344\n",
      "Train Epoch: 66 [100000/697932 (14%)]\tLoss: 139.213109\n",
      "Train Epoch: 66 [200000/697932 (29%)]\tLoss: 139.804016\n",
      "Train Epoch: 66 [300000/697932 (43%)]\tLoss: 140.327359\n",
      "Train Epoch: 66 [400000/697932 (57%)]\tLoss: 139.400078\n",
      "Train Epoch: 66 [500000/697932 (72%)]\tLoss: 140.003641\n",
      "Train Epoch: 66 [600000/697932 (86%)]\tLoss: 139.361047\n",
      "====> Epoch: 66 Average loss: 140.0952\n",
      "====> Test set loss: 140.7871\n",
      "Train Epoch: 67 [0/697932 (0%)]\tLoss: 140.938844\n",
      "Train Epoch: 67 [100000/697932 (14%)]\tLoss: 139.086000\n",
      "Train Epoch: 67 [200000/697932 (29%)]\tLoss: 139.027813\n",
      "Train Epoch: 67 [300000/697932 (43%)]\tLoss: 140.915656\n",
      "Train Epoch: 67 [400000/697932 (57%)]\tLoss: 139.516594\n",
      "Train Epoch: 67 [500000/697932 (72%)]\tLoss: 139.316781\n",
      "Train Epoch: 67 [600000/697932 (86%)]\tLoss: 138.801578\n",
      "====> Epoch: 67 Average loss: 140.0763\n",
      "====> Test set loss: 140.7594\n",
      "Train Epoch: 68 [0/697932 (0%)]\tLoss: 138.819094\n",
      "Train Epoch: 68 [100000/697932 (14%)]\tLoss: 141.173750\n",
      "Train Epoch: 68 [200000/697932 (29%)]\tLoss: 140.602672\n",
      "Train Epoch: 68 [300000/697932 (43%)]\tLoss: 139.403781\n",
      "Train Epoch: 68 [400000/697932 (57%)]\tLoss: 140.322375\n",
      "Train Epoch: 68 [500000/697932 (72%)]\tLoss: 139.923016\n",
      "Train Epoch: 68 [600000/697932 (86%)]\tLoss: 140.252016\n",
      "====> Epoch: 68 Average loss: 140.0522\n",
      "====> Test set loss: 140.8765\n",
      "Train Epoch: 69 [0/697932 (0%)]\tLoss: 137.986109\n",
      "Train Epoch: 69 [100000/697932 (14%)]\tLoss: 139.616031\n",
      "Train Epoch: 69 [200000/697932 (29%)]\tLoss: 140.222094\n",
      "Train Epoch: 69 [300000/697932 (43%)]\tLoss: 137.155172\n",
      "Train Epoch: 69 [400000/697932 (57%)]\tLoss: 140.824172\n",
      "Train Epoch: 69 [500000/697932 (72%)]\tLoss: 140.158016\n",
      "Train Epoch: 69 [600000/697932 (86%)]\tLoss: 138.258484\n",
      "====> Epoch: 69 Average loss: 140.0245\n",
      "====> Test set loss: 140.8122\n",
      "Train Epoch: 70 [0/697932 (0%)]\tLoss: 139.594250\n",
      "Train Epoch: 70 [100000/697932 (14%)]\tLoss: 138.113547\n",
      "Train Epoch: 70 [200000/697932 (29%)]\tLoss: 139.854547\n",
      "Train Epoch: 70 [300000/697932 (43%)]\tLoss: 139.233188\n",
      "Train Epoch: 70 [400000/697932 (57%)]\tLoss: 140.657094\n",
      "Train Epoch: 70 [500000/697932 (72%)]\tLoss: 140.053562\n",
      "Train Epoch: 70 [600000/697932 (86%)]\tLoss: 140.310281\n",
      "====> Epoch: 70 Average loss: 140.0018\n",
      "====> Test set loss: 140.6564\n",
      "Train Epoch: 71 [0/697932 (0%)]\tLoss: 138.473859\n",
      "Train Epoch: 71 [100000/697932 (14%)]\tLoss: 140.369734\n",
      "Train Epoch: 71 [200000/697932 (29%)]\tLoss: 141.024391\n",
      "Train Epoch: 71 [300000/697932 (43%)]\tLoss: 141.272500\n",
      "Train Epoch: 71 [400000/697932 (57%)]\tLoss: 138.139438\n",
      "Train Epoch: 71 [500000/697932 (72%)]\tLoss: 139.971375\n",
      "Train Epoch: 71 [600000/697932 (86%)]\tLoss: 142.213063\n",
      "====> Epoch: 71 Average loss: 139.9843\n",
      "====> Test set loss: 140.6841\n",
      "Train Epoch: 72 [0/697932 (0%)]\tLoss: 140.172656\n",
      "Train Epoch: 72 [100000/697932 (14%)]\tLoss: 140.354906\n",
      "Train Epoch: 72 [200000/697932 (29%)]\tLoss: 138.071922\n",
      "Train Epoch: 72 [300000/697932 (43%)]\tLoss: 138.546281\n",
      "Train Epoch: 72 [400000/697932 (57%)]\tLoss: 140.641437\n",
      "Train Epoch: 72 [500000/697932 (72%)]\tLoss: 141.165406\n",
      "Train Epoch: 72 [600000/697932 (86%)]\tLoss: 141.577313\n",
      "====> Epoch: 72 Average loss: 139.9505\n",
      "====> Test set loss: 140.6785\n",
      "Train Epoch: 73 [0/697932 (0%)]\tLoss: 138.835375\n",
      "Train Epoch: 73 [100000/697932 (14%)]\tLoss: 140.928625\n",
      "Train Epoch: 73 [200000/697932 (29%)]\tLoss: 140.499797\n",
      "Train Epoch: 73 [300000/697932 (43%)]\tLoss: 138.900922\n",
      "Train Epoch: 73 [400000/697932 (57%)]\tLoss: 139.089750\n",
      "Train Epoch: 73 [500000/697932 (72%)]\tLoss: 137.203812\n",
      "Train Epoch: 73 [600000/697932 (86%)]\tLoss: 140.044094\n",
      "====> Epoch: 73 Average loss: 139.9381\n",
      "====> Test set loss: 140.6930\n",
      "Train Epoch: 74 [0/697932 (0%)]\tLoss: 140.037156\n",
      "Train Epoch: 74 [100000/697932 (14%)]\tLoss: 140.125219\n",
      "Train Epoch: 74 [200000/697932 (29%)]\tLoss: 139.280891\n",
      "Train Epoch: 74 [300000/697932 (43%)]\tLoss: 139.965031\n",
      "Train Epoch: 74 [400000/697932 (57%)]\tLoss: 141.452203\n",
      "Train Epoch: 74 [500000/697932 (72%)]\tLoss: 141.147594\n",
      "Train Epoch: 74 [600000/697932 (86%)]\tLoss: 138.576437\n",
      "====> Epoch: 74 Average loss: 139.9026\n",
      "====> Test set loss: 140.6167\n",
      "Train Epoch: 75 [0/697932 (0%)]\tLoss: 138.699547\n",
      "Train Epoch: 75 [100000/697932 (14%)]\tLoss: 138.653719\n",
      "Train Epoch: 75 [200000/697932 (29%)]\tLoss: 138.787422\n",
      "Train Epoch: 75 [300000/697932 (43%)]\tLoss: 138.318500\n",
      "Train Epoch: 75 [400000/697932 (57%)]\tLoss: 139.076375\n",
      "Train Epoch: 75 [500000/697932 (72%)]\tLoss: 140.597750\n",
      "Train Epoch: 75 [600000/697932 (86%)]\tLoss: 140.032062\n",
      "====> Epoch: 75 Average loss: 139.8534\n",
      "====> Test set loss: 140.6321\n",
      "Train Epoch: 76 [0/697932 (0%)]\tLoss: 138.472875\n",
      "Train Epoch: 76 [100000/697932 (14%)]\tLoss: 140.170625\n",
      "Train Epoch: 76 [200000/697932 (29%)]\tLoss: 138.552094\n",
      "Train Epoch: 76 [300000/697932 (43%)]\tLoss: 139.184438\n",
      "Train Epoch: 76 [400000/697932 (57%)]\tLoss: 140.053266\n",
      "Train Epoch: 76 [500000/697932 (72%)]\tLoss: 140.536812\n",
      "Train Epoch: 76 [600000/697932 (86%)]\tLoss: 138.888313\n",
      "====> Epoch: 76 Average loss: 139.8697\n",
      "====> Test set loss: 140.5358\n",
      "Train Epoch: 77 [0/697932 (0%)]\tLoss: 137.447937\n",
      "Train Epoch: 77 [100000/697932 (14%)]\tLoss: 138.921031\n",
      "Train Epoch: 77 [200000/697932 (29%)]\tLoss: 142.262734\n",
      "Train Epoch: 77 [300000/697932 (43%)]\tLoss: 137.511359\n",
      "Train Epoch: 77 [400000/697932 (57%)]\tLoss: 139.605297\n",
      "Train Epoch: 77 [500000/697932 (72%)]\tLoss: 140.333156\n",
      "Train Epoch: 77 [600000/697932 (86%)]\tLoss: 139.732781\n",
      "====> Epoch: 77 Average loss: 139.8470\n",
      "====> Test set loss: 140.6455\n",
      "Train Epoch: 78 [0/697932 (0%)]\tLoss: 139.980687\n",
      "Train Epoch: 78 [100000/697932 (14%)]\tLoss: 139.133062\n",
      "Train Epoch: 78 [200000/697932 (29%)]\tLoss: 137.086266\n",
      "Train Epoch: 78 [300000/697932 (43%)]\tLoss: 140.773672\n",
      "Train Epoch: 78 [400000/697932 (57%)]\tLoss: 141.254328\n",
      "Train Epoch: 78 [500000/697932 (72%)]\tLoss: 139.775281\n",
      "Train Epoch: 78 [600000/697932 (86%)]\tLoss: 139.891750\n",
      "====> Epoch: 78 Average loss: 139.8080\n",
      "====> Test set loss: 140.5048\n",
      "Train Epoch: 79 [0/697932 (0%)]\tLoss: 138.642578\n",
      "Train Epoch: 79 [100000/697932 (14%)]\tLoss: 139.723813\n",
      "Train Epoch: 79 [200000/697932 (29%)]\tLoss: 140.380484\n",
      "Train Epoch: 79 [300000/697932 (43%)]\tLoss: 139.689734\n",
      "Train Epoch: 79 [400000/697932 (57%)]\tLoss: 140.199344\n",
      "Train Epoch: 79 [500000/697932 (72%)]\tLoss: 138.441031\n",
      "Train Epoch: 79 [600000/697932 (86%)]\tLoss: 140.273391\n",
      "====> Epoch: 79 Average loss: 139.7978\n",
      "====> Test set loss: 140.7420\n",
      "Train Epoch: 80 [0/697932 (0%)]\tLoss: 139.507844\n",
      "Train Epoch: 80 [100000/697932 (14%)]\tLoss: 140.225437\n",
      "Train Epoch: 80 [200000/697932 (29%)]\tLoss: 138.862453\n",
      "Train Epoch: 80 [300000/697932 (43%)]\tLoss: 139.339266\n",
      "Train Epoch: 80 [400000/697932 (57%)]\tLoss: 138.378844\n",
      "Train Epoch: 80 [500000/697932 (72%)]\tLoss: 139.113578\n",
      "Train Epoch: 80 [600000/697932 (86%)]\tLoss: 139.051516\n",
      "====> Epoch: 80 Average loss: 139.7686\n",
      "====> Test set loss: 140.6690\n",
      "Train Epoch: 81 [0/697932 (0%)]\tLoss: 138.946297\n",
      "Train Epoch: 81 [100000/697932 (14%)]\tLoss: 138.309281\n",
      "Train Epoch: 81 [200000/697932 (29%)]\tLoss: 141.413484\n",
      "Train Epoch: 81 [300000/697932 (43%)]\tLoss: 139.926031\n",
      "Train Epoch: 81 [400000/697932 (57%)]\tLoss: 141.426297\n",
      "Train Epoch: 81 [500000/697932 (72%)]\tLoss: 138.750344\n",
      "Train Epoch: 81 [600000/697932 (86%)]\tLoss: 138.532594\n",
      "====> Epoch: 81 Average loss: 139.7543\n",
      "====> Test set loss: 140.4258\n",
      "Train Epoch: 82 [0/697932 (0%)]\tLoss: 141.837656\n",
      "Train Epoch: 82 [100000/697932 (14%)]\tLoss: 139.392109\n",
      "Train Epoch: 82 [200000/697932 (29%)]\tLoss: 141.162797\n",
      "Train Epoch: 82 [300000/697932 (43%)]\tLoss: 138.229375\n",
      "Train Epoch: 82 [400000/697932 (57%)]\tLoss: 139.778031\n",
      "Train Epoch: 82 [500000/697932 (72%)]\tLoss: 140.131219\n",
      "Train Epoch: 82 [600000/697932 (86%)]\tLoss: 139.567281\n",
      "====> Epoch: 82 Average loss: 139.7409\n",
      "====> Test set loss: 140.3989\n",
      "Train Epoch: 83 [0/697932 (0%)]\tLoss: 139.833469\n",
      "Train Epoch: 83 [100000/697932 (14%)]\tLoss: 138.527562\n",
      "Train Epoch: 83 [200000/697932 (29%)]\tLoss: 138.657984\n",
      "Train Epoch: 83 [300000/697932 (43%)]\tLoss: 140.454578\n",
      "Train Epoch: 83 [400000/697932 (57%)]\tLoss: 138.838922\n",
      "Train Epoch: 83 [500000/697932 (72%)]\tLoss: 139.968375\n",
      "Train Epoch: 83 [600000/697932 (86%)]\tLoss: 140.261063\n",
      "====> Epoch: 83 Average loss: 139.7220\n",
      "====> Test set loss: 140.5573\n",
      "Train Epoch: 84 [0/697932 (0%)]\tLoss: 140.170781\n",
      "Train Epoch: 84 [100000/697932 (14%)]\tLoss: 139.407625\n",
      "Train Epoch: 84 [200000/697932 (29%)]\tLoss: 142.856812\n",
      "Train Epoch: 84 [300000/697932 (43%)]\tLoss: 137.773906\n",
      "Train Epoch: 84 [400000/697932 (57%)]\tLoss: 140.807234\n",
      "Train Epoch: 84 [500000/697932 (72%)]\tLoss: 140.685594\n",
      "Train Epoch: 84 [600000/697932 (86%)]\tLoss: 139.325594\n",
      "====> Epoch: 84 Average loss: 139.7115\n",
      "====> Test set loss: 140.4356\n",
      "Train Epoch: 85 [0/697932 (0%)]\tLoss: 139.171156\n",
      "Train Epoch: 85 [100000/697932 (14%)]\tLoss: 141.547687\n",
      "Train Epoch: 85 [200000/697932 (29%)]\tLoss: 139.966719\n",
      "Train Epoch: 85 [300000/697932 (43%)]\tLoss: 138.872562\n",
      "Train Epoch: 85 [400000/697932 (57%)]\tLoss: 138.912656\n",
      "Train Epoch: 85 [500000/697932 (72%)]\tLoss: 139.684531\n",
      "Train Epoch: 85 [600000/697932 (86%)]\tLoss: 138.829531\n",
      "====> Epoch: 85 Average loss: 139.6784\n",
      "====> Test set loss: 140.5148\n",
      "Train Epoch: 86 [0/697932 (0%)]\tLoss: 140.252813\n",
      "Train Epoch: 86 [100000/697932 (14%)]\tLoss: 139.332234\n",
      "Train Epoch: 86 [200000/697932 (29%)]\tLoss: 140.836594\n",
      "Train Epoch: 86 [300000/697932 (43%)]\tLoss: 138.467047\n",
      "Train Epoch: 86 [400000/697932 (57%)]\tLoss: 138.351047\n",
      "Train Epoch: 86 [500000/697932 (72%)]\tLoss: 140.532016\n",
      "Train Epoch: 86 [600000/697932 (86%)]\tLoss: 139.660156\n",
      "====> Epoch: 86 Average loss: 139.6633\n",
      "====> Test set loss: 140.4611\n",
      "Train Epoch: 87 [0/697932 (0%)]\tLoss: 140.529203\n",
      "Train Epoch: 87 [100000/697932 (14%)]\tLoss: 140.376844\n",
      "Train Epoch: 87 [200000/697932 (29%)]\tLoss: 138.817391\n",
      "Train Epoch: 87 [300000/697932 (43%)]\tLoss: 140.583797\n",
      "Train Epoch: 87 [400000/697932 (57%)]\tLoss: 139.558281\n",
      "Train Epoch: 87 [500000/697932 (72%)]\tLoss: 139.921375\n",
      "Train Epoch: 87 [600000/697932 (86%)]\tLoss: 140.813500\n",
      "====> Epoch: 87 Average loss: 139.6518\n",
      "====> Test set loss: 140.4962\n",
      "Train Epoch: 88 [0/697932 (0%)]\tLoss: 140.622187\n",
      "Train Epoch: 88 [100000/697932 (14%)]\tLoss: 139.974406\n",
      "Train Epoch: 88 [200000/697932 (29%)]\tLoss: 139.553031\n",
      "Train Epoch: 88 [300000/697932 (43%)]\tLoss: 142.666516\n",
      "Train Epoch: 88 [400000/697932 (57%)]\tLoss: 138.346359\n",
      "Train Epoch: 88 [500000/697932 (72%)]\tLoss: 138.808312\n",
      "Train Epoch: 88 [600000/697932 (86%)]\tLoss: 139.687344\n",
      "====> Epoch: 88 Average loss: 139.6247\n",
      "====> Test set loss: 140.4377\n",
      "Train Epoch: 89 [0/697932 (0%)]\tLoss: 138.792141\n",
      "Train Epoch: 89 [100000/697932 (14%)]\tLoss: 138.317000\n",
      "Train Epoch: 89 [200000/697932 (29%)]\tLoss: 141.272406\n",
      "Train Epoch: 89 [300000/697932 (43%)]\tLoss: 137.681437\n",
      "Train Epoch: 89 [400000/697932 (57%)]\tLoss: 140.713422\n",
      "Train Epoch: 89 [500000/697932 (72%)]\tLoss: 139.928859\n",
      "Train Epoch: 89 [600000/697932 (86%)]\tLoss: 139.610516\n",
      "====> Epoch: 89 Average loss: 139.6035\n",
      "====> Test set loss: 140.3840\n",
      "Train Epoch: 90 [0/697932 (0%)]\tLoss: 141.311266\n",
      "Train Epoch: 90 [100000/697932 (14%)]\tLoss: 140.880656\n",
      "Train Epoch: 90 [200000/697932 (29%)]\tLoss: 139.978906\n",
      "Train Epoch: 90 [300000/697932 (43%)]\tLoss: 139.641969\n",
      "Train Epoch: 90 [400000/697932 (57%)]\tLoss: 139.918078\n",
      "Train Epoch: 90 [500000/697932 (72%)]\tLoss: 139.171469\n",
      "Train Epoch: 90 [600000/697932 (86%)]\tLoss: 138.034875\n",
      "====> Epoch: 90 Average loss: 139.5795\n",
      "====> Test set loss: 140.3809\n",
      "Train Epoch: 91 [0/697932 (0%)]\tLoss: 141.607859\n",
      "Train Epoch: 91 [100000/697932 (14%)]\tLoss: 138.926844\n",
      "Train Epoch: 91 [200000/697932 (29%)]\tLoss: 138.813047\n",
      "Train Epoch: 91 [300000/697932 (43%)]\tLoss: 140.802547\n",
      "Train Epoch: 91 [400000/697932 (57%)]\tLoss: 139.368797\n",
      "Train Epoch: 91 [500000/697932 (72%)]\tLoss: 139.261125\n",
      "Train Epoch: 91 [600000/697932 (86%)]\tLoss: 138.968016\n",
      "====> Epoch: 91 Average loss: 139.5697\n",
      "====> Test set loss: 140.3545\n",
      "Train Epoch: 92 [0/697932 (0%)]\tLoss: 139.481328\n",
      "Train Epoch: 92 [100000/697932 (14%)]\tLoss: 140.374125\n",
      "Train Epoch: 92 [200000/697932 (29%)]\tLoss: 141.647047\n",
      "Train Epoch: 92 [300000/697932 (43%)]\tLoss: 139.858188\n",
      "Train Epoch: 92 [400000/697932 (57%)]\tLoss: 139.326469\n",
      "Train Epoch: 92 [500000/697932 (72%)]\tLoss: 139.212219\n",
      "Train Epoch: 92 [600000/697932 (86%)]\tLoss: 137.930469\n",
      "====> Epoch: 92 Average loss: 139.5576\n",
      "====> Test set loss: 140.3251\n",
      "Train Epoch: 93 [0/697932 (0%)]\tLoss: 140.690516\n",
      "Train Epoch: 93 [100000/697932 (14%)]\tLoss: 138.928156\n",
      "Train Epoch: 93 [200000/697932 (29%)]\tLoss: 139.097719\n",
      "Train Epoch: 93 [300000/697932 (43%)]\tLoss: 141.712375\n",
      "Train Epoch: 93 [400000/697932 (57%)]\tLoss: 140.254156\n",
      "Train Epoch: 93 [500000/697932 (72%)]\tLoss: 140.197500\n",
      "Train Epoch: 93 [600000/697932 (86%)]\tLoss: 139.810344\n",
      "====> Epoch: 93 Average loss: 139.5309\n",
      "====> Test set loss: 140.3234\n",
      "Train Epoch: 94 [0/697932 (0%)]\tLoss: 139.921172\n",
      "Train Epoch: 94 [100000/697932 (14%)]\tLoss: 139.123156\n",
      "Train Epoch: 94 [200000/697932 (29%)]\tLoss: 137.426375\n",
      "Train Epoch: 94 [300000/697932 (43%)]\tLoss: 140.422516\n",
      "Train Epoch: 94 [400000/697932 (57%)]\tLoss: 141.058766\n",
      "Train Epoch: 94 [500000/697932 (72%)]\tLoss: 139.929062\n",
      "Train Epoch: 94 [600000/697932 (86%)]\tLoss: 139.179359\n",
      "====> Epoch: 94 Average loss: 139.5247\n",
      "====> Test set loss: 140.4648\n",
      "Train Epoch: 95 [0/697932 (0%)]\tLoss: 142.736094\n",
      "Train Epoch: 95 [100000/697932 (14%)]\tLoss: 136.973547\n",
      "Train Epoch: 95 [200000/697932 (29%)]\tLoss: 138.890281\n",
      "Train Epoch: 95 [300000/697932 (43%)]\tLoss: 140.515156\n",
      "Train Epoch: 95 [400000/697932 (57%)]\tLoss: 138.934281\n",
      "Train Epoch: 95 [500000/697932 (72%)]\tLoss: 139.662531\n",
      "Train Epoch: 95 [600000/697932 (86%)]\tLoss: 138.666266\n",
      "====> Epoch: 95 Average loss: 139.5171\n",
      "====> Test set loss: 140.2661\n",
      "Train Epoch: 96 [0/697932 (0%)]\tLoss: 138.442719\n",
      "Train Epoch: 96 [100000/697932 (14%)]\tLoss: 141.071094\n",
      "Train Epoch: 96 [200000/697932 (29%)]\tLoss: 139.272812\n",
      "Train Epoch: 96 [300000/697932 (43%)]\tLoss: 139.371813\n",
      "Train Epoch: 96 [400000/697932 (57%)]\tLoss: 138.540984\n",
      "Train Epoch: 96 [500000/697932 (72%)]\tLoss: 140.126937\n",
      "Train Epoch: 96 [600000/697932 (86%)]\tLoss: 139.915594\n",
      "====> Epoch: 96 Average loss: 139.4906\n",
      "====> Test set loss: 140.3092\n",
      "Train Epoch: 97 [0/697932 (0%)]\tLoss: 139.353844\n",
      "Train Epoch: 97 [100000/697932 (14%)]\tLoss: 138.806625\n",
      "Train Epoch: 97 [200000/697932 (29%)]\tLoss: 137.071812\n",
      "Train Epoch: 97 [300000/697932 (43%)]\tLoss: 138.270234\n",
      "Train Epoch: 97 [400000/697932 (57%)]\tLoss: 140.223656\n",
      "Train Epoch: 97 [500000/697932 (72%)]\tLoss: 139.651156\n",
      "Train Epoch: 97 [600000/697932 (86%)]\tLoss: 138.004406\n",
      "====> Epoch: 97 Average loss: 139.4730\n",
      "====> Test set loss: 140.2419\n",
      "Train Epoch: 98 [0/697932 (0%)]\tLoss: 140.874031\n",
      "Train Epoch: 98 [100000/697932 (14%)]\tLoss: 136.776875\n",
      "Train Epoch: 98 [200000/697932 (29%)]\tLoss: 138.065969\n",
      "Train Epoch: 98 [300000/697932 (43%)]\tLoss: 140.035562\n",
      "Train Epoch: 98 [400000/697932 (57%)]\tLoss: 139.627266\n",
      "Train Epoch: 98 [500000/697932 (72%)]\tLoss: 138.830563\n",
      "Train Epoch: 98 [600000/697932 (86%)]\tLoss: 138.555984\n",
      "====> Epoch: 98 Average loss: 139.4648\n",
      "====> Test set loss: 140.2723\n",
      "Train Epoch: 99 [0/697932 (0%)]\tLoss: 139.499391\n",
      "Train Epoch: 99 [100000/697932 (14%)]\tLoss: 138.924031\n",
      "Train Epoch: 99 [200000/697932 (29%)]\tLoss: 138.550719\n",
      "Train Epoch: 99 [300000/697932 (43%)]\tLoss: 141.715250\n",
      "Train Epoch: 99 [400000/697932 (57%)]\tLoss: 138.067266\n",
      "Train Epoch: 99 [500000/697932 (72%)]\tLoss: 137.677719\n",
      "Train Epoch: 99 [600000/697932 (86%)]\tLoss: 139.928359\n",
      "====> Epoch: 99 Average loss: 139.4490\n",
      "====> Test set loss: 140.2685\n",
      "Train Epoch: 100 [0/697932 (0%)]\tLoss: 140.415609\n",
      "Train Epoch: 100 [100000/697932 (14%)]\tLoss: 140.980969\n",
      "Train Epoch: 100 [200000/697932 (29%)]\tLoss: 138.923109\n",
      "Train Epoch: 100 [300000/697932 (43%)]\tLoss: 140.120266\n",
      "Train Epoch: 100 [400000/697932 (57%)]\tLoss: 139.692672\n",
      "Train Epoch: 100 [500000/697932 (72%)]\tLoss: 138.905844\n",
      "Train Epoch: 100 [600000/697932 (86%)]\tLoss: 140.603047\n",
      "====> Epoch: 100 Average loss: 139.4229\n",
      "====> Test set loss: 140.2094\n",
      "Train Epoch: 101 [0/697932 (0%)]\tLoss: 139.673719\n",
      "Train Epoch: 101 [100000/697932 (14%)]\tLoss: 139.453734\n",
      "Train Epoch: 101 [200000/697932 (29%)]\tLoss: 138.778125\n",
      "Train Epoch: 101 [300000/697932 (43%)]\tLoss: 136.499328\n",
      "Train Epoch: 101 [400000/697932 (57%)]\tLoss: 139.982937\n",
      "Train Epoch: 101 [500000/697932 (72%)]\tLoss: 140.207250\n",
      "Train Epoch: 101 [600000/697932 (86%)]\tLoss: 138.680844\n",
      "====> Epoch: 101 Average loss: 139.3988\n",
      "====> Test set loss: 140.2518\n",
      "Train Epoch: 102 [0/697932 (0%)]\tLoss: 140.089969\n",
      "Train Epoch: 102 [100000/697932 (14%)]\tLoss: 141.128969\n",
      "Train Epoch: 102 [200000/697932 (29%)]\tLoss: 140.627109\n",
      "Train Epoch: 102 [300000/697932 (43%)]\tLoss: 140.189406\n",
      "Train Epoch: 102 [400000/697932 (57%)]\tLoss: 138.699578\n",
      "Train Epoch: 102 [500000/697932 (72%)]\tLoss: 139.661969\n",
      "Train Epoch: 102 [600000/697932 (86%)]\tLoss: 139.386531\n",
      "====> Epoch: 102 Average loss: 139.4062\n",
      "====> Test set loss: 140.1979\n",
      "Train Epoch: 103 [0/697932 (0%)]\tLoss: 138.724453\n",
      "Train Epoch: 103 [100000/697932 (14%)]\tLoss: 138.243219\n",
      "Train Epoch: 103 [200000/697932 (29%)]\tLoss: 141.581828\n",
      "Train Epoch: 103 [300000/697932 (43%)]\tLoss: 138.310313\n",
      "Train Epoch: 103 [400000/697932 (57%)]\tLoss: 138.931375\n",
      "Train Epoch: 103 [500000/697932 (72%)]\tLoss: 138.317875\n",
      "Train Epoch: 103 [600000/697932 (86%)]\tLoss: 141.325469\n",
      "====> Epoch: 103 Average loss: 139.3984\n",
      "====> Test set loss: 140.3557\n",
      "Train Epoch: 104 [0/697932 (0%)]\tLoss: 141.477344\n",
      "Train Epoch: 104 [100000/697932 (14%)]\tLoss: 139.947719\n",
      "Train Epoch: 104 [200000/697932 (29%)]\tLoss: 138.585828\n",
      "Train Epoch: 104 [300000/697932 (43%)]\tLoss: 141.041766\n",
      "Train Epoch: 104 [400000/697932 (57%)]\tLoss: 138.067031\n",
      "Train Epoch: 104 [500000/697932 (72%)]\tLoss: 140.094125\n",
      "Train Epoch: 104 [600000/697932 (86%)]\tLoss: 139.256906\n",
      "====> Epoch: 104 Average loss: 139.3847\n",
      "====> Test set loss: 140.1468\n",
      "Train Epoch: 105 [0/697932 (0%)]\tLoss: 139.773594\n",
      "Train Epoch: 105 [100000/697932 (14%)]\tLoss: 139.492188\n",
      "Train Epoch: 105 [200000/697932 (29%)]\tLoss: 140.260141\n",
      "Train Epoch: 105 [300000/697932 (43%)]\tLoss: 140.468734\n",
      "Train Epoch: 105 [400000/697932 (57%)]\tLoss: 139.244125\n",
      "Train Epoch: 105 [500000/697932 (72%)]\tLoss: 141.636562\n",
      "Train Epoch: 105 [600000/697932 (86%)]\tLoss: 136.622531\n",
      "====> Epoch: 105 Average loss: 139.3453\n",
      "====> Test set loss: 140.2103\n",
      "Train Epoch: 106 [0/697932 (0%)]\tLoss: 138.223625\n",
      "Train Epoch: 106 [100000/697932 (14%)]\tLoss: 138.595687\n",
      "Train Epoch: 106 [200000/697932 (29%)]\tLoss: 139.873797\n",
      "Train Epoch: 106 [300000/697932 (43%)]\tLoss: 140.015062\n",
      "Train Epoch: 106 [400000/697932 (57%)]\tLoss: 141.008266\n",
      "Train Epoch: 106 [500000/697932 (72%)]\tLoss: 139.871406\n",
      "Train Epoch: 106 [600000/697932 (86%)]\tLoss: 139.456484\n",
      "====> Epoch: 106 Average loss: 139.3378\n",
      "====> Test set loss: 140.1855\n",
      "Train Epoch: 107 [0/697932 (0%)]\tLoss: 138.410047\n",
      "Train Epoch: 107 [100000/697932 (14%)]\tLoss: 137.416625\n",
      "Train Epoch: 107 [200000/697932 (29%)]\tLoss: 140.138766\n",
      "Train Epoch: 107 [300000/697932 (43%)]\tLoss: 140.490219\n",
      "Train Epoch: 107 [400000/697932 (57%)]\tLoss: 138.265781\n",
      "Train Epoch: 107 [500000/697932 (72%)]\tLoss: 138.649969\n",
      "Train Epoch: 107 [600000/697932 (86%)]\tLoss: 140.720453\n",
      "====> Epoch: 107 Average loss: 139.3282\n",
      "====> Test set loss: 140.2062\n",
      "Train Epoch: 108 [0/697932 (0%)]\tLoss: 139.866562\n",
      "Train Epoch: 108 [100000/697932 (14%)]\tLoss: 138.294078\n",
      "Train Epoch: 108 [200000/697932 (29%)]\tLoss: 139.126531\n",
      "Train Epoch: 108 [300000/697932 (43%)]\tLoss: 139.919422\n",
      "Train Epoch: 108 [400000/697932 (57%)]\tLoss: 140.170547\n",
      "Train Epoch: 108 [500000/697932 (72%)]\tLoss: 138.777750\n",
      "Train Epoch: 108 [600000/697932 (86%)]\tLoss: 141.389938\n",
      "====> Epoch: 108 Average loss: 139.3000\n",
      "====> Test set loss: 140.2843\n",
      "Train Epoch: 109 [0/697932 (0%)]\tLoss: 138.553375\n",
      "Train Epoch: 109 [100000/697932 (14%)]\tLoss: 138.456375\n",
      "Train Epoch: 109 [200000/697932 (29%)]\tLoss: 139.460187\n",
      "Train Epoch: 109 [300000/697932 (43%)]\tLoss: 138.597641\n",
      "Train Epoch: 109 [400000/697932 (57%)]\tLoss: 139.838141\n",
      "Train Epoch: 109 [500000/697932 (72%)]\tLoss: 138.514187\n",
      "Train Epoch: 109 [600000/697932 (86%)]\tLoss: 138.227812\n",
      "====> Epoch: 109 Average loss: 139.3064\n",
      "====> Test set loss: 140.1065\n",
      "Train Epoch: 110 [0/697932 (0%)]\tLoss: 139.553969\n",
      "Train Epoch: 110 [100000/697932 (14%)]\tLoss: 139.474000\n",
      "Train Epoch: 110 [200000/697932 (29%)]\tLoss: 138.205563\n",
      "Train Epoch: 110 [300000/697932 (43%)]\tLoss: 138.871219\n",
      "Train Epoch: 110 [400000/697932 (57%)]\tLoss: 141.290203\n",
      "Train Epoch: 110 [500000/697932 (72%)]\tLoss: 137.350656\n",
      "Train Epoch: 110 [600000/697932 (86%)]\tLoss: 136.976859\n",
      "====> Epoch: 110 Average loss: 139.2981\n",
      "====> Test set loss: 140.3755\n",
      "Train Epoch: 111 [0/697932 (0%)]\tLoss: 139.310094\n",
      "Train Epoch: 111 [100000/697932 (14%)]\tLoss: 138.496438\n",
      "Train Epoch: 111 [200000/697932 (29%)]\tLoss: 141.074000\n",
      "Train Epoch: 111 [300000/697932 (43%)]\tLoss: 140.923750\n",
      "Train Epoch: 111 [400000/697932 (57%)]\tLoss: 138.254547\n",
      "Train Epoch: 111 [500000/697932 (72%)]\tLoss: 138.140203\n",
      "Train Epoch: 111 [600000/697932 (86%)]\tLoss: 138.246641\n",
      "====> Epoch: 111 Average loss: 139.2750\n",
      "====> Test set loss: 140.1284\n",
      "Train Epoch: 112 [0/697932 (0%)]\tLoss: 139.172969\n",
      "Train Epoch: 112 [100000/697932 (14%)]\tLoss: 139.686047\n",
      "Train Epoch: 112 [200000/697932 (29%)]\tLoss: 137.486844\n",
      "Train Epoch: 112 [300000/697932 (43%)]\tLoss: 140.577156\n",
      "Train Epoch: 112 [400000/697932 (57%)]\tLoss: 139.148609\n",
      "Train Epoch: 112 [500000/697932 (72%)]\tLoss: 138.578812\n",
      "Train Epoch: 112 [600000/697932 (86%)]\tLoss: 140.171172\n",
      "====> Epoch: 112 Average loss: 139.2569\n",
      "====> Test set loss: 140.1322\n",
      "Train Epoch: 113 [0/697932 (0%)]\tLoss: 139.404484\n",
      "Train Epoch: 113 [100000/697932 (14%)]\tLoss: 138.921969\n",
      "Train Epoch: 113 [200000/697932 (29%)]\tLoss: 139.552484\n",
      "Train Epoch: 113 [300000/697932 (43%)]\tLoss: 138.621109\n",
      "Train Epoch: 113 [400000/697932 (57%)]\tLoss: 139.876422\n",
      "Train Epoch: 113 [500000/697932 (72%)]\tLoss: 139.602797\n",
      "Train Epoch: 113 [600000/697932 (86%)]\tLoss: 138.500109\n",
      "====> Epoch: 113 Average loss: 139.2408\n",
      "====> Test set loss: 140.0742\n",
      "Train Epoch: 114 [0/697932 (0%)]\tLoss: 141.169859\n",
      "Train Epoch: 114 [100000/697932 (14%)]\tLoss: 141.555187\n",
      "Train Epoch: 114 [200000/697932 (29%)]\tLoss: 138.432094\n",
      "Train Epoch: 114 [300000/697932 (43%)]\tLoss: 139.469594\n",
      "Train Epoch: 114 [400000/697932 (57%)]\tLoss: 136.936203\n",
      "Train Epoch: 114 [500000/697932 (72%)]\tLoss: 139.442547\n",
      "Train Epoch: 114 [600000/697932 (86%)]\tLoss: 138.118625\n",
      "====> Epoch: 114 Average loss: 139.2417\n",
      "====> Test set loss: 140.0916\n",
      "Train Epoch: 115 [0/697932 (0%)]\tLoss: 140.071750\n",
      "Train Epoch: 115 [100000/697932 (14%)]\tLoss: 137.437266\n",
      "Train Epoch: 115 [200000/697932 (29%)]\tLoss: 139.791625\n",
      "Train Epoch: 115 [300000/697932 (43%)]\tLoss: 139.826734\n",
      "Train Epoch: 115 [400000/697932 (57%)]\tLoss: 139.061313\n",
      "Train Epoch: 115 [500000/697932 (72%)]\tLoss: 139.693813\n",
      "Train Epoch: 115 [600000/697932 (86%)]\tLoss: 139.232828\n",
      "====> Epoch: 115 Average loss: 139.2278\n",
      "====> Test set loss: 140.0779\n",
      "Train Epoch: 116 [0/697932 (0%)]\tLoss: 137.832687\n",
      "Train Epoch: 116 [100000/697932 (14%)]\tLoss: 139.049047\n",
      "Train Epoch: 116 [200000/697932 (29%)]\tLoss: 139.187984\n",
      "Train Epoch: 116 [300000/697932 (43%)]\tLoss: 139.695344\n",
      "Train Epoch: 116 [400000/697932 (57%)]\tLoss: 138.272906\n",
      "Train Epoch: 116 [500000/697932 (72%)]\tLoss: 140.264797\n",
      "Train Epoch: 116 [600000/697932 (86%)]\tLoss: 140.351531\n",
      "====> Epoch: 116 Average loss: 139.2179\n",
      "====> Test set loss: 140.1544\n",
      "Train Epoch: 117 [0/697932 (0%)]\tLoss: 141.584313\n",
      "Train Epoch: 117 [100000/697932 (14%)]\tLoss: 138.339953\n",
      "Train Epoch: 117 [200000/697932 (29%)]\tLoss: 141.382250\n",
      "Train Epoch: 117 [300000/697932 (43%)]\tLoss: 139.089203\n",
      "Train Epoch: 117 [400000/697932 (57%)]\tLoss: 138.480281\n",
      "Train Epoch: 117 [500000/697932 (72%)]\tLoss: 139.211984\n",
      "Train Epoch: 117 [600000/697932 (86%)]\tLoss: 140.489781\n",
      "====> Epoch: 117 Average loss: 139.1965\n",
      "====> Test set loss: 140.0300\n",
      "Train Epoch: 118 [0/697932 (0%)]\tLoss: 137.498406\n",
      "Train Epoch: 118 [100000/697932 (14%)]\tLoss: 140.639203\n",
      "Train Epoch: 118 [200000/697932 (29%)]\tLoss: 139.262125\n",
      "Train Epoch: 118 [300000/697932 (43%)]\tLoss: 139.345828\n",
      "Train Epoch: 118 [400000/697932 (57%)]\tLoss: 138.496797\n",
      "Train Epoch: 118 [500000/697932 (72%)]\tLoss: 138.340344\n",
      "Train Epoch: 118 [600000/697932 (86%)]\tLoss: 139.692969\n",
      "====> Epoch: 118 Average loss: 139.1949\n",
      "====> Test set loss: 140.0327\n",
      "Train Epoch: 119 [0/697932 (0%)]\tLoss: 141.281625\n",
      "Train Epoch: 119 [100000/697932 (14%)]\tLoss: 139.624484\n",
      "Train Epoch: 119 [200000/697932 (29%)]\tLoss: 141.351953\n",
      "Train Epoch: 119 [300000/697932 (43%)]\tLoss: 138.435188\n",
      "Train Epoch: 119 [400000/697932 (57%)]\tLoss: 139.838687\n",
      "Train Epoch: 119 [500000/697932 (72%)]\tLoss: 139.209125\n",
      "Train Epoch: 119 [600000/697932 (86%)]\tLoss: 139.282297\n",
      "====> Epoch: 119 Average loss: 139.1805\n",
      "====> Test set loss: 140.0774\n",
      "Train Epoch: 120 [0/697932 (0%)]\tLoss: 137.216250\n",
      "Train Epoch: 120 [100000/697932 (14%)]\tLoss: 140.094687\n",
      "Train Epoch: 120 [200000/697932 (29%)]\tLoss: 137.124516\n",
      "Train Epoch: 120 [300000/697932 (43%)]\tLoss: 139.059094\n",
      "Train Epoch: 120 [400000/697932 (57%)]\tLoss: 139.195359\n",
      "Train Epoch: 120 [500000/697932 (72%)]\tLoss: 139.130406\n",
      "Train Epoch: 120 [600000/697932 (86%)]\tLoss: 138.996281\n",
      "====> Epoch: 120 Average loss: 139.1522\n",
      "====> Test set loss: 140.2233\n",
      "Train Epoch: 121 [0/697932 (0%)]\tLoss: 137.996344\n",
      "Train Epoch: 121 [100000/697932 (14%)]\tLoss: 138.783469\n",
      "Train Epoch: 121 [200000/697932 (29%)]\tLoss: 139.220094\n",
      "Train Epoch: 121 [300000/697932 (43%)]\tLoss: 136.817406\n",
      "Train Epoch: 121 [400000/697932 (57%)]\tLoss: 141.095297\n",
      "Train Epoch: 121 [500000/697932 (72%)]\tLoss: 138.996234\n",
      "Train Epoch: 121 [600000/697932 (86%)]\tLoss: 138.857109\n",
      "====> Epoch: 121 Average loss: 139.1550\n",
      "====> Test set loss: 140.0032\n",
      "Train Epoch: 122 [0/697932 (0%)]\tLoss: 137.163813\n",
      "Train Epoch: 122 [100000/697932 (14%)]\tLoss: 139.564609\n",
      "Train Epoch: 122 [200000/697932 (29%)]\tLoss: 139.369297\n",
      "Train Epoch: 122 [300000/697932 (43%)]\tLoss: 137.800875\n",
      "Train Epoch: 122 [400000/697932 (57%)]\tLoss: 139.569250\n",
      "Train Epoch: 122 [500000/697932 (72%)]\tLoss: 139.875781\n",
      "Train Epoch: 122 [600000/697932 (86%)]\tLoss: 138.068859\n",
      "====> Epoch: 122 Average loss: 139.1369\n",
      "====> Test set loss: 140.0306\n",
      "Train Epoch: 123 [0/697932 (0%)]\tLoss: 139.030500\n",
      "Train Epoch: 123 [100000/697932 (14%)]\tLoss: 139.131781\n",
      "Train Epoch: 123 [200000/697932 (29%)]\tLoss: 140.505250\n",
      "Train Epoch: 123 [300000/697932 (43%)]\tLoss: 141.495531\n",
      "Train Epoch: 123 [400000/697932 (57%)]\tLoss: 140.476594\n",
      "Train Epoch: 123 [500000/697932 (72%)]\tLoss: 137.617656\n",
      "Train Epoch: 123 [600000/697932 (86%)]\tLoss: 137.417750\n",
      "====> Epoch: 123 Average loss: 139.1314\n",
      "====> Test set loss: 140.2630\n",
      "Train Epoch: 124 [0/697932 (0%)]\tLoss: 139.257828\n",
      "Train Epoch: 124 [100000/697932 (14%)]\tLoss: 139.775203\n",
      "Train Epoch: 124 [200000/697932 (29%)]\tLoss: 142.129844\n",
      "Train Epoch: 124 [300000/697932 (43%)]\tLoss: 139.130391\n",
      "Train Epoch: 124 [400000/697932 (57%)]\tLoss: 139.279875\n",
      "Train Epoch: 124 [500000/697932 (72%)]\tLoss: 138.186094\n",
      "Train Epoch: 124 [600000/697932 (86%)]\tLoss: 139.536578\n",
      "====> Epoch: 124 Average loss: 139.1231\n",
      "====> Test set loss: 139.9835\n",
      "Train Epoch: 125 [0/697932 (0%)]\tLoss: 137.613031\n",
      "Train Epoch: 125 [100000/697932 (14%)]\tLoss: 139.600063\n",
      "Train Epoch: 125 [200000/697932 (29%)]\tLoss: 138.380969\n",
      "Train Epoch: 125 [300000/697932 (43%)]\tLoss: 138.817781\n",
      "Train Epoch: 125 [400000/697932 (57%)]\tLoss: 138.501781\n",
      "Train Epoch: 125 [500000/697932 (72%)]\tLoss: 140.608047\n",
      "Train Epoch: 125 [600000/697932 (86%)]\tLoss: 137.460953\n",
      "====> Epoch: 125 Average loss: 139.1007\n",
      "====> Test set loss: 139.9879\n",
      "Train Epoch: 126 [0/697932 (0%)]\tLoss: 138.168906\n",
      "Train Epoch: 126 [100000/697932 (14%)]\tLoss: 139.312078\n",
      "Train Epoch: 126 [200000/697932 (29%)]\tLoss: 139.481125\n",
      "Train Epoch: 126 [300000/697932 (43%)]\tLoss: 139.533375\n",
      "Train Epoch: 126 [400000/697932 (57%)]\tLoss: 140.918969\n",
      "Train Epoch: 126 [500000/697932 (72%)]\tLoss: 140.701281\n",
      "Train Epoch: 126 [600000/697932 (86%)]\tLoss: 140.213469\n",
      "====> Epoch: 126 Average loss: 139.0958\n",
      "====> Test set loss: 140.0047\n",
      "Train Epoch: 127 [0/697932 (0%)]\tLoss: 138.873375\n",
      "Train Epoch: 127 [100000/697932 (14%)]\tLoss: 139.341938\n",
      "Train Epoch: 127 [200000/697932 (29%)]\tLoss: 138.049031\n",
      "Train Epoch: 127 [300000/697932 (43%)]\tLoss: 138.647375\n",
      "Train Epoch: 127 [400000/697932 (57%)]\tLoss: 138.437922\n",
      "Train Epoch: 127 [500000/697932 (72%)]\tLoss: 137.794594\n",
      "Train Epoch: 127 [600000/697932 (86%)]\tLoss: 139.314687\n",
      "====> Epoch: 127 Average loss: 139.0774\n",
      "====> Test set loss: 140.1301\n",
      "Train Epoch: 128 [0/697932 (0%)]\tLoss: 141.305250\n",
      "Train Epoch: 128 [100000/697932 (14%)]\tLoss: 139.140187\n",
      "Train Epoch: 128 [200000/697932 (29%)]\tLoss: 138.483438\n",
      "Train Epoch: 128 [300000/697932 (43%)]\tLoss: 137.967109\n",
      "Train Epoch: 128 [400000/697932 (57%)]\tLoss: 139.566172\n",
      "Train Epoch: 128 [500000/697932 (72%)]\tLoss: 138.943906\n",
      "Train Epoch: 128 [600000/697932 (86%)]\tLoss: 139.037781\n",
      "====> Epoch: 128 Average loss: 139.0730\n",
      "====> Test set loss: 140.1262\n",
      "Train Epoch: 129 [0/697932 (0%)]\tLoss: 140.210844\n",
      "Train Epoch: 129 [100000/697932 (14%)]\tLoss: 137.366031\n",
      "Train Epoch: 129 [200000/697932 (29%)]\tLoss: 139.775281\n",
      "Train Epoch: 129 [300000/697932 (43%)]\tLoss: 138.333391\n",
      "Train Epoch: 129 [400000/697932 (57%)]\tLoss: 141.146000\n",
      "Train Epoch: 129 [500000/697932 (72%)]\tLoss: 139.801844\n",
      "Train Epoch: 129 [600000/697932 (86%)]\tLoss: 139.387156\n",
      "====> Epoch: 129 Average loss: 139.0716\n",
      "====> Test set loss: 139.9894\n",
      "Train Epoch: 130 [0/697932 (0%)]\tLoss: 141.220844\n",
      "Train Epoch: 130 [100000/697932 (14%)]\tLoss: 139.751922\n",
      "Train Epoch: 130 [200000/697932 (29%)]\tLoss: 139.005313\n",
      "Train Epoch: 130 [300000/697932 (43%)]\tLoss: 139.700750\n",
      "Train Epoch: 130 [400000/697932 (57%)]\tLoss: 140.733203\n",
      "Train Epoch: 130 [500000/697932 (72%)]\tLoss: 139.130234\n",
      "Train Epoch: 130 [600000/697932 (86%)]\tLoss: 139.551063\n",
      "====> Epoch: 130 Average loss: 139.0554\n",
      "====> Test set loss: 140.0510\n",
      "Train Epoch: 131 [0/697932 (0%)]\tLoss: 136.328594\n",
      "Train Epoch: 131 [100000/697932 (14%)]\tLoss: 138.402813\n",
      "Train Epoch: 131 [200000/697932 (29%)]\tLoss: 138.506125\n",
      "Train Epoch: 131 [300000/697932 (43%)]\tLoss: 139.084750\n",
      "Train Epoch: 131 [400000/697932 (57%)]\tLoss: 138.157703\n",
      "Train Epoch: 131 [500000/697932 (72%)]\tLoss: 138.245625\n",
      "Train Epoch: 131 [600000/697932 (86%)]\tLoss: 140.226797\n",
      "====> Epoch: 131 Average loss: 139.0434\n",
      "====> Test set loss: 140.1142\n",
      "Train Epoch: 132 [0/697932 (0%)]\tLoss: 138.863531\n",
      "Train Epoch: 132 [100000/697932 (14%)]\tLoss: 139.191172\n",
      "Train Epoch: 132 [200000/697932 (29%)]\tLoss: 137.463875\n",
      "Train Epoch: 132 [300000/697932 (43%)]\tLoss: 138.792016\n",
      "Train Epoch: 132 [400000/697932 (57%)]\tLoss: 137.034984\n",
      "Train Epoch: 132 [500000/697932 (72%)]\tLoss: 141.342875\n",
      "Train Epoch: 132 [600000/697932 (86%)]\tLoss: 138.157859\n",
      "====> Epoch: 132 Average loss: 139.0294\n",
      "====> Test set loss: 139.9316\n",
      "Train Epoch: 133 [0/697932 (0%)]\tLoss: 139.967047\n",
      "Train Epoch: 133 [100000/697932 (14%)]\tLoss: 139.952922\n",
      "Train Epoch: 133 [200000/697932 (29%)]\tLoss: 138.321703\n",
      "Train Epoch: 133 [300000/697932 (43%)]\tLoss: 139.363250\n",
      "Train Epoch: 133 [400000/697932 (57%)]\tLoss: 139.271094\n",
      "Train Epoch: 133 [500000/697932 (72%)]\tLoss: 138.158500\n",
      "Train Epoch: 133 [600000/697932 (86%)]\tLoss: 138.972109\n",
      "====> Epoch: 133 Average loss: 139.0301\n",
      "====> Test set loss: 139.8914\n",
      "Train Epoch: 134 [0/697932 (0%)]\tLoss: 139.183375\n",
      "Train Epoch: 134 [100000/697932 (14%)]\tLoss: 139.396531\n",
      "Train Epoch: 134 [200000/697932 (29%)]\tLoss: 136.726609\n",
      "Train Epoch: 134 [300000/697932 (43%)]\tLoss: 140.251625\n",
      "Train Epoch: 134 [400000/697932 (57%)]\tLoss: 140.534188\n",
      "Train Epoch: 134 [500000/697932 (72%)]\tLoss: 140.902031\n",
      "Train Epoch: 134 [600000/697932 (86%)]\tLoss: 140.471969\n",
      "====> Epoch: 134 Average loss: 139.0045\n",
      "====> Test set loss: 139.9363\n",
      "Train Epoch: 135 [0/697932 (0%)]\tLoss: 138.326000\n",
      "Train Epoch: 135 [100000/697932 (14%)]\tLoss: 142.361312\n",
      "Train Epoch: 135 [200000/697932 (29%)]\tLoss: 140.668297\n",
      "Train Epoch: 135 [300000/697932 (43%)]\tLoss: 138.819750\n",
      "Train Epoch: 135 [400000/697932 (57%)]\tLoss: 138.880063\n",
      "Train Epoch: 135 [500000/697932 (72%)]\tLoss: 139.739141\n",
      "Train Epoch: 135 [600000/697932 (86%)]\tLoss: 139.870828\n",
      "====> Epoch: 135 Average loss: 139.0042\n",
      "====> Test set loss: 140.0046\n",
      "Train Epoch: 136 [0/697932 (0%)]\tLoss: 139.615453\n",
      "Train Epoch: 136 [100000/697932 (14%)]\tLoss: 138.218453\n",
      "Train Epoch: 136 [200000/697932 (29%)]\tLoss: 137.466344\n",
      "Train Epoch: 136 [300000/697932 (43%)]\tLoss: 139.343594\n",
      "Train Epoch: 136 [400000/697932 (57%)]\tLoss: 139.453281\n",
      "Train Epoch: 136 [500000/697932 (72%)]\tLoss: 137.498547\n",
      "Train Epoch: 136 [600000/697932 (86%)]\tLoss: 138.627969\n",
      "====> Epoch: 136 Average loss: 139.0034\n",
      "====> Test set loss: 139.9357\n",
      "Train Epoch: 137 [0/697932 (0%)]\tLoss: 138.760078\n",
      "Train Epoch: 137 [100000/697932 (14%)]\tLoss: 137.007266\n",
      "Train Epoch: 137 [200000/697932 (29%)]\tLoss: 138.294453\n",
      "Train Epoch: 137 [300000/697932 (43%)]\tLoss: 139.705609\n",
      "Train Epoch: 137 [400000/697932 (57%)]\tLoss: 140.381906\n",
      "Train Epoch: 137 [500000/697932 (72%)]\tLoss: 139.849719\n",
      "Train Epoch: 137 [600000/697932 (86%)]\tLoss: 136.884875\n",
      "====> Epoch: 137 Average loss: 138.9893\n",
      "====> Test set loss: 139.8354\n",
      "Train Epoch: 138 [0/697932 (0%)]\tLoss: 138.266141\n",
      "Train Epoch: 138 [100000/697932 (14%)]\tLoss: 138.983453\n",
      "Train Epoch: 138 [200000/697932 (29%)]\tLoss: 139.359281\n",
      "Train Epoch: 138 [300000/697932 (43%)]\tLoss: 138.464250\n",
      "Train Epoch: 138 [400000/697932 (57%)]\tLoss: 138.758250\n",
      "Train Epoch: 138 [500000/697932 (72%)]\tLoss: 137.768219\n",
      "Train Epoch: 138 [600000/697932 (86%)]\tLoss: 141.255703\n",
      "====> Epoch: 138 Average loss: 138.9681\n",
      "====> Test set loss: 139.9971\n",
      "Train Epoch: 139 [0/697932 (0%)]\tLoss: 139.341969\n",
      "Train Epoch: 139 [100000/697932 (14%)]\tLoss: 140.040766\n",
      "Train Epoch: 139 [200000/697932 (29%)]\tLoss: 138.815891\n",
      "Train Epoch: 139 [300000/697932 (43%)]\tLoss: 138.507094\n",
      "Train Epoch: 139 [400000/697932 (57%)]\tLoss: 138.422344\n",
      "Train Epoch: 139 [500000/697932 (72%)]\tLoss: 139.884187\n",
      "Train Epoch: 139 [600000/697932 (86%)]\tLoss: 136.820781\n",
      "====> Epoch: 139 Average loss: 138.9789\n",
      "====> Test set loss: 139.8177\n",
      "Train Epoch: 140 [0/697932 (0%)]\tLoss: 138.981344\n",
      "Train Epoch: 140 [100000/697932 (14%)]\tLoss: 138.781234\n",
      "Train Epoch: 140 [200000/697932 (29%)]\tLoss: 139.073859\n",
      "Train Epoch: 140 [300000/697932 (43%)]\tLoss: 138.724234\n",
      "Train Epoch: 140 [400000/697932 (57%)]\tLoss: 139.626750\n",
      "Train Epoch: 140 [500000/697932 (72%)]\tLoss: 139.926203\n",
      "Train Epoch: 140 [600000/697932 (86%)]\tLoss: 138.559313\n",
      "====> Epoch: 140 Average loss: 138.9400\n",
      "====> Test set loss: 139.9075\n",
      "Train Epoch: 141 [0/697932 (0%)]\tLoss: 138.421516\n",
      "Train Epoch: 141 [100000/697932 (14%)]\tLoss: 139.735281\n",
      "Train Epoch: 141 [200000/697932 (29%)]\tLoss: 136.175187\n",
      "Train Epoch: 141 [300000/697932 (43%)]\tLoss: 137.488516\n",
      "Train Epoch: 141 [400000/697932 (57%)]\tLoss: 139.652062\n",
      "Train Epoch: 141 [500000/697932 (72%)]\tLoss: 140.411281\n",
      "Train Epoch: 141 [600000/697932 (86%)]\tLoss: 137.503625\n",
      "====> Epoch: 141 Average loss: 138.9389\n",
      "====> Test set loss: 139.8568\n",
      "Train Epoch: 142 [0/697932 (0%)]\tLoss: 138.021281\n",
      "Train Epoch: 142 [100000/697932 (14%)]\tLoss: 137.344906\n",
      "Train Epoch: 142 [200000/697932 (29%)]\tLoss: 140.424609\n",
      "Train Epoch: 142 [300000/697932 (43%)]\tLoss: 139.534500\n",
      "Train Epoch: 142 [400000/697932 (57%)]\tLoss: 139.740781\n",
      "Train Epoch: 142 [500000/697932 (72%)]\tLoss: 138.054516\n",
      "Train Epoch: 142 [600000/697932 (86%)]\tLoss: 139.300594\n",
      "====> Epoch: 142 Average loss: 138.9437\n",
      "====> Test set loss: 139.8484\n",
      "Train Epoch: 143 [0/697932 (0%)]\tLoss: 138.092578\n",
      "Train Epoch: 143 [100000/697932 (14%)]\tLoss: 137.904188\n",
      "Train Epoch: 143 [200000/697932 (29%)]\tLoss: 140.459594\n",
      "Train Epoch: 143 [300000/697932 (43%)]\tLoss: 140.143484\n",
      "Train Epoch: 143 [400000/697932 (57%)]\tLoss: 138.557922\n",
      "Train Epoch: 143 [500000/697932 (72%)]\tLoss: 137.999188\n",
      "Train Epoch: 143 [600000/697932 (86%)]\tLoss: 137.730406\n",
      "====> Epoch: 143 Average loss: 138.9275\n",
      "====> Test set loss: 139.9385\n",
      "Train Epoch: 144 [0/697932 (0%)]\tLoss: 137.600750\n",
      "Train Epoch: 144 [100000/697932 (14%)]\tLoss: 139.467156\n",
      "Train Epoch: 144 [200000/697932 (29%)]\tLoss: 139.865813\n",
      "Train Epoch: 144 [300000/697932 (43%)]\tLoss: 139.428594\n",
      "Train Epoch: 144 [400000/697932 (57%)]\tLoss: 140.304375\n",
      "Train Epoch: 144 [500000/697932 (72%)]\tLoss: 138.157938\n",
      "Train Epoch: 144 [600000/697932 (86%)]\tLoss: 137.482203\n",
      "====> Epoch: 144 Average loss: 138.9256\n",
      "====> Test set loss: 139.8930\n",
      "Train Epoch: 145 [0/697932 (0%)]\tLoss: 138.927344\n",
      "Train Epoch: 145 [100000/697932 (14%)]\tLoss: 139.206500\n",
      "Train Epoch: 145 [200000/697932 (29%)]\tLoss: 141.159000\n",
      "Train Epoch: 145 [300000/697932 (43%)]\tLoss: 137.788234\n",
      "Train Epoch: 145 [400000/697932 (57%)]\tLoss: 139.547063\n",
      "Train Epoch: 145 [500000/697932 (72%)]\tLoss: 139.685188\n",
      "Train Epoch: 145 [600000/697932 (86%)]\tLoss: 139.405687\n",
      "====> Epoch: 145 Average loss: 138.8985\n",
      "====> Test set loss: 139.8125\n",
      "Train Epoch: 146 [0/697932 (0%)]\tLoss: 135.214031\n",
      "Train Epoch: 146 [100000/697932 (14%)]\tLoss: 138.723719\n",
      "Train Epoch: 146 [200000/697932 (29%)]\tLoss: 138.400750\n",
      "Train Epoch: 146 [300000/697932 (43%)]\tLoss: 139.074672\n",
      "Train Epoch: 146 [400000/697932 (57%)]\tLoss: 139.425875\n",
      "Train Epoch: 146 [500000/697932 (72%)]\tLoss: 138.514219\n",
      "Train Epoch: 146 [600000/697932 (86%)]\tLoss: 138.492719\n",
      "====> Epoch: 146 Average loss: 138.8866\n",
      "====> Test set loss: 139.8146\n",
      "Train Epoch: 147 [0/697932 (0%)]\tLoss: 138.823688\n",
      "Train Epoch: 147 [100000/697932 (14%)]\tLoss: 138.686469\n",
      "Train Epoch: 147 [200000/697932 (29%)]\tLoss: 137.684719\n",
      "Train Epoch: 147 [300000/697932 (43%)]\tLoss: 139.106594\n",
      "Train Epoch: 147 [400000/697932 (57%)]\tLoss: 136.867781\n",
      "Train Epoch: 147 [500000/697932 (72%)]\tLoss: 140.365234\n",
      "Train Epoch: 147 [600000/697932 (86%)]\tLoss: 140.114313\n",
      "====> Epoch: 147 Average loss: 138.8945\n",
      "====> Test set loss: 139.8347\n",
      "Train Epoch: 148 [0/697932 (0%)]\tLoss: 137.760844\n",
      "Train Epoch: 148 [100000/697932 (14%)]\tLoss: 139.662469\n",
      "Train Epoch: 148 [200000/697932 (29%)]\tLoss: 137.646187\n",
      "Train Epoch: 148 [300000/697932 (43%)]\tLoss: 139.599375\n",
      "Train Epoch: 148 [400000/697932 (57%)]\tLoss: 139.928438\n",
      "Train Epoch: 148 [500000/697932 (72%)]\tLoss: 138.295031\n",
      "Train Epoch: 148 [600000/697932 (86%)]\tLoss: 138.508828\n",
      "====> Epoch: 148 Average loss: 138.8805\n",
      "====> Test set loss: 139.7951\n",
      "Train Epoch: 149 [0/697932 (0%)]\tLoss: 138.169375\n",
      "Train Epoch: 149 [100000/697932 (14%)]\tLoss: 137.852250\n",
      "Train Epoch: 149 [200000/697932 (29%)]\tLoss: 138.077766\n",
      "Train Epoch: 149 [300000/697932 (43%)]\tLoss: 139.376484\n",
      "Train Epoch: 149 [400000/697932 (57%)]\tLoss: 138.512937\n",
      "Train Epoch: 149 [500000/697932 (72%)]\tLoss: 140.312359\n",
      "Train Epoch: 149 [600000/697932 (86%)]\tLoss: 135.795531\n",
      "====> Epoch: 149 Average loss: 138.8785\n",
      "====> Test set loss: 139.7870\n",
      "Train Epoch: 150 [0/697932 (0%)]\tLoss: 140.640797\n",
      "Train Epoch: 150 [100000/697932 (14%)]\tLoss: 141.355516\n",
      "Train Epoch: 150 [200000/697932 (29%)]\tLoss: 141.327500\n",
      "Train Epoch: 150 [300000/697932 (43%)]\tLoss: 139.248984\n",
      "Train Epoch: 150 [400000/697932 (57%)]\tLoss: 136.701734\n",
      "Train Epoch: 150 [500000/697932 (72%)]\tLoss: 139.640062\n",
      "Train Epoch: 150 [600000/697932 (86%)]\tLoss: 139.484531\n",
      "====> Epoch: 150 Average loss: 138.8734\n",
      "====> Test set loss: 139.8222\n",
      "Train Epoch: 151 [0/697932 (0%)]\tLoss: 140.249156\n",
      "Train Epoch: 151 [100000/697932 (14%)]\tLoss: 139.217437\n",
      "Train Epoch: 151 [200000/697932 (29%)]\tLoss: 139.157406\n",
      "Train Epoch: 151 [300000/697932 (43%)]\tLoss: 138.204813\n",
      "Train Epoch: 151 [400000/697932 (57%)]\tLoss: 139.202500\n",
      "Train Epoch: 151 [500000/697932 (72%)]\tLoss: 140.106875\n",
      "Train Epoch: 151 [600000/697932 (86%)]\tLoss: 140.004359\n",
      "====> Epoch: 151 Average loss: 138.8510\n",
      "====> Test set loss: 140.0121\n",
      "Train Epoch: 152 [0/697932 (0%)]\tLoss: 138.335250\n",
      "Train Epoch: 152 [100000/697932 (14%)]\tLoss: 139.209859\n",
      "Train Epoch: 152 [200000/697932 (29%)]\tLoss: 141.450172\n",
      "Train Epoch: 152 [300000/697932 (43%)]\tLoss: 138.248391\n",
      "Train Epoch: 152 [400000/697932 (57%)]\tLoss: 139.799984\n",
      "Train Epoch: 152 [500000/697932 (72%)]\tLoss: 138.286219\n",
      "Train Epoch: 152 [600000/697932 (86%)]\tLoss: 140.143203\n",
      "====> Epoch: 152 Average loss: 138.8457\n",
      "====> Test set loss: 139.8179\n",
      "Train Epoch: 153 [0/697932 (0%)]\tLoss: 140.937219\n",
      "Train Epoch: 153 [100000/697932 (14%)]\tLoss: 137.689281\n",
      "Train Epoch: 153 [200000/697932 (29%)]\tLoss: 140.091172\n",
      "Train Epoch: 153 [300000/697932 (43%)]\tLoss: 140.104922\n",
      "Train Epoch: 153 [400000/697932 (57%)]\tLoss: 139.838125\n",
      "Train Epoch: 153 [500000/697932 (72%)]\tLoss: 139.132500\n",
      "Train Epoch: 153 [600000/697932 (86%)]\tLoss: 137.711375\n",
      "====> Epoch: 153 Average loss: 138.8220\n",
      "====> Test set loss: 139.6895\n",
      "Train Epoch: 154 [0/697932 (0%)]\tLoss: 138.751156\n",
      "Train Epoch: 154 [100000/697932 (14%)]\tLoss: 138.339750\n",
      "Train Epoch: 154 [200000/697932 (29%)]\tLoss: 140.349594\n",
      "Train Epoch: 154 [300000/697932 (43%)]\tLoss: 137.506078\n",
      "Train Epoch: 154 [400000/697932 (57%)]\tLoss: 140.489266\n",
      "Train Epoch: 154 [500000/697932 (72%)]\tLoss: 136.954906\n",
      "Train Epoch: 154 [600000/697932 (86%)]\tLoss: 137.619000\n",
      "====> Epoch: 154 Average loss: 138.8376\n",
      "====> Test set loss: 139.7898\n",
      "Train Epoch: 155 [0/697932 (0%)]\tLoss: 138.007250\n",
      "Train Epoch: 155 [100000/697932 (14%)]\tLoss: 136.286469\n",
      "Train Epoch: 155 [200000/697932 (29%)]\tLoss: 138.809391\n",
      "Train Epoch: 155 [300000/697932 (43%)]\tLoss: 137.683234\n",
      "Train Epoch: 155 [400000/697932 (57%)]\tLoss: 138.403875\n",
      "Train Epoch: 155 [500000/697932 (72%)]\tLoss: 137.886016\n",
      "Train Epoch: 155 [600000/697932 (86%)]\tLoss: 140.078781\n",
      "====> Epoch: 155 Average loss: 138.8277\n",
      "====> Test set loss: 139.8836\n",
      "Train Epoch: 156 [0/697932 (0%)]\tLoss: 139.989812\n",
      "Train Epoch: 156 [100000/697932 (14%)]\tLoss: 138.075719\n",
      "Train Epoch: 156 [200000/697932 (29%)]\tLoss: 139.047922\n",
      "Train Epoch: 156 [300000/697932 (43%)]\tLoss: 138.250937\n",
      "Train Epoch: 156 [400000/697932 (57%)]\tLoss: 139.933781\n",
      "Train Epoch: 156 [500000/697932 (72%)]\tLoss: 137.536422\n",
      "Train Epoch: 156 [600000/697932 (86%)]\tLoss: 139.744281\n",
      "====> Epoch: 156 Average loss: 138.8190\n",
      "====> Test set loss: 139.7205\n",
      "Train Epoch: 157 [0/697932 (0%)]\tLoss: 140.236938\n",
      "Train Epoch: 157 [100000/697932 (14%)]\tLoss: 138.941406\n",
      "Train Epoch: 157 [200000/697932 (29%)]\tLoss: 139.271813\n",
      "Train Epoch: 157 [300000/697932 (43%)]\tLoss: 139.210156\n",
      "Train Epoch: 157 [400000/697932 (57%)]\tLoss: 139.888469\n",
      "Train Epoch: 157 [500000/697932 (72%)]\tLoss: 138.618422\n",
      "Train Epoch: 157 [600000/697932 (86%)]\tLoss: 138.319219\n",
      "====> Epoch: 157 Average loss: 138.8222\n",
      "====> Test set loss: 139.9352\n",
      "Train Epoch: 158 [0/697932 (0%)]\tLoss: 140.167062\n",
      "Train Epoch: 158 [100000/697932 (14%)]\tLoss: 140.533750\n",
      "Train Epoch: 158 [200000/697932 (29%)]\tLoss: 139.851172\n",
      "Train Epoch: 158 [300000/697932 (43%)]\tLoss: 139.691984\n",
      "Train Epoch: 158 [400000/697932 (57%)]\tLoss: 140.241953\n",
      "Train Epoch: 158 [500000/697932 (72%)]\tLoss: 137.880500\n",
      "Train Epoch: 158 [600000/697932 (86%)]\tLoss: 139.123500\n",
      "====> Epoch: 158 Average loss: 138.7959\n",
      "====> Test set loss: 139.7297\n",
      "Train Epoch: 159 [0/697932 (0%)]\tLoss: 139.887844\n",
      "Train Epoch: 159 [100000/697932 (14%)]\tLoss: 139.340250\n",
      "Train Epoch: 159 [200000/697932 (29%)]\tLoss: 140.238234\n",
      "Train Epoch: 159 [300000/697932 (43%)]\tLoss: 138.606906\n",
      "Train Epoch: 159 [400000/697932 (57%)]\tLoss: 140.206813\n",
      "Train Epoch: 159 [500000/697932 (72%)]\tLoss: 139.870688\n",
      "Train Epoch: 159 [600000/697932 (86%)]\tLoss: 138.622031\n",
      "====> Epoch: 159 Average loss: 138.7840\n",
      "====> Test set loss: 139.7091\n",
      "Train Epoch: 160 [0/697932 (0%)]\tLoss: 138.448406\n",
      "Train Epoch: 160 [100000/697932 (14%)]\tLoss: 138.039437\n",
      "Train Epoch: 160 [200000/697932 (29%)]\tLoss: 138.095562\n",
      "Train Epoch: 160 [300000/697932 (43%)]\tLoss: 137.683453\n",
      "Train Epoch: 160 [400000/697932 (57%)]\tLoss: 139.496359\n",
      "Train Epoch: 160 [500000/697932 (72%)]\tLoss: 138.756578\n",
      "Train Epoch: 160 [600000/697932 (86%)]\tLoss: 140.672734\n",
      "====> Epoch: 160 Average loss: 138.7880\n",
      "====> Test set loss: 139.7197\n",
      "Train Epoch: 161 [0/697932 (0%)]\tLoss: 138.614609\n",
      "Train Epoch: 161 [100000/697932 (14%)]\tLoss: 139.452859\n",
      "Train Epoch: 161 [200000/697932 (29%)]\tLoss: 138.887750\n",
      "Train Epoch: 161 [300000/697932 (43%)]\tLoss: 139.214172\n",
      "Train Epoch: 161 [400000/697932 (57%)]\tLoss: 140.959172\n",
      "Train Epoch: 161 [500000/697932 (72%)]\tLoss: 139.053000\n",
      "Train Epoch: 161 [600000/697932 (86%)]\tLoss: 138.651187\n",
      "====> Epoch: 161 Average loss: 138.7837\n",
      "====> Test set loss: 139.7602\n",
      "Train Epoch: 162 [0/697932 (0%)]\tLoss: 137.471781\n",
      "Train Epoch: 162 [100000/697932 (14%)]\tLoss: 140.028781\n",
      "Train Epoch: 162 [200000/697932 (29%)]\tLoss: 138.938250\n",
      "Train Epoch: 162 [300000/697932 (43%)]\tLoss: 137.277047\n",
      "Train Epoch: 162 [400000/697932 (57%)]\tLoss: 136.935062\n",
      "Train Epoch: 162 [500000/697932 (72%)]\tLoss: 139.163281\n",
      "Train Epoch: 162 [600000/697932 (86%)]\tLoss: 135.724219\n",
      "====> Epoch: 162 Average loss: 138.7680\n",
      "====> Test set loss: 139.8572\n",
      "Train Epoch: 163 [0/697932 (0%)]\tLoss: 137.456437\n",
      "Train Epoch: 163 [100000/697932 (14%)]\tLoss: 137.125531\n",
      "Train Epoch: 163 [200000/697932 (29%)]\tLoss: 138.204312\n",
      "Train Epoch: 163 [300000/697932 (43%)]\tLoss: 138.407750\n",
      "Train Epoch: 163 [400000/697932 (57%)]\tLoss: 136.662813\n",
      "Train Epoch: 163 [500000/697932 (72%)]\tLoss: 139.101125\n",
      "Train Epoch: 163 [600000/697932 (86%)]\tLoss: 140.883156\n",
      "====> Epoch: 163 Average loss: 138.7702\n",
      "====> Test set loss: 139.6989\n",
      "Train Epoch: 164 [0/697932 (0%)]\tLoss: 138.520656\n",
      "Train Epoch: 164 [100000/697932 (14%)]\tLoss: 136.753828\n",
      "Train Epoch: 164 [200000/697932 (29%)]\tLoss: 137.754422\n",
      "Train Epoch: 164 [300000/697932 (43%)]\tLoss: 137.449484\n",
      "Train Epoch: 164 [400000/697932 (57%)]\tLoss: 139.954312\n",
      "Train Epoch: 164 [500000/697932 (72%)]\tLoss: 139.761687\n",
      "Train Epoch: 164 [600000/697932 (86%)]\tLoss: 137.112344\n",
      "====> Epoch: 164 Average loss: 138.7530\n",
      "====> Test set loss: 139.8720\n",
      "Train Epoch: 165 [0/697932 (0%)]\tLoss: 140.275891\n",
      "Train Epoch: 165 [100000/697932 (14%)]\tLoss: 140.371484\n",
      "Train Epoch: 165 [200000/697932 (29%)]\tLoss: 137.849562\n",
      "Train Epoch: 165 [300000/697932 (43%)]\tLoss: 138.714344\n",
      "Train Epoch: 165 [400000/697932 (57%)]\tLoss: 138.448453\n",
      "Train Epoch: 165 [500000/697932 (72%)]\tLoss: 137.126500\n",
      "Train Epoch: 165 [600000/697932 (86%)]\tLoss: 137.515953\n",
      "====> Epoch: 165 Average loss: 138.7466\n",
      "====> Test set loss: 139.7942\n",
      "Train Epoch: 166 [0/697932 (0%)]\tLoss: 139.053828\n",
      "Train Epoch: 166 [100000/697932 (14%)]\tLoss: 139.981016\n",
      "Train Epoch: 166 [200000/697932 (29%)]\tLoss: 134.961062\n",
      "Train Epoch: 166 [300000/697932 (43%)]\tLoss: 140.088031\n",
      "Train Epoch: 166 [400000/697932 (57%)]\tLoss: 138.252891\n",
      "Train Epoch: 166 [500000/697932 (72%)]\tLoss: 137.547031\n",
      "Train Epoch: 166 [600000/697932 (86%)]\tLoss: 137.991984\n",
      "====> Epoch: 166 Average loss: 138.7358\n",
      "====> Test set loss: 139.6539\n",
      "Train Epoch: 167 [0/697932 (0%)]\tLoss: 136.206562\n",
      "Train Epoch: 167 [100000/697932 (14%)]\tLoss: 138.689344\n",
      "Train Epoch: 167 [200000/697932 (29%)]\tLoss: 138.575187\n",
      "Train Epoch: 167 [300000/697932 (43%)]\tLoss: 138.883047\n",
      "Train Epoch: 167 [400000/697932 (57%)]\tLoss: 140.826250\n",
      "Train Epoch: 167 [500000/697932 (72%)]\tLoss: 137.646953\n",
      "Train Epoch: 167 [600000/697932 (86%)]\tLoss: 137.446047\n",
      "====> Epoch: 167 Average loss: 138.7282\n",
      "====> Test set loss: 139.7198\n",
      "Train Epoch: 168 [0/697932 (0%)]\tLoss: 139.659906\n",
      "Train Epoch: 168 [100000/697932 (14%)]\tLoss: 139.078234\n",
      "Train Epoch: 168 [200000/697932 (29%)]\tLoss: 139.669797\n",
      "Train Epoch: 168 [300000/697932 (43%)]\tLoss: 140.362953\n",
      "Train Epoch: 168 [400000/697932 (57%)]\tLoss: 140.969719\n",
      "Train Epoch: 168 [500000/697932 (72%)]\tLoss: 137.845047\n",
      "Train Epoch: 168 [600000/697932 (86%)]\tLoss: 137.956375\n",
      "====> Epoch: 168 Average loss: 138.7336\n",
      "====> Test set loss: 139.7298\n",
      "Train Epoch: 169 [0/697932 (0%)]\tLoss: 139.303937\n",
      "Train Epoch: 169 [100000/697932 (14%)]\tLoss: 139.971609\n",
      "Train Epoch: 169 [200000/697932 (29%)]\tLoss: 139.371422\n",
      "Train Epoch: 169 [300000/697932 (43%)]\tLoss: 139.538750\n",
      "Train Epoch: 169 [400000/697932 (57%)]\tLoss: 138.315391\n",
      "Train Epoch: 169 [500000/697932 (72%)]\tLoss: 140.066594\n",
      "Train Epoch: 169 [600000/697932 (86%)]\tLoss: 136.378000\n",
      "====> Epoch: 169 Average loss: 138.7288\n",
      "====> Test set loss: 139.6418\n",
      "Train Epoch: 170 [0/697932 (0%)]\tLoss: 135.801219\n",
      "Train Epoch: 170 [100000/697932 (14%)]\tLoss: 139.799062\n",
      "Train Epoch: 170 [200000/697932 (29%)]\tLoss: 141.730984\n",
      "Train Epoch: 170 [300000/697932 (43%)]\tLoss: 136.417469\n",
      "Train Epoch: 170 [400000/697932 (57%)]\tLoss: 139.787328\n",
      "Train Epoch: 170 [500000/697932 (72%)]\tLoss: 138.220375\n",
      "Train Epoch: 170 [600000/697932 (86%)]\tLoss: 138.395516\n",
      "====> Epoch: 170 Average loss: 138.7156\n",
      "====> Test set loss: 139.6617\n",
      "Train Epoch: 171 [0/697932 (0%)]\tLoss: 137.716062\n",
      "Train Epoch: 171 [100000/697932 (14%)]\tLoss: 139.682344\n",
      "Train Epoch: 171 [200000/697932 (29%)]\tLoss: 137.541094\n",
      "Train Epoch: 171 [300000/697932 (43%)]\tLoss: 140.973750\n",
      "Train Epoch: 171 [400000/697932 (57%)]\tLoss: 138.980953\n",
      "Train Epoch: 171 [500000/697932 (72%)]\tLoss: 139.065422\n",
      "Train Epoch: 171 [600000/697932 (86%)]\tLoss: 139.800609\n",
      "====> Epoch: 171 Average loss: 138.7198\n",
      "====> Test set loss: 139.6253\n",
      "Train Epoch: 172 [0/697932 (0%)]\tLoss: 136.718391\n",
      "Train Epoch: 172 [100000/697932 (14%)]\tLoss: 138.452250\n",
      "Train Epoch: 172 [200000/697932 (29%)]\tLoss: 137.568563\n",
      "Train Epoch: 172 [300000/697932 (43%)]\tLoss: 140.404922\n",
      "Train Epoch: 172 [400000/697932 (57%)]\tLoss: 138.841031\n",
      "Train Epoch: 172 [500000/697932 (72%)]\tLoss: 137.927812\n",
      "Train Epoch: 172 [600000/697932 (86%)]\tLoss: 136.594219\n",
      "====> Epoch: 172 Average loss: 138.6943\n",
      "====> Test set loss: 139.6476\n",
      "Train Epoch: 173 [0/697932 (0%)]\tLoss: 138.257375\n",
      "Train Epoch: 173 [100000/697932 (14%)]\tLoss: 136.116109\n",
      "Train Epoch: 173 [200000/697932 (29%)]\tLoss: 139.386281\n",
      "Train Epoch: 173 [300000/697932 (43%)]\tLoss: 139.320547\n",
      "Train Epoch: 173 [400000/697932 (57%)]\tLoss: 140.613125\n",
      "Train Epoch: 173 [500000/697932 (72%)]\tLoss: 138.857625\n",
      "Train Epoch: 173 [600000/697932 (86%)]\tLoss: 137.998297\n",
      "====> Epoch: 173 Average loss: 138.6988\n",
      "====> Test set loss: 139.6769\n",
      "Train Epoch: 174 [0/697932 (0%)]\tLoss: 139.388141\n",
      "Train Epoch: 174 [100000/697932 (14%)]\tLoss: 137.572172\n",
      "Train Epoch: 174 [200000/697932 (29%)]\tLoss: 140.938000\n",
      "Train Epoch: 174 [300000/697932 (43%)]\tLoss: 139.450969\n",
      "Train Epoch: 174 [400000/697932 (57%)]\tLoss: 139.150156\n",
      "Train Epoch: 174 [500000/697932 (72%)]\tLoss: 138.626906\n",
      "Train Epoch: 174 [600000/697932 (86%)]\tLoss: 138.942641\n",
      "====> Epoch: 174 Average loss: 138.6787\n",
      "====> Test set loss: 139.7120\n",
      "Train Epoch: 175 [0/697932 (0%)]\tLoss: 137.877859\n",
      "Train Epoch: 175 [100000/697932 (14%)]\tLoss: 138.404344\n",
      "Train Epoch: 175 [200000/697932 (29%)]\tLoss: 136.639516\n",
      "Train Epoch: 175 [300000/697932 (43%)]\tLoss: 137.530344\n",
      "Train Epoch: 175 [400000/697932 (57%)]\tLoss: 138.420500\n",
      "Train Epoch: 175 [500000/697932 (72%)]\tLoss: 140.667891\n",
      "Train Epoch: 175 [600000/697932 (86%)]\tLoss: 140.825938\n",
      "====> Epoch: 175 Average loss: 138.6856\n",
      "====> Test set loss: 139.7663\n",
      "Train Epoch: 176 [0/697932 (0%)]\tLoss: 137.591516\n",
      "Train Epoch: 176 [100000/697932 (14%)]\tLoss: 139.622547\n",
      "Train Epoch: 176 [200000/697932 (29%)]\tLoss: 138.067781\n",
      "Train Epoch: 176 [300000/697932 (43%)]\tLoss: 134.839063\n",
      "Train Epoch: 176 [400000/697932 (57%)]\tLoss: 138.573844\n",
      "Train Epoch: 176 [500000/697932 (72%)]\tLoss: 141.511703\n",
      "Train Epoch: 176 [600000/697932 (86%)]\tLoss: 139.121219\n",
      "====> Epoch: 176 Average loss: 138.6849\n",
      "====> Test set loss: 139.6475\n",
      "Train Epoch: 177 [0/697932 (0%)]\tLoss: 140.786531\n",
      "Train Epoch: 177 [100000/697932 (14%)]\tLoss: 137.418531\n",
      "Train Epoch: 177 [200000/697932 (29%)]\tLoss: 138.383234\n",
      "Train Epoch: 177 [300000/697932 (43%)]\tLoss: 139.359109\n",
      "Train Epoch: 177 [400000/697932 (57%)]\tLoss: 137.884047\n",
      "Train Epoch: 177 [500000/697932 (72%)]\tLoss: 138.708344\n",
      "Train Epoch: 177 [600000/697932 (86%)]\tLoss: 138.539375\n",
      "====> Epoch: 177 Average loss: 138.6561\n",
      "====> Test set loss: 139.7509\n",
      "Train Epoch: 178 [0/697932 (0%)]\tLoss: 139.491344\n",
      "Train Epoch: 178 [100000/697932 (14%)]\tLoss: 141.548281\n",
      "Train Epoch: 178 [200000/697932 (29%)]\tLoss: 138.412422\n",
      "Train Epoch: 178 [300000/697932 (43%)]\tLoss: 138.139969\n",
      "Train Epoch: 178 [400000/697932 (57%)]\tLoss: 139.282062\n",
      "Train Epoch: 178 [500000/697932 (72%)]\tLoss: 137.537750\n",
      "Train Epoch: 178 [600000/697932 (86%)]\tLoss: 138.338703\n",
      "====> Epoch: 178 Average loss: 138.6660\n",
      "====> Test set loss: 139.6821\n",
      "Train Epoch: 179 [0/697932 (0%)]\tLoss: 137.985922\n",
      "Train Epoch: 179 [100000/697932 (14%)]\tLoss: 138.400031\n",
      "Train Epoch: 179 [200000/697932 (29%)]\tLoss: 137.048078\n",
      "Train Epoch: 179 [300000/697932 (43%)]\tLoss: 141.034766\n",
      "Train Epoch: 179 [400000/697932 (57%)]\tLoss: 137.382125\n",
      "Train Epoch: 179 [500000/697932 (72%)]\tLoss: 138.430609\n",
      "Train Epoch: 179 [600000/697932 (86%)]\tLoss: 138.694562\n",
      "====> Epoch: 179 Average loss: 138.6514\n",
      "====> Test set loss: 139.5537\n",
      "Train Epoch: 180 [0/697932 (0%)]\tLoss: 138.148969\n",
      "Train Epoch: 180 [100000/697932 (14%)]\tLoss: 138.151187\n",
      "Train Epoch: 180 [200000/697932 (29%)]\tLoss: 140.814828\n",
      "Train Epoch: 180 [300000/697932 (43%)]\tLoss: 139.755391\n",
      "Train Epoch: 180 [400000/697932 (57%)]\tLoss: 140.136531\n",
      "Train Epoch: 180 [500000/697932 (72%)]\tLoss: 139.135016\n",
      "Train Epoch: 180 [600000/697932 (86%)]\tLoss: 140.681531\n",
      "====> Epoch: 180 Average loss: 138.6409\n",
      "====> Test set loss: 139.6724\n",
      "Train Epoch: 181 [0/697932 (0%)]\tLoss: 136.592594\n",
      "Train Epoch: 181 [100000/697932 (14%)]\tLoss: 137.949594\n",
      "Train Epoch: 181 [200000/697932 (29%)]\tLoss: 138.847438\n",
      "Train Epoch: 181 [300000/697932 (43%)]\tLoss: 137.241328\n",
      "Train Epoch: 181 [400000/697932 (57%)]\tLoss: 137.300938\n",
      "Train Epoch: 181 [500000/697932 (72%)]\tLoss: 138.290109\n",
      "Train Epoch: 181 [600000/697932 (86%)]\tLoss: 137.550984\n",
      "====> Epoch: 181 Average loss: 138.6505\n",
      "====> Test set loss: 139.7047\n",
      "Train Epoch: 182 [0/697932 (0%)]\tLoss: 138.691984\n",
      "Train Epoch: 182 [100000/697932 (14%)]\tLoss: 136.913766\n",
      "Train Epoch: 182 [200000/697932 (29%)]\tLoss: 138.217141\n",
      "Train Epoch: 182 [300000/697932 (43%)]\tLoss: 139.702578\n",
      "Train Epoch: 182 [400000/697932 (57%)]\tLoss: 139.083328\n",
      "Train Epoch: 182 [500000/697932 (72%)]\tLoss: 137.557219\n",
      "Train Epoch: 182 [600000/697932 (86%)]\tLoss: 138.635984\n",
      "====> Epoch: 182 Average loss: 138.6268\n",
      "====> Test set loss: 139.6445\n",
      "Train Epoch: 183 [0/697932 (0%)]\tLoss: 138.625500\n",
      "Train Epoch: 183 [100000/697932 (14%)]\tLoss: 138.289734\n",
      "Train Epoch: 183 [200000/697932 (29%)]\tLoss: 139.470328\n",
      "Train Epoch: 183 [300000/697932 (43%)]\tLoss: 138.518547\n",
      "Train Epoch: 183 [400000/697932 (57%)]\tLoss: 138.556125\n",
      "Train Epoch: 183 [500000/697932 (72%)]\tLoss: 136.834937\n",
      "Train Epoch: 183 [600000/697932 (86%)]\tLoss: 138.646375\n",
      "====> Epoch: 183 Average loss: 138.6312\n",
      "====> Test set loss: 139.7485\n",
      "Train Epoch: 184 [0/697932 (0%)]\tLoss: 139.873406\n",
      "Train Epoch: 184 [100000/697932 (14%)]\tLoss: 137.553297\n",
      "Train Epoch: 184 [200000/697932 (29%)]\tLoss: 137.211703\n",
      "Train Epoch: 184 [300000/697932 (43%)]\tLoss: 138.031484\n",
      "Train Epoch: 184 [400000/697932 (57%)]\tLoss: 137.250313\n",
      "Train Epoch: 184 [500000/697932 (72%)]\tLoss: 138.589234\n",
      "Train Epoch: 184 [600000/697932 (86%)]\tLoss: 137.427328\n",
      "====> Epoch: 184 Average loss: 138.6113\n",
      "====> Test set loss: 139.6503\n",
      "Train Epoch: 185 [0/697932 (0%)]\tLoss: 137.142922\n",
      "Train Epoch: 185 [100000/697932 (14%)]\tLoss: 138.125281\n",
      "Train Epoch: 185 [200000/697932 (29%)]\tLoss: 136.662141\n",
      "Train Epoch: 185 [300000/697932 (43%)]\tLoss: 137.170828\n",
      "Train Epoch: 185 [400000/697932 (57%)]\tLoss: 138.561500\n",
      "Train Epoch: 185 [500000/697932 (72%)]\tLoss: 138.341813\n",
      "Train Epoch: 185 [600000/697932 (86%)]\tLoss: 137.488969\n",
      "====> Epoch: 185 Average loss: 138.6202\n",
      "====> Test set loss: 139.6612\n",
      "Train Epoch: 186 [0/697932 (0%)]\tLoss: 139.732422\n",
      "Train Epoch: 186 [100000/697932 (14%)]\tLoss: 137.782391\n",
      "Train Epoch: 186 [200000/697932 (29%)]\tLoss: 140.256719\n",
      "Train Epoch: 186 [300000/697932 (43%)]\tLoss: 141.028953\n",
      "Train Epoch: 186 [400000/697932 (57%)]\tLoss: 141.590891\n",
      "Train Epoch: 186 [500000/697932 (72%)]\tLoss: 138.477922\n",
      "Train Epoch: 186 [600000/697932 (86%)]\tLoss: 138.822563\n",
      "====> Epoch: 186 Average loss: 138.6240\n",
      "====> Test set loss: 139.7122\n",
      "Train Epoch: 187 [0/697932 (0%)]\tLoss: 136.152078\n",
      "Train Epoch: 187 [100000/697932 (14%)]\tLoss: 137.115609\n",
      "Train Epoch: 187 [200000/697932 (29%)]\tLoss: 139.096781\n",
      "Train Epoch: 187 [300000/697932 (43%)]\tLoss: 137.540469\n",
      "Train Epoch: 187 [400000/697932 (57%)]\tLoss: 138.964438\n",
      "Train Epoch: 187 [500000/697932 (72%)]\tLoss: 137.851328\n",
      "Train Epoch: 187 [600000/697932 (86%)]\tLoss: 138.496281\n",
      "====> Epoch: 187 Average loss: 138.6029\n",
      "====> Test set loss: 139.5915\n",
      "Train Epoch: 188 [0/697932 (0%)]\tLoss: 140.098859\n",
      "Train Epoch: 188 [100000/697932 (14%)]\tLoss: 137.491656\n",
      "Train Epoch: 188 [200000/697932 (29%)]\tLoss: 138.909922\n",
      "Train Epoch: 188 [300000/697932 (43%)]\tLoss: 138.973406\n",
      "Train Epoch: 188 [400000/697932 (57%)]\tLoss: 140.295813\n",
      "Train Epoch: 188 [500000/697932 (72%)]\tLoss: 138.211563\n",
      "Train Epoch: 188 [600000/697932 (86%)]\tLoss: 136.406047\n",
      "====> Epoch: 188 Average loss: 138.6038\n",
      "====> Test set loss: 139.5577\n",
      "Train Epoch: 189 [0/697932 (0%)]\tLoss: 140.195641\n",
      "Train Epoch: 189 [100000/697932 (14%)]\tLoss: 138.466906\n",
      "Train Epoch: 189 [200000/697932 (29%)]\tLoss: 139.934969\n",
      "Train Epoch: 189 [300000/697932 (43%)]\tLoss: 138.599109\n",
      "Train Epoch: 189 [400000/697932 (57%)]\tLoss: 138.652047\n",
      "Train Epoch: 189 [500000/697932 (72%)]\tLoss: 138.685375\n",
      "Train Epoch: 189 [600000/697932 (86%)]\tLoss: 138.971469\n",
      "====> Epoch: 189 Average loss: 138.5928\n",
      "====> Test set loss: 139.6008\n",
      "Train Epoch: 190 [0/697932 (0%)]\tLoss: 137.733094\n",
      "Train Epoch: 190 [100000/697932 (14%)]\tLoss: 139.930781\n",
      "Train Epoch: 190 [200000/697932 (29%)]\tLoss: 140.339734\n",
      "Train Epoch: 190 [300000/697932 (43%)]\tLoss: 140.177000\n",
      "Train Epoch: 190 [400000/697932 (57%)]\tLoss: 138.189234\n",
      "Train Epoch: 190 [500000/697932 (72%)]\tLoss: 137.270078\n",
      "Train Epoch: 190 [600000/697932 (86%)]\tLoss: 140.270594\n",
      "====> Epoch: 190 Average loss: 138.5854\n",
      "====> Test set loss: 139.6909\n",
      "Train Epoch: 191 [0/697932 (0%)]\tLoss: 139.568266\n",
      "Train Epoch: 191 [100000/697932 (14%)]\tLoss: 138.060078\n",
      "Train Epoch: 191 [200000/697932 (29%)]\tLoss: 137.714016\n",
      "Train Epoch: 191 [300000/697932 (43%)]\tLoss: 138.817203\n",
      "Train Epoch: 191 [400000/697932 (57%)]\tLoss: 139.034281\n",
      "Train Epoch: 191 [500000/697932 (72%)]\tLoss: 137.706187\n",
      "Train Epoch: 191 [600000/697932 (86%)]\tLoss: 138.567281\n",
      "====> Epoch: 191 Average loss: 138.5827\n",
      "====> Test set loss: 139.5422\n",
      "Train Epoch: 192 [0/697932 (0%)]\tLoss: 137.429422\n",
      "Train Epoch: 192 [100000/697932 (14%)]\tLoss: 141.222984\n",
      "Train Epoch: 192 [200000/697932 (29%)]\tLoss: 140.081344\n",
      "Train Epoch: 192 [300000/697932 (43%)]\tLoss: 138.830766\n",
      "Train Epoch: 192 [400000/697932 (57%)]\tLoss: 138.004828\n",
      "Train Epoch: 192 [500000/697932 (72%)]\tLoss: 139.406891\n",
      "Train Epoch: 192 [600000/697932 (86%)]\tLoss: 137.578328\n",
      "====> Epoch: 192 Average loss: 138.5756\n",
      "====> Test set loss: 139.6479\n",
      "Train Epoch: 193 [0/697932 (0%)]\tLoss: 139.099250\n",
      "Train Epoch: 193 [100000/697932 (14%)]\tLoss: 140.850531\n",
      "Train Epoch: 193 [200000/697932 (29%)]\tLoss: 138.089484\n",
      "Train Epoch: 193 [300000/697932 (43%)]\tLoss: 137.945859\n",
      "Train Epoch: 193 [400000/697932 (57%)]\tLoss: 139.931625\n",
      "Train Epoch: 193 [500000/697932 (72%)]\tLoss: 137.943891\n",
      "Train Epoch: 193 [600000/697932 (86%)]\tLoss: 137.457016\n",
      "====> Epoch: 193 Average loss: 138.5681\n",
      "====> Test set loss: 139.6702\n",
      "Train Epoch: 194 [0/697932 (0%)]\tLoss: 137.790844\n",
      "Train Epoch: 194 [100000/697932 (14%)]\tLoss: 139.697984\n",
      "Train Epoch: 194 [200000/697932 (29%)]\tLoss: 136.818031\n",
      "Train Epoch: 194 [300000/697932 (43%)]\tLoss: 138.172656\n",
      "Train Epoch: 194 [400000/697932 (57%)]\tLoss: 138.735906\n",
      "Train Epoch: 194 [500000/697932 (72%)]\tLoss: 139.345078\n",
      "Train Epoch: 194 [600000/697932 (86%)]\tLoss: 138.969000\n",
      "====> Epoch: 194 Average loss: 138.5675\n",
      "====> Test set loss: 139.6261\n",
      "Train Epoch: 195 [0/697932 (0%)]\tLoss: 140.390172\n",
      "Train Epoch: 195 [100000/697932 (14%)]\tLoss: 139.856719\n",
      "Train Epoch: 195 [200000/697932 (29%)]\tLoss: 137.779188\n",
      "Train Epoch: 195 [300000/697932 (43%)]\tLoss: 138.070687\n",
      "Train Epoch: 195 [400000/697932 (57%)]\tLoss: 138.455594\n",
      "Train Epoch: 195 [500000/697932 (72%)]\tLoss: 138.312500\n",
      "Train Epoch: 195 [600000/697932 (86%)]\tLoss: 136.433484\n",
      "====> Epoch: 195 Average loss: 138.5528\n",
      "====> Test set loss: 139.6948\n",
      "Train Epoch: 196 [0/697932 (0%)]\tLoss: 138.696281\n",
      "Train Epoch: 196 [100000/697932 (14%)]\tLoss: 136.893188\n",
      "Train Epoch: 196 [200000/697932 (29%)]\tLoss: 137.453641\n",
      "Train Epoch: 196 [300000/697932 (43%)]\tLoss: 138.742578\n",
      "Train Epoch: 196 [400000/697932 (57%)]\tLoss: 137.703359\n",
      "Train Epoch: 196 [500000/697932 (72%)]\tLoss: 135.242750\n",
      "Train Epoch: 196 [600000/697932 (86%)]\tLoss: 135.294859\n",
      "====> Epoch: 196 Average loss: 138.5528\n",
      "====> Test set loss: 139.5666\n",
      "Train Epoch: 197 [0/697932 (0%)]\tLoss: 137.648906\n",
      "Train Epoch: 197 [100000/697932 (14%)]\tLoss: 138.568938\n",
      "Train Epoch: 197 [200000/697932 (29%)]\tLoss: 137.928609\n",
      "Train Epoch: 197 [300000/697932 (43%)]\tLoss: 138.625812\n",
      "Train Epoch: 197 [400000/697932 (57%)]\tLoss: 139.409797\n",
      "Train Epoch: 197 [500000/697932 (72%)]\tLoss: 137.887047\n",
      "Train Epoch: 197 [600000/697932 (86%)]\tLoss: 137.741891\n",
      "====> Epoch: 197 Average loss: 138.5394\n",
      "====> Test set loss: 139.5508\n",
      "Train Epoch: 198 [0/697932 (0%)]\tLoss: 137.564500\n",
      "Train Epoch: 198 [100000/697932 (14%)]\tLoss: 140.081672\n",
      "Train Epoch: 198 [200000/697932 (29%)]\tLoss: 137.946625\n",
      "Train Epoch: 198 [300000/697932 (43%)]\tLoss: 138.472438\n",
      "Train Epoch: 198 [400000/697932 (57%)]\tLoss: 139.796172\n",
      "Train Epoch: 198 [500000/697932 (72%)]\tLoss: 139.678719\n",
      "Train Epoch: 198 [600000/697932 (86%)]\tLoss: 138.627922\n",
      "====> Epoch: 198 Average loss: 138.5458\n",
      "====> Test set loss: 139.6781\n",
      "Train Epoch: 199 [0/697932 (0%)]\tLoss: 137.483172\n",
      "Train Epoch: 199 [100000/697932 (14%)]\tLoss: 139.956625\n",
      "Train Epoch: 199 [200000/697932 (29%)]\tLoss: 135.987687\n",
      "Train Epoch: 199 [300000/697932 (43%)]\tLoss: 138.469391\n",
      "Train Epoch: 199 [400000/697932 (57%)]\tLoss: 137.189906\n",
      "Train Epoch: 199 [500000/697932 (72%)]\tLoss: 138.633703\n",
      "Train Epoch: 199 [600000/697932 (86%)]\tLoss: 138.137469\n",
      "====> Epoch: 199 Average loss: 138.5335\n",
      "====> Test set loss: 139.4822\n",
      "Train Epoch: 200 [0/697932 (0%)]\tLoss: 139.480828\n",
      "Train Epoch: 200 [100000/697932 (14%)]\tLoss: 138.893891\n",
      "Train Epoch: 200 [200000/697932 (29%)]\tLoss: 138.497734\n",
      "Train Epoch: 200 [300000/697932 (43%)]\tLoss: 137.727859\n",
      "Train Epoch: 200 [400000/697932 (57%)]\tLoss: 139.407813\n",
      "Train Epoch: 200 [500000/697932 (72%)]\tLoss: 138.150797\n",
      "Train Epoch: 200 [600000/697932 (86%)]\tLoss: 139.266078\n",
      "====> Epoch: 200 Average loss: 138.5412\n",
      "====> Test set loss: 139.6030\n",
      "Train Epoch: 201 [0/697932 (0%)]\tLoss: 138.604344\n",
      "Train Epoch: 201 [100000/697932 (14%)]\tLoss: 137.336234\n",
      "Train Epoch: 201 [200000/697932 (29%)]\tLoss: 137.605719\n",
      "Train Epoch: 201 [300000/697932 (43%)]\tLoss: 139.096984\n",
      "Train Epoch: 201 [400000/697932 (57%)]\tLoss: 139.830000\n",
      "Train Epoch: 201 [500000/697932 (72%)]\tLoss: 138.775234\n",
      "Train Epoch: 201 [600000/697932 (86%)]\tLoss: 138.761937\n",
      "====> Epoch: 201 Average loss: 138.5221\n",
      "====> Test set loss: 139.6180\n",
      "Train Epoch: 202 [0/697932 (0%)]\tLoss: 137.759891\n",
      "Train Epoch: 202 [100000/697932 (14%)]\tLoss: 137.676453\n",
      "Train Epoch: 202 [200000/697932 (29%)]\tLoss: 139.348484\n",
      "Train Epoch: 202 [300000/697932 (43%)]\tLoss: 138.189188\n",
      "Train Epoch: 202 [400000/697932 (57%)]\tLoss: 138.655391\n",
      "Train Epoch: 202 [500000/697932 (72%)]\tLoss: 139.119906\n",
      "Train Epoch: 202 [600000/697932 (86%)]\tLoss: 139.737609\n",
      "====> Epoch: 202 Average loss: 138.5159\n",
      "====> Test set loss: 139.6211\n",
      "Train Epoch: 203 [0/697932 (0%)]\tLoss: 136.367500\n",
      "Train Epoch: 203 [100000/697932 (14%)]\tLoss: 136.635891\n",
      "Train Epoch: 203 [200000/697932 (29%)]\tLoss: 139.149687\n",
      "Train Epoch: 203 [300000/697932 (43%)]\tLoss: 136.897359\n",
      "Train Epoch: 203 [400000/697932 (57%)]\tLoss: 139.286937\n",
      "Train Epoch: 203 [500000/697932 (72%)]\tLoss: 138.210719\n",
      "Train Epoch: 203 [600000/697932 (86%)]\tLoss: 137.825203\n",
      "====> Epoch: 203 Average loss: 138.5284\n",
      "====> Test set loss: 139.5684\n",
      "Train Epoch: 204 [0/697932 (0%)]\tLoss: 139.353344\n",
      "Train Epoch: 204 [100000/697932 (14%)]\tLoss: 137.732344\n",
      "Train Epoch: 204 [200000/697932 (29%)]\tLoss: 138.671922\n",
      "Train Epoch: 204 [300000/697932 (43%)]\tLoss: 139.349125\n",
      "Train Epoch: 204 [400000/697932 (57%)]\tLoss: 138.815922\n",
      "Train Epoch: 204 [500000/697932 (72%)]\tLoss: 137.603203\n",
      "Train Epoch: 204 [600000/697932 (86%)]\tLoss: 137.981656\n",
      "====> Epoch: 204 Average loss: 138.5030\n",
      "====> Test set loss: 139.4973\n",
      "Train Epoch: 205 [0/697932 (0%)]\tLoss: 139.308766\n",
      "Train Epoch: 205 [100000/697932 (14%)]\tLoss: 137.418172\n",
      "Train Epoch: 205 [200000/697932 (29%)]\tLoss: 138.819500\n",
      "Train Epoch: 205 [300000/697932 (43%)]\tLoss: 138.853406\n",
      "Train Epoch: 205 [400000/697932 (57%)]\tLoss: 138.758469\n",
      "Train Epoch: 205 [500000/697932 (72%)]\tLoss: 137.222547\n",
      "Train Epoch: 205 [600000/697932 (86%)]\tLoss: 137.269031\n",
      "====> Epoch: 205 Average loss: 138.5065\n",
      "====> Test set loss: 139.4969\n",
      "Train Epoch: 206 [0/697932 (0%)]\tLoss: 139.435859\n",
      "Train Epoch: 206 [100000/697932 (14%)]\tLoss: 138.234750\n",
      "Train Epoch: 206 [200000/697932 (29%)]\tLoss: 139.096125\n",
      "Train Epoch: 206 [300000/697932 (43%)]\tLoss: 138.421359\n",
      "Train Epoch: 206 [400000/697932 (57%)]\tLoss: 140.903594\n",
      "Train Epoch: 206 [500000/697932 (72%)]\tLoss: 139.103969\n",
      "Train Epoch: 206 [600000/697932 (86%)]\tLoss: 139.413094\n",
      "====> Epoch: 206 Average loss: 138.5101\n",
      "====> Test set loss: 139.6800\n",
      "Train Epoch: 207 [0/697932 (0%)]\tLoss: 139.546516\n",
      "Train Epoch: 207 [100000/697932 (14%)]\tLoss: 136.951188\n",
      "Train Epoch: 207 [200000/697932 (29%)]\tLoss: 139.205766\n",
      "Train Epoch: 207 [300000/697932 (43%)]\tLoss: 138.776922\n",
      "Train Epoch: 207 [400000/697932 (57%)]\tLoss: 137.314531\n",
      "Train Epoch: 207 [500000/697932 (72%)]\tLoss: 139.103719\n",
      "Train Epoch: 207 [600000/697932 (86%)]\tLoss: 139.791453\n",
      "====> Epoch: 207 Average loss: 138.4892\n",
      "====> Test set loss: 139.6217\n",
      "Train Epoch: 208 [0/697932 (0%)]\tLoss: 137.834688\n",
      "Train Epoch: 208 [100000/697932 (14%)]\tLoss: 140.251484\n",
      "Train Epoch: 208 [200000/697932 (29%)]\tLoss: 138.765969\n",
      "Train Epoch: 208 [300000/697932 (43%)]\tLoss: 138.971891\n",
      "Train Epoch: 208 [400000/697932 (57%)]\tLoss: 139.427562\n",
      "Train Epoch: 208 [500000/697932 (72%)]\tLoss: 140.091656\n",
      "Train Epoch: 208 [600000/697932 (86%)]\tLoss: 137.850844\n",
      "====> Epoch: 208 Average loss: 138.4985\n",
      "====> Test set loss: 139.5286\n",
      "Train Epoch: 209 [0/697932 (0%)]\tLoss: 138.525813\n",
      "Train Epoch: 209 [100000/697932 (14%)]\tLoss: 137.206312\n",
      "Train Epoch: 209 [200000/697932 (29%)]\tLoss: 137.392281\n",
      "Train Epoch: 209 [300000/697932 (43%)]\tLoss: 139.400266\n",
      "Train Epoch: 209 [400000/697932 (57%)]\tLoss: 138.664172\n",
      "Train Epoch: 209 [500000/697932 (72%)]\tLoss: 139.468219\n",
      "Train Epoch: 209 [600000/697932 (86%)]\tLoss: 137.642422\n",
      "====> Epoch: 209 Average loss: 138.4712\n",
      "====> Test set loss: 139.5728\n",
      "Train Epoch: 210 [0/697932 (0%)]\tLoss: 140.055203\n",
      "Train Epoch: 210 [100000/697932 (14%)]\tLoss: 139.950516\n",
      "Train Epoch: 210 [200000/697932 (29%)]\tLoss: 138.708516\n",
      "Train Epoch: 210 [300000/697932 (43%)]\tLoss: 138.398266\n",
      "Train Epoch: 210 [400000/697932 (57%)]\tLoss: 138.191000\n",
      "Train Epoch: 210 [500000/697932 (72%)]\tLoss: 139.634078\n",
      "Train Epoch: 210 [600000/697932 (86%)]\tLoss: 136.965094\n",
      "====> Epoch: 210 Average loss: 138.4694\n",
      "====> Test set loss: 139.6329\n",
      "Train Epoch: 211 [0/697932 (0%)]\tLoss: 138.307187\n",
      "Train Epoch: 211 [100000/697932 (14%)]\tLoss: 138.135016\n",
      "Train Epoch: 211 [200000/697932 (29%)]\tLoss: 139.032406\n",
      "Train Epoch: 211 [300000/697932 (43%)]\tLoss: 137.789938\n",
      "Train Epoch: 211 [400000/697932 (57%)]\tLoss: 141.026813\n",
      "Train Epoch: 211 [500000/697932 (72%)]\tLoss: 138.365859\n",
      "Train Epoch: 211 [600000/697932 (86%)]\tLoss: 138.737547\n",
      "====> Epoch: 211 Average loss: 138.4642\n",
      "====> Test set loss: 139.5564\n",
      "Train Epoch: 212 [0/697932 (0%)]\tLoss: 136.458547\n",
      "Train Epoch: 212 [100000/697932 (14%)]\tLoss: 138.132875\n",
      "Train Epoch: 212 [200000/697932 (29%)]\tLoss: 139.706906\n",
      "Train Epoch: 212 [300000/697932 (43%)]\tLoss: 138.813797\n",
      "Train Epoch: 212 [400000/697932 (57%)]\tLoss: 137.484203\n",
      "Train Epoch: 212 [500000/697932 (72%)]\tLoss: 137.517719\n",
      "Train Epoch: 212 [600000/697932 (86%)]\tLoss: 139.217281\n",
      "====> Epoch: 212 Average loss: 138.4769\n",
      "====> Test set loss: 139.5135\n",
      "Train Epoch: 213 [0/697932 (0%)]\tLoss: 137.556609\n",
      "Train Epoch: 213 [100000/697932 (14%)]\tLoss: 137.688844\n",
      "Train Epoch: 213 [200000/697932 (29%)]\tLoss: 139.281875\n",
      "Train Epoch: 213 [300000/697932 (43%)]\tLoss: 138.712562\n",
      "Train Epoch: 213 [400000/697932 (57%)]\tLoss: 137.817406\n",
      "Train Epoch: 213 [500000/697932 (72%)]\tLoss: 137.666031\n",
      "Train Epoch: 213 [600000/697932 (86%)]\tLoss: 138.560078\n",
      "====> Epoch: 213 Average loss: 138.4587\n",
      "====> Test set loss: 139.4691\n",
      "Train Epoch: 214 [0/697932 (0%)]\tLoss: 139.970109\n",
      "Train Epoch: 214 [100000/697932 (14%)]\tLoss: 138.558312\n",
      "Train Epoch: 214 [200000/697932 (29%)]\tLoss: 138.714531\n",
      "Train Epoch: 214 [300000/697932 (43%)]\tLoss: 138.545297\n",
      "Train Epoch: 214 [400000/697932 (57%)]\tLoss: 136.477031\n",
      "Train Epoch: 214 [500000/697932 (72%)]\tLoss: 141.870844\n",
      "Train Epoch: 214 [600000/697932 (86%)]\tLoss: 139.496047\n",
      "====> Epoch: 214 Average loss: 138.4591\n",
      "====> Test set loss: 139.5305\n",
      "Train Epoch: 215 [0/697932 (0%)]\tLoss: 135.822000\n",
      "Train Epoch: 215 [100000/697932 (14%)]\tLoss: 137.656766\n",
      "Train Epoch: 215 [200000/697932 (29%)]\tLoss: 139.255672\n",
      "Train Epoch: 215 [300000/697932 (43%)]\tLoss: 139.447734\n",
      "Train Epoch: 215 [400000/697932 (57%)]\tLoss: 139.849422\n",
      "Train Epoch: 215 [500000/697932 (72%)]\tLoss: 138.661016\n",
      "Train Epoch: 215 [600000/697932 (86%)]\tLoss: 136.466219\n",
      "====> Epoch: 215 Average loss: 138.4585\n",
      "====> Test set loss: 139.4505\n",
      "Train Epoch: 216 [0/697932 (0%)]\tLoss: 137.869203\n",
      "Train Epoch: 216 [100000/697932 (14%)]\tLoss: 138.658266\n",
      "Train Epoch: 216 [200000/697932 (29%)]\tLoss: 138.765656\n",
      "Train Epoch: 216 [300000/697932 (43%)]\tLoss: 138.971172\n",
      "Train Epoch: 216 [400000/697932 (57%)]\tLoss: 137.841000\n",
      "Train Epoch: 216 [500000/697932 (72%)]\tLoss: 140.475188\n",
      "Train Epoch: 216 [600000/697932 (86%)]\tLoss: 137.993656\n",
      "====> Epoch: 216 Average loss: 138.4538\n",
      "====> Test set loss: 139.4360\n",
      "Train Epoch: 217 [0/697932 (0%)]\tLoss: 137.767734\n",
      "Train Epoch: 217 [100000/697932 (14%)]\tLoss: 139.673344\n",
      "Train Epoch: 217 [200000/697932 (29%)]\tLoss: 138.706562\n",
      "Train Epoch: 217 [300000/697932 (43%)]\tLoss: 139.596172\n",
      "Train Epoch: 217 [400000/697932 (57%)]\tLoss: 137.415875\n",
      "Train Epoch: 217 [500000/697932 (72%)]\tLoss: 139.094906\n",
      "Train Epoch: 217 [600000/697932 (86%)]\tLoss: 138.728859\n",
      "====> Epoch: 217 Average loss: 138.4315\n",
      "====> Test set loss: 139.5993\n",
      "Train Epoch: 218 [0/697932 (0%)]\tLoss: 137.916188\n",
      "Train Epoch: 218 [100000/697932 (14%)]\tLoss: 138.636484\n",
      "Train Epoch: 218 [200000/697932 (29%)]\tLoss: 137.579641\n",
      "Train Epoch: 218 [300000/697932 (43%)]\tLoss: 140.200891\n",
      "Train Epoch: 218 [400000/697932 (57%)]\tLoss: 137.620438\n",
      "Train Epoch: 218 [500000/697932 (72%)]\tLoss: 138.292062\n",
      "Train Epoch: 218 [600000/697932 (86%)]\tLoss: 139.161687\n",
      "====> Epoch: 218 Average loss: 138.4438\n",
      "====> Test set loss: 139.5678\n",
      "Train Epoch: 219 [0/697932 (0%)]\tLoss: 137.883172\n",
      "Train Epoch: 219 [100000/697932 (14%)]\tLoss: 138.724969\n",
      "Train Epoch: 219 [200000/697932 (29%)]\tLoss: 137.360813\n",
      "Train Epoch: 219 [300000/697932 (43%)]\tLoss: 139.220141\n",
      "Train Epoch: 219 [400000/697932 (57%)]\tLoss: 136.770000\n",
      "Train Epoch: 219 [500000/697932 (72%)]\tLoss: 138.562578\n",
      "Train Epoch: 219 [600000/697932 (86%)]\tLoss: 140.072656\n",
      "====> Epoch: 219 Average loss: 138.4385\n",
      "====> Test set loss: 139.5059\n",
      "Train Epoch: 220 [0/697932 (0%)]\tLoss: 139.484969\n",
      "Train Epoch: 220 [100000/697932 (14%)]\tLoss: 137.964063\n",
      "Train Epoch: 220 [200000/697932 (29%)]\tLoss: 136.968656\n",
      "Train Epoch: 220 [300000/697932 (43%)]\tLoss: 139.720937\n",
      "Train Epoch: 220 [400000/697932 (57%)]\tLoss: 139.847375\n",
      "Train Epoch: 220 [500000/697932 (72%)]\tLoss: 140.531031\n",
      "Train Epoch: 220 [600000/697932 (86%)]\tLoss: 135.030703\n",
      "====> Epoch: 220 Average loss: 138.4177\n",
      "====> Test set loss: 139.5939\n",
      "Train Epoch: 221 [0/697932 (0%)]\tLoss: 139.142141\n",
      "Train Epoch: 221 [100000/697932 (14%)]\tLoss: 137.183625\n",
      "Train Epoch: 221 [200000/697932 (29%)]\tLoss: 137.853156\n",
      "Train Epoch: 221 [300000/697932 (43%)]\tLoss: 140.620422\n",
      "Train Epoch: 221 [400000/697932 (57%)]\tLoss: 139.682656\n",
      "Train Epoch: 221 [500000/697932 (72%)]\tLoss: 136.419672\n",
      "Train Epoch: 221 [600000/697932 (86%)]\tLoss: 135.558562\n",
      "====> Epoch: 221 Average loss: 138.4217\n",
      "====> Test set loss: 139.5399\n",
      "Train Epoch: 222 [0/697932 (0%)]\tLoss: 138.522953\n",
      "Train Epoch: 222 [100000/697932 (14%)]\tLoss: 137.696719\n",
      "Train Epoch: 222 [200000/697932 (29%)]\tLoss: 137.876297\n",
      "Train Epoch: 222 [300000/697932 (43%)]\tLoss: 139.237531\n",
      "Train Epoch: 222 [400000/697932 (57%)]\tLoss: 139.094469\n",
      "Train Epoch: 222 [500000/697932 (72%)]\tLoss: 139.687125\n",
      "Train Epoch: 222 [600000/697932 (86%)]\tLoss: 138.423156\n",
      "====> Epoch: 222 Average loss: 138.4054\n",
      "====> Test set loss: 139.4981\n",
      "Train Epoch: 223 [0/697932 (0%)]\tLoss: 138.973984\n",
      "Train Epoch: 223 [100000/697932 (14%)]\tLoss: 138.139859\n",
      "Train Epoch: 223 [200000/697932 (29%)]\tLoss: 136.701531\n",
      "Train Epoch: 223 [300000/697932 (43%)]\tLoss: 139.559547\n",
      "Train Epoch: 223 [400000/697932 (57%)]\tLoss: 138.240531\n",
      "Train Epoch: 223 [500000/697932 (72%)]\tLoss: 137.030453\n",
      "Train Epoch: 223 [600000/697932 (86%)]\tLoss: 138.167406\n",
      "====> Epoch: 223 Average loss: 138.4260\n",
      "====> Test set loss: 139.4258\n",
      "Train Epoch: 224 [0/697932 (0%)]\tLoss: 138.640766\n",
      "Train Epoch: 224 [100000/697932 (14%)]\tLoss: 136.945969\n",
      "Train Epoch: 224 [200000/697932 (29%)]\tLoss: 136.280578\n",
      "Train Epoch: 224 [300000/697932 (43%)]\tLoss: 138.743609\n",
      "Train Epoch: 224 [400000/697932 (57%)]\tLoss: 139.364188\n",
      "Train Epoch: 224 [500000/697932 (72%)]\tLoss: 141.283766\n",
      "Train Epoch: 224 [600000/697932 (86%)]\tLoss: 137.889266\n",
      "====> Epoch: 224 Average loss: 138.4070\n",
      "====> Test set loss: 139.4640\n",
      "Train Epoch: 225 [0/697932 (0%)]\tLoss: 138.789219\n",
      "Train Epoch: 225 [100000/697932 (14%)]\tLoss: 139.226188\n",
      "Train Epoch: 225 [200000/697932 (29%)]\tLoss: 139.175641\n",
      "Train Epoch: 225 [300000/697932 (43%)]\tLoss: 139.571750\n",
      "Train Epoch: 225 [400000/697932 (57%)]\tLoss: 136.889297\n",
      "Train Epoch: 225 [500000/697932 (72%)]\tLoss: 138.430141\n",
      "Train Epoch: 225 [600000/697932 (86%)]\tLoss: 138.569781\n",
      "====> Epoch: 225 Average loss: 138.4023\n",
      "====> Test set loss: 139.5416\n",
      "Train Epoch: 226 [0/697932 (0%)]\tLoss: 136.112406\n",
      "Train Epoch: 226 [100000/697932 (14%)]\tLoss: 138.919031\n",
      "Train Epoch: 226 [200000/697932 (29%)]\tLoss: 139.536531\n",
      "Train Epoch: 226 [300000/697932 (43%)]\tLoss: 137.627750\n",
      "Train Epoch: 226 [400000/697932 (57%)]\tLoss: 138.038281\n",
      "Train Epoch: 226 [500000/697932 (72%)]\tLoss: 137.695469\n",
      "Train Epoch: 226 [600000/697932 (86%)]\tLoss: 139.739906\n",
      "====> Epoch: 226 Average loss: 138.3978\n",
      "====> Test set loss: 139.4604\n",
      "Train Epoch: 227 [0/697932 (0%)]\tLoss: 137.919125\n",
      "Train Epoch: 227 [100000/697932 (14%)]\tLoss: 138.990219\n",
      "Train Epoch: 227 [200000/697932 (29%)]\tLoss: 138.233969\n",
      "Train Epoch: 227 [300000/697932 (43%)]\tLoss: 139.635250\n",
      "Train Epoch: 227 [400000/697932 (57%)]\tLoss: 139.231188\n",
      "Train Epoch: 227 [500000/697932 (72%)]\tLoss: 137.615328\n",
      "Train Epoch: 227 [600000/697932 (86%)]\tLoss: 137.404656\n",
      "====> Epoch: 227 Average loss: 138.3942\n",
      "====> Test set loss: 139.5844\n",
      "Train Epoch: 228 [0/697932 (0%)]\tLoss: 137.545266\n",
      "Train Epoch: 228 [100000/697932 (14%)]\tLoss: 138.084922\n",
      "Train Epoch: 228 [200000/697932 (29%)]\tLoss: 136.941469\n",
      "Train Epoch: 228 [300000/697932 (43%)]\tLoss: 139.888125\n",
      "Train Epoch: 228 [400000/697932 (57%)]\tLoss: 139.523828\n",
      "Train Epoch: 228 [500000/697932 (72%)]\tLoss: 137.930203\n",
      "Train Epoch: 228 [600000/697932 (86%)]\tLoss: 141.311875\n",
      "====> Epoch: 228 Average loss: 138.3912\n",
      "====> Test set loss: 139.4481\n",
      "Train Epoch: 229 [0/697932 (0%)]\tLoss: 137.327469\n",
      "Train Epoch: 229 [100000/697932 (14%)]\tLoss: 139.166188\n",
      "Train Epoch: 229 [200000/697932 (29%)]\tLoss: 139.447625\n",
      "Train Epoch: 229 [300000/697932 (43%)]\tLoss: 136.503375\n",
      "Train Epoch: 229 [400000/697932 (57%)]\tLoss: 139.030750\n",
      "Train Epoch: 229 [500000/697932 (72%)]\tLoss: 138.373719\n",
      "Train Epoch: 229 [600000/697932 (86%)]\tLoss: 138.294578\n",
      "====> Epoch: 229 Average loss: 138.3948\n",
      "====> Test set loss: 139.4033\n",
      "Train Epoch: 230 [0/697932 (0%)]\tLoss: 137.523484\n",
      "Train Epoch: 230 [100000/697932 (14%)]\tLoss: 137.496000\n",
      "Train Epoch: 230 [200000/697932 (29%)]\tLoss: 138.629484\n",
      "Train Epoch: 230 [300000/697932 (43%)]\tLoss: 140.268953\n",
      "Train Epoch: 230 [400000/697932 (57%)]\tLoss: 138.239328\n",
      "Train Epoch: 230 [500000/697932 (72%)]\tLoss: 137.464562\n",
      "Train Epoch: 230 [600000/697932 (86%)]\tLoss: 137.078047\n",
      "====> Epoch: 230 Average loss: 138.3716\n",
      "====> Test set loss: 139.4518\n",
      "Train Epoch: 231 [0/697932 (0%)]\tLoss: 137.785531\n",
      "Train Epoch: 231 [100000/697932 (14%)]\tLoss: 138.118562\n",
      "Train Epoch: 231 [200000/697932 (29%)]\tLoss: 137.532672\n",
      "Train Epoch: 231 [300000/697932 (43%)]\tLoss: 137.848281\n",
      "Train Epoch: 231 [400000/697932 (57%)]\tLoss: 138.662297\n",
      "Train Epoch: 231 [500000/697932 (72%)]\tLoss: 140.525078\n",
      "Train Epoch: 231 [600000/697932 (86%)]\tLoss: 140.050734\n",
      "====> Epoch: 231 Average loss: 138.3719\n",
      "====> Test set loss: 139.4652\n",
      "Train Epoch: 232 [0/697932 (0%)]\tLoss: 137.430172\n",
      "Train Epoch: 232 [100000/697932 (14%)]\tLoss: 137.419813\n",
      "Train Epoch: 232 [200000/697932 (29%)]\tLoss: 137.247094\n",
      "Train Epoch: 232 [300000/697932 (43%)]\tLoss: 136.531078\n",
      "Train Epoch: 232 [400000/697932 (57%)]\tLoss: 139.747203\n",
      "Train Epoch: 232 [500000/697932 (72%)]\tLoss: 140.980844\n",
      "Train Epoch: 232 [600000/697932 (86%)]\tLoss: 140.551187\n",
      "====> Epoch: 232 Average loss: 138.3850\n",
      "====> Test set loss: 139.5482\n",
      "Train Epoch: 233 [0/697932 (0%)]\tLoss: 141.099656\n",
      "Train Epoch: 233 [100000/697932 (14%)]\tLoss: 139.199016\n",
      "Train Epoch: 233 [200000/697932 (29%)]\tLoss: 138.217813\n",
      "Train Epoch: 233 [300000/697932 (43%)]\tLoss: 139.206656\n",
      "Train Epoch: 233 [400000/697932 (57%)]\tLoss: 137.274844\n",
      "Train Epoch: 233 [500000/697932 (72%)]\tLoss: 139.805187\n",
      "Train Epoch: 233 [600000/697932 (86%)]\tLoss: 138.787547\n",
      "====> Epoch: 233 Average loss: 138.3725\n",
      "====> Test set loss: 139.4839\n",
      "Train Epoch: 234 [0/697932 (0%)]\tLoss: 138.255672\n",
      "Train Epoch: 234 [100000/697932 (14%)]\tLoss: 138.681062\n",
      "Train Epoch: 234 [200000/697932 (29%)]\tLoss: 137.397938\n",
      "Train Epoch: 234 [300000/697932 (43%)]\tLoss: 139.012703\n",
      "Train Epoch: 234 [400000/697932 (57%)]\tLoss: 137.560563\n",
      "Train Epoch: 234 [500000/697932 (72%)]\tLoss: 138.394250\n",
      "Train Epoch: 234 [600000/697932 (86%)]\tLoss: 136.605312\n",
      "====> Epoch: 234 Average loss: 138.3617\n",
      "====> Test set loss: 139.5061\n",
      "Train Epoch: 235 [0/697932 (0%)]\tLoss: 139.100672\n",
      "Train Epoch: 235 [100000/697932 (14%)]\tLoss: 138.026734\n",
      "Train Epoch: 235 [200000/697932 (29%)]\tLoss: 137.881219\n",
      "Train Epoch: 235 [300000/697932 (43%)]\tLoss: 137.590922\n",
      "Train Epoch: 235 [400000/697932 (57%)]\tLoss: 138.388172\n",
      "Train Epoch: 235 [500000/697932 (72%)]\tLoss: 139.615750\n",
      "Train Epoch: 235 [600000/697932 (86%)]\tLoss: 137.716953\n",
      "====> Epoch: 235 Average loss: 138.3508\n",
      "====> Test set loss: 139.4134\n",
      "Train Epoch: 236 [0/697932 (0%)]\tLoss: 136.424828\n",
      "Train Epoch: 236 [100000/697932 (14%)]\tLoss: 137.409719\n",
      "Train Epoch: 236 [200000/697932 (29%)]\tLoss: 136.630531\n",
      "Train Epoch: 236 [300000/697932 (43%)]\tLoss: 138.637734\n",
      "Train Epoch: 236 [400000/697932 (57%)]\tLoss: 137.853328\n",
      "Train Epoch: 236 [500000/697932 (72%)]\tLoss: 139.079766\n",
      "Train Epoch: 236 [600000/697932 (86%)]\tLoss: 140.741281\n",
      "====> Epoch: 236 Average loss: 138.3488\n",
      "====> Test set loss: 139.5241\n",
      "Train Epoch: 237 [0/697932 (0%)]\tLoss: 138.584047\n",
      "Train Epoch: 237 [100000/697932 (14%)]\tLoss: 137.951016\n",
      "Train Epoch: 237 [200000/697932 (29%)]\tLoss: 137.797344\n",
      "Train Epoch: 237 [300000/697932 (43%)]\tLoss: 138.151859\n",
      "Train Epoch: 237 [400000/697932 (57%)]\tLoss: 138.602641\n",
      "Train Epoch: 237 [500000/697932 (72%)]\tLoss: 137.757594\n",
      "Train Epoch: 237 [600000/697932 (86%)]\tLoss: 140.992750\n",
      "====> Epoch: 237 Average loss: 138.3454\n",
      "====> Test set loss: 139.3926\n",
      "Train Epoch: 238 [0/697932 (0%)]\tLoss: 135.984969\n",
      "Train Epoch: 238 [100000/697932 (14%)]\tLoss: 137.109609\n",
      "Train Epoch: 238 [200000/697932 (29%)]\tLoss: 138.999094\n",
      "Train Epoch: 238 [300000/697932 (43%)]\tLoss: 138.331437\n",
      "Train Epoch: 238 [400000/697932 (57%)]\tLoss: 138.409281\n",
      "Train Epoch: 238 [500000/697932 (72%)]\tLoss: 139.677141\n",
      "Train Epoch: 238 [600000/697932 (86%)]\tLoss: 139.368047\n",
      "====> Epoch: 238 Average loss: 138.3486\n",
      "====> Test set loss: 139.4583\n",
      "Train Epoch: 239 [0/697932 (0%)]\tLoss: 138.886125\n",
      "Train Epoch: 239 [100000/697932 (14%)]\tLoss: 138.814266\n",
      "Train Epoch: 239 [200000/697932 (29%)]\tLoss: 137.930438\n",
      "Train Epoch: 239 [300000/697932 (43%)]\tLoss: 139.835469\n",
      "Train Epoch: 239 [400000/697932 (57%)]\tLoss: 136.551516\n",
      "Train Epoch: 239 [500000/697932 (72%)]\tLoss: 137.132812\n",
      "Train Epoch: 239 [600000/697932 (86%)]\tLoss: 137.078438\n",
      "====> Epoch: 239 Average loss: 138.3467\n",
      "====> Test set loss: 139.4151\n",
      "Train Epoch: 240 [0/697932 (0%)]\tLoss: 137.542125\n",
      "Train Epoch: 240 [100000/697932 (14%)]\tLoss: 138.935219\n",
      "Train Epoch: 240 [200000/697932 (29%)]\tLoss: 137.439188\n",
      "Train Epoch: 240 [300000/697932 (43%)]\tLoss: 137.409344\n",
      "Train Epoch: 240 [400000/697932 (57%)]\tLoss: 138.830297\n",
      "Train Epoch: 240 [500000/697932 (72%)]\tLoss: 139.009719\n",
      "Train Epoch: 240 [600000/697932 (86%)]\tLoss: 137.959062\n",
      "====> Epoch: 240 Average loss: 138.3456\n",
      "====> Test set loss: 139.4726\n",
      "Train Epoch: 241 [0/697932 (0%)]\tLoss: 136.492031\n",
      "Train Epoch: 241 [100000/697932 (14%)]\tLoss: 139.016812\n",
      "Train Epoch: 241 [200000/697932 (29%)]\tLoss: 139.145000\n",
      "Train Epoch: 241 [300000/697932 (43%)]\tLoss: 137.534938\n",
      "Train Epoch: 241 [400000/697932 (57%)]\tLoss: 138.808812\n",
      "Train Epoch: 241 [500000/697932 (72%)]\tLoss: 136.679953\n",
      "Train Epoch: 241 [600000/697932 (86%)]\tLoss: 139.395266\n",
      "====> Epoch: 241 Average loss: 138.3318\n",
      "====> Test set loss: 139.4947\n",
      "Train Epoch: 242 [0/697932 (0%)]\tLoss: 138.277750\n",
      "Train Epoch: 242 [100000/697932 (14%)]\tLoss: 135.663422\n",
      "Train Epoch: 242 [200000/697932 (29%)]\tLoss: 140.255578\n",
      "Train Epoch: 242 [300000/697932 (43%)]\tLoss: 137.251625\n",
      "Train Epoch: 242 [400000/697932 (57%)]\tLoss: 138.862469\n",
      "Train Epoch: 242 [500000/697932 (72%)]\tLoss: 139.802234\n",
      "Train Epoch: 242 [600000/697932 (86%)]\tLoss: 137.639203\n",
      "====> Epoch: 242 Average loss: 138.3269\n",
      "====> Test set loss: 139.3797\n",
      "Train Epoch: 243 [0/697932 (0%)]\tLoss: 138.102250\n",
      "Train Epoch: 243 [100000/697932 (14%)]\tLoss: 137.907500\n",
      "Train Epoch: 243 [200000/697932 (29%)]\tLoss: 136.935625\n",
      "Train Epoch: 243 [300000/697932 (43%)]\tLoss: 136.877531\n",
      "Train Epoch: 243 [400000/697932 (57%)]\tLoss: 138.158141\n",
      "Train Epoch: 243 [500000/697932 (72%)]\tLoss: 139.022109\n",
      "Train Epoch: 243 [600000/697932 (86%)]\tLoss: 139.167469\n",
      "====> Epoch: 243 Average loss: 138.3234\n",
      "====> Test set loss: 139.4990\n",
      "Train Epoch: 244 [0/697932 (0%)]\tLoss: 138.063469\n",
      "Train Epoch: 244 [100000/697932 (14%)]\tLoss: 135.841500\n",
      "Train Epoch: 244 [200000/697932 (29%)]\tLoss: 138.859938\n",
      "Train Epoch: 244 [300000/697932 (43%)]\tLoss: 138.405781\n",
      "Train Epoch: 244 [400000/697932 (57%)]\tLoss: 137.700375\n",
      "Train Epoch: 244 [500000/697932 (72%)]\tLoss: 137.974766\n",
      "Train Epoch: 244 [600000/697932 (86%)]\tLoss: 139.292563\n",
      "====> Epoch: 244 Average loss: 138.3232\n",
      "====> Test set loss: 139.4120\n",
      "Train Epoch: 245 [0/697932 (0%)]\tLoss: 136.215609\n",
      "Train Epoch: 245 [100000/697932 (14%)]\tLoss: 139.476562\n",
      "Train Epoch: 245 [200000/697932 (29%)]\tLoss: 137.361859\n",
      "Train Epoch: 245 [300000/697932 (43%)]\tLoss: 139.115328\n",
      "Train Epoch: 245 [400000/697932 (57%)]\tLoss: 136.682422\n",
      "Train Epoch: 245 [500000/697932 (72%)]\tLoss: 138.672781\n",
      "Train Epoch: 245 [600000/697932 (86%)]\tLoss: 138.858984\n",
      "====> Epoch: 245 Average loss: 138.3098\n",
      "====> Test set loss: 139.5878\n",
      "Train Epoch: 246 [0/697932 (0%)]\tLoss: 137.959359\n",
      "Train Epoch: 246 [100000/697932 (14%)]\tLoss: 138.788750\n",
      "Train Epoch: 246 [200000/697932 (29%)]\tLoss: 137.948031\n",
      "Train Epoch: 246 [300000/697932 (43%)]\tLoss: 137.687047\n",
      "Train Epoch: 246 [400000/697932 (57%)]\tLoss: 137.059469\n",
      "Train Epoch: 246 [500000/697932 (72%)]\tLoss: 138.630547\n",
      "Train Epoch: 246 [600000/697932 (86%)]\tLoss: 140.770047\n",
      "====> Epoch: 246 Average loss: 138.3111\n",
      "====> Test set loss: 139.4900\n",
      "Train Epoch: 247 [0/697932 (0%)]\tLoss: 138.735969\n",
      "Train Epoch: 247 [100000/697932 (14%)]\tLoss: 137.268563\n",
      "Train Epoch: 247 [200000/697932 (29%)]\tLoss: 138.656281\n",
      "Train Epoch: 247 [300000/697932 (43%)]\tLoss: 138.007656\n",
      "Train Epoch: 247 [400000/697932 (57%)]\tLoss: 139.748875\n",
      "Train Epoch: 247 [500000/697932 (72%)]\tLoss: 137.174781\n",
      "Train Epoch: 247 [600000/697932 (86%)]\tLoss: 137.711078\n",
      "====> Epoch: 247 Average loss: 138.3106\n",
      "====> Test set loss: 139.4058\n",
      "Train Epoch: 248 [0/697932 (0%)]\tLoss: 139.374063\n",
      "Train Epoch: 248 [100000/697932 (14%)]\tLoss: 138.015281\n",
      "Train Epoch: 248 [200000/697932 (29%)]\tLoss: 135.671406\n",
      "Train Epoch: 248 [300000/697932 (43%)]\tLoss: 137.602062\n",
      "Train Epoch: 248 [400000/697932 (57%)]\tLoss: 137.346438\n",
      "Train Epoch: 248 [500000/697932 (72%)]\tLoss: 139.461813\n",
      "Train Epoch: 248 [600000/697932 (86%)]\tLoss: 139.030000\n",
      "====> Epoch: 248 Average loss: 138.3122\n",
      "====> Test set loss: 139.4024\n",
      "Train Epoch: 249 [0/697932 (0%)]\tLoss: 137.978906\n",
      "Train Epoch: 249 [100000/697932 (14%)]\tLoss: 139.173594\n",
      "Train Epoch: 249 [200000/697932 (29%)]\tLoss: 137.846750\n",
      "Train Epoch: 249 [300000/697932 (43%)]\tLoss: 136.071203\n",
      "Train Epoch: 249 [400000/697932 (57%)]\tLoss: 138.071922\n",
      "Train Epoch: 249 [500000/697932 (72%)]\tLoss: 139.735984\n",
      "Train Epoch: 249 [600000/697932 (86%)]\tLoss: 138.913375\n",
      "====> Epoch: 249 Average loss: 138.2990\n",
      "====> Test set loss: 139.4420\n",
      "Train Epoch: 250 [0/697932 (0%)]\tLoss: 138.825250\n",
      "Train Epoch: 250 [100000/697932 (14%)]\tLoss: 139.840094\n",
      "Train Epoch: 250 [200000/697932 (29%)]\tLoss: 137.004562\n",
      "Train Epoch: 250 [300000/697932 (43%)]\tLoss: 139.150500\n",
      "Train Epoch: 250 [400000/697932 (57%)]\tLoss: 138.146953\n",
      "Train Epoch: 250 [500000/697932 (72%)]\tLoss: 138.961766\n",
      "Train Epoch: 250 [600000/697932 (86%)]\tLoss: 137.922922\n",
      "====> Epoch: 250 Average loss: 138.3015\n",
      "====> Test set loss: 139.3947\n",
      "Train Epoch: 251 [0/697932 (0%)]\tLoss: 138.822516\n",
      "Train Epoch: 251 [100000/697932 (14%)]\tLoss: 140.304578\n",
      "Train Epoch: 251 [200000/697932 (29%)]\tLoss: 139.044813\n",
      "Train Epoch: 251 [300000/697932 (43%)]\tLoss: 140.363859\n",
      "Train Epoch: 251 [400000/697932 (57%)]\tLoss: 138.438281\n",
      "Train Epoch: 251 [500000/697932 (72%)]\tLoss: 138.856906\n",
      "Train Epoch: 251 [600000/697932 (86%)]\tLoss: 138.846156\n",
      "====> Epoch: 251 Average loss: 138.3046\n",
      "====> Test set loss: 139.4107\n",
      "Train Epoch: 252 [0/697932 (0%)]\tLoss: 138.139344\n",
      "Train Epoch: 252 [100000/697932 (14%)]\tLoss: 136.083219\n",
      "Train Epoch: 252 [200000/697932 (29%)]\tLoss: 137.789500\n",
      "Train Epoch: 252 [300000/697932 (43%)]\tLoss: 138.174141\n",
      "Train Epoch: 252 [400000/697932 (57%)]\tLoss: 137.592672\n",
      "Train Epoch: 252 [500000/697932 (72%)]\tLoss: 136.438547\n",
      "Train Epoch: 252 [600000/697932 (86%)]\tLoss: 137.707719\n",
      "====> Epoch: 252 Average loss: 138.2731\n",
      "====> Test set loss: 139.5671\n",
      "Train Epoch: 253 [0/697932 (0%)]\tLoss: 137.289922\n",
      "Train Epoch: 253 [100000/697932 (14%)]\tLoss: 138.635750\n",
      "Train Epoch: 253 [200000/697932 (29%)]\tLoss: 137.774984\n",
      "Train Epoch: 253 [300000/697932 (43%)]\tLoss: 137.911781\n",
      "Train Epoch: 253 [400000/697932 (57%)]\tLoss: 139.762281\n",
      "Train Epoch: 253 [500000/697932 (72%)]\tLoss: 138.337891\n",
      "Train Epoch: 253 [600000/697932 (86%)]\tLoss: 137.949516\n",
      "====> Epoch: 253 Average loss: 138.2837\n",
      "====> Test set loss: 139.3533\n",
      "Train Epoch: 254 [0/697932 (0%)]\tLoss: 136.746750\n",
      "Train Epoch: 254 [100000/697932 (14%)]\tLoss: 139.373781\n",
      "Train Epoch: 254 [200000/697932 (29%)]\tLoss: 139.373141\n",
      "Train Epoch: 254 [300000/697932 (43%)]\tLoss: 138.485125\n",
      "Train Epoch: 254 [400000/697932 (57%)]\tLoss: 137.688266\n",
      "Train Epoch: 254 [500000/697932 (72%)]\tLoss: 137.545656\n",
      "Train Epoch: 254 [600000/697932 (86%)]\tLoss: 137.839781\n",
      "====> Epoch: 254 Average loss: 138.2925\n",
      "====> Test set loss: 139.3353\n",
      "Train Epoch: 255 [0/697932 (0%)]\tLoss: 137.638047\n",
      "Train Epoch: 255 [100000/697932 (14%)]\tLoss: 138.369391\n",
      "Train Epoch: 255 [200000/697932 (29%)]\tLoss: 138.571547\n",
      "Train Epoch: 255 [300000/697932 (43%)]\tLoss: 138.538500\n",
      "Train Epoch: 255 [400000/697932 (57%)]\tLoss: 138.480672\n",
      "Train Epoch: 255 [500000/697932 (72%)]\tLoss: 137.753469\n",
      "Train Epoch: 255 [600000/697932 (86%)]\tLoss: 138.640094\n",
      "====> Epoch: 255 Average loss: 138.2555\n",
      "====> Test set loss: 139.3813\n",
      "Train Epoch: 256 [0/697932 (0%)]\tLoss: 137.320125\n",
      "Train Epoch: 256 [100000/697932 (14%)]\tLoss: 139.795125\n",
      "Train Epoch: 256 [200000/697932 (29%)]\tLoss: 139.116766\n",
      "Train Epoch: 256 [300000/697932 (43%)]\tLoss: 138.431344\n",
      "Train Epoch: 256 [400000/697932 (57%)]\tLoss: 137.804250\n",
      "Train Epoch: 256 [500000/697932 (72%)]\tLoss: 138.110219\n",
      "Train Epoch: 256 [600000/697932 (86%)]\tLoss: 138.499516\n",
      "====> Epoch: 256 Average loss: 138.2848\n",
      "====> Test set loss: 139.3576\n",
      "Train Epoch: 257 [0/697932 (0%)]\tLoss: 139.329969\n",
      "Train Epoch: 257 [100000/697932 (14%)]\tLoss: 138.819031\n",
      "Train Epoch: 257 [200000/697932 (29%)]\tLoss: 137.120344\n",
      "Train Epoch: 257 [300000/697932 (43%)]\tLoss: 138.735609\n",
      "Train Epoch: 257 [400000/697932 (57%)]\tLoss: 139.615641\n",
      "Train Epoch: 257 [500000/697932 (72%)]\tLoss: 137.765969\n",
      "Train Epoch: 257 [600000/697932 (86%)]\tLoss: 137.680906\n",
      "====> Epoch: 257 Average loss: 138.2789\n",
      "====> Test set loss: 139.6125\n",
      "Train Epoch: 258 [0/697932 (0%)]\tLoss: 140.120656\n",
      "Train Epoch: 258 [100000/697932 (14%)]\tLoss: 138.811578\n",
      "Train Epoch: 258 [200000/697932 (29%)]\tLoss: 139.444391\n",
      "Train Epoch: 258 [300000/697932 (43%)]\tLoss: 138.498875\n",
      "Train Epoch: 258 [400000/697932 (57%)]\tLoss: 137.746125\n",
      "Train Epoch: 258 [500000/697932 (72%)]\tLoss: 139.119500\n",
      "Train Epoch: 258 [600000/697932 (86%)]\tLoss: 136.845656\n",
      "====> Epoch: 258 Average loss: 138.2553\n",
      "====> Test set loss: 139.4743\n",
      "Train Epoch: 259 [0/697932 (0%)]\tLoss: 138.513234\n",
      "Train Epoch: 259 [100000/697932 (14%)]\tLoss: 136.987516\n",
      "Train Epoch: 259 [200000/697932 (29%)]\tLoss: 138.280984\n",
      "Train Epoch: 259 [300000/697932 (43%)]\tLoss: 139.810734\n",
      "Train Epoch: 259 [400000/697932 (57%)]\tLoss: 138.405953\n",
      "Train Epoch: 259 [500000/697932 (72%)]\tLoss: 137.122000\n",
      "Train Epoch: 259 [600000/697932 (86%)]\tLoss: 138.859187\n",
      "====> Epoch: 259 Average loss: 138.2552\n",
      "====> Test set loss: 139.3793\n",
      "Train Epoch: 260 [0/697932 (0%)]\tLoss: 139.196766\n",
      "Train Epoch: 260 [100000/697932 (14%)]\tLoss: 140.370719\n",
      "Train Epoch: 260 [200000/697932 (29%)]\tLoss: 139.360828\n",
      "Train Epoch: 260 [300000/697932 (43%)]\tLoss: 138.387625\n",
      "Train Epoch: 260 [400000/697932 (57%)]\tLoss: 137.050844\n",
      "Train Epoch: 260 [500000/697932 (72%)]\tLoss: 138.749016\n",
      "Train Epoch: 260 [600000/697932 (86%)]\tLoss: 138.400391\n",
      "====> Epoch: 260 Average loss: 138.2517\n",
      "====> Test set loss: 139.4844\n",
      "Train Epoch: 261 [0/697932 (0%)]\tLoss: 136.085984\n",
      "Train Epoch: 261 [100000/697932 (14%)]\tLoss: 137.307656\n",
      "Train Epoch: 261 [200000/697932 (29%)]\tLoss: 138.525828\n",
      "Train Epoch: 261 [300000/697932 (43%)]\tLoss: 137.845531\n",
      "Train Epoch: 261 [400000/697932 (57%)]\tLoss: 138.556312\n",
      "Train Epoch: 261 [500000/697932 (72%)]\tLoss: 141.477563\n",
      "Train Epoch: 261 [600000/697932 (86%)]\tLoss: 136.849938\n",
      "====> Epoch: 261 Average loss: 138.2453\n",
      "====> Test set loss: 139.4528\n",
      "Train Epoch: 262 [0/697932 (0%)]\tLoss: 139.400000\n",
      "Train Epoch: 262 [100000/697932 (14%)]\tLoss: 136.998750\n",
      "Train Epoch: 262 [200000/697932 (29%)]\tLoss: 138.023734\n",
      "Train Epoch: 262 [300000/697932 (43%)]\tLoss: 135.200734\n",
      "Train Epoch: 262 [400000/697932 (57%)]\tLoss: 138.862812\n",
      "Train Epoch: 262 [500000/697932 (72%)]\tLoss: 139.253312\n",
      "Train Epoch: 262 [600000/697932 (86%)]\tLoss: 138.856109\n",
      "====> Epoch: 262 Average loss: 138.2565\n",
      "====> Test set loss: 139.3768\n",
      "Train Epoch: 263 [0/697932 (0%)]\tLoss: 139.644984\n",
      "Train Epoch: 263 [100000/697932 (14%)]\tLoss: 136.807375\n",
      "Train Epoch: 263 [200000/697932 (29%)]\tLoss: 137.551922\n",
      "Train Epoch: 263 [300000/697932 (43%)]\tLoss: 139.497125\n",
      "Train Epoch: 263 [400000/697932 (57%)]\tLoss: 138.091156\n",
      "Train Epoch: 263 [500000/697932 (72%)]\tLoss: 138.406219\n",
      "Train Epoch: 263 [600000/697932 (86%)]\tLoss: 137.589281\n",
      "====> Epoch: 263 Average loss: 138.2521\n",
      "====> Test set loss: 139.4086\n",
      "Train Epoch: 264 [0/697932 (0%)]\tLoss: 138.306062\n",
      "Train Epoch: 264 [100000/697932 (14%)]\tLoss: 136.935625\n",
      "Train Epoch: 264 [200000/697932 (29%)]\tLoss: 138.038094\n",
      "Train Epoch: 264 [300000/697932 (43%)]\tLoss: 139.524719\n",
      "Train Epoch: 264 [400000/697932 (57%)]\tLoss: 139.126844\n",
      "Train Epoch: 264 [500000/697932 (72%)]\tLoss: 139.300531\n",
      "Train Epoch: 264 [600000/697932 (86%)]\tLoss: 138.376219\n",
      "====> Epoch: 264 Average loss: 138.2395\n",
      "====> Test set loss: 139.3977\n",
      "Train Epoch: 265 [0/697932 (0%)]\tLoss: 137.299797\n",
      "Train Epoch: 265 [100000/697932 (14%)]\tLoss: 139.101922\n",
      "Train Epoch: 265 [200000/697932 (29%)]\tLoss: 137.777500\n",
      "Train Epoch: 265 [300000/697932 (43%)]\tLoss: 138.862359\n",
      "Train Epoch: 265 [400000/697932 (57%)]\tLoss: 136.553406\n",
      "Train Epoch: 265 [500000/697932 (72%)]\tLoss: 138.992828\n",
      "Train Epoch: 265 [600000/697932 (86%)]\tLoss: 137.700094\n",
      "====> Epoch: 265 Average loss: 138.2458\n",
      "====> Test set loss: 139.4479\n",
      "Train Epoch: 266 [0/697932 (0%)]\tLoss: 135.053125\n",
      "Train Epoch: 266 [100000/697932 (14%)]\tLoss: 137.918094\n",
      "Train Epoch: 266 [200000/697932 (29%)]\tLoss: 138.090531\n",
      "Train Epoch: 266 [300000/697932 (43%)]\tLoss: 138.062484\n",
      "Train Epoch: 266 [400000/697932 (57%)]\tLoss: 137.335187\n",
      "Train Epoch: 266 [500000/697932 (72%)]\tLoss: 137.978094\n",
      "Train Epoch: 266 [600000/697932 (86%)]\tLoss: 137.350313\n",
      "====> Epoch: 266 Average loss: 138.2257\n",
      "====> Test set loss: 139.3616\n",
      "Train Epoch: 267 [0/697932 (0%)]\tLoss: 138.779656\n",
      "Train Epoch: 267 [100000/697932 (14%)]\tLoss: 135.005875\n",
      "Train Epoch: 267 [200000/697932 (29%)]\tLoss: 137.785281\n",
      "Train Epoch: 267 [300000/697932 (43%)]\tLoss: 138.665812\n",
      "Train Epoch: 267 [400000/697932 (57%)]\tLoss: 138.266547\n",
      "Train Epoch: 267 [500000/697932 (72%)]\tLoss: 138.611641\n",
      "Train Epoch: 267 [600000/697932 (86%)]\tLoss: 135.945156\n",
      "====> Epoch: 267 Average loss: 138.2267\n",
      "====> Test set loss: 139.5112\n",
      "Train Epoch: 268 [0/697932 (0%)]\tLoss: 136.731766\n",
      "Train Epoch: 268 [100000/697932 (14%)]\tLoss: 139.949906\n",
      "Train Epoch: 268 [200000/697932 (29%)]\tLoss: 138.700578\n",
      "Train Epoch: 268 [300000/697932 (43%)]\tLoss: 138.805047\n",
      "Train Epoch: 268 [400000/697932 (57%)]\tLoss: 135.215156\n",
      "Train Epoch: 268 [500000/697932 (72%)]\tLoss: 137.313141\n",
      "Train Epoch: 268 [600000/697932 (86%)]\tLoss: 136.788312\n",
      "====> Epoch: 268 Average loss: 138.2298\n",
      "====> Test set loss: 139.4331\n",
      "Train Epoch: 269 [0/697932 (0%)]\tLoss: 135.973203\n",
      "Train Epoch: 269 [100000/697932 (14%)]\tLoss: 139.281594\n",
      "Train Epoch: 269 [200000/697932 (29%)]\tLoss: 136.428578\n",
      "Train Epoch: 269 [300000/697932 (43%)]\tLoss: 137.908813\n",
      "Train Epoch: 269 [400000/697932 (57%)]\tLoss: 139.672594\n",
      "Train Epoch: 269 [500000/697932 (72%)]\tLoss: 137.128437\n",
      "Train Epoch: 269 [600000/697932 (86%)]\tLoss: 138.025547\n",
      "====> Epoch: 269 Average loss: 138.2231\n",
      "====> Test set loss: 139.4780\n",
      "Train Epoch: 270 [0/697932 (0%)]\tLoss: 138.302562\n",
      "Train Epoch: 270 [100000/697932 (14%)]\tLoss: 137.909781\n",
      "Train Epoch: 270 [200000/697932 (29%)]\tLoss: 139.615422\n",
      "Train Epoch: 270 [300000/697932 (43%)]\tLoss: 136.279859\n",
      "Train Epoch: 270 [400000/697932 (57%)]\tLoss: 138.865797\n",
      "Train Epoch: 270 [500000/697932 (72%)]\tLoss: 139.407219\n",
      "Train Epoch: 270 [600000/697932 (86%)]\tLoss: 138.752781\n",
      "====> Epoch: 270 Average loss: 138.2153\n",
      "====> Test set loss: 139.3950\n",
      "Train Epoch: 271 [0/697932 (0%)]\tLoss: 139.513688\n",
      "Train Epoch: 271 [100000/697932 (14%)]\tLoss: 136.263125\n",
      "Train Epoch: 271 [200000/697932 (29%)]\tLoss: 138.354656\n",
      "Train Epoch: 271 [300000/697932 (43%)]\tLoss: 138.005812\n",
      "Train Epoch: 271 [400000/697932 (57%)]\tLoss: 137.422953\n",
      "Train Epoch: 271 [500000/697932 (72%)]\tLoss: 139.190391\n",
      "Train Epoch: 271 [600000/697932 (86%)]\tLoss: 137.701906\n",
      "====> Epoch: 271 Average loss: 138.2229\n",
      "====> Test set loss: 139.4379\n",
      "Train Epoch: 272 [0/697932 (0%)]\tLoss: 137.731063\n",
      "Train Epoch: 272 [100000/697932 (14%)]\tLoss: 139.226297\n",
      "Train Epoch: 272 [200000/697932 (29%)]\tLoss: 137.939391\n",
      "Train Epoch: 272 [300000/697932 (43%)]\tLoss: 138.277406\n",
      "Train Epoch: 272 [400000/697932 (57%)]\tLoss: 139.179937\n",
      "Train Epoch: 272 [500000/697932 (72%)]\tLoss: 139.516734\n",
      "Train Epoch: 272 [600000/697932 (86%)]\tLoss: 138.854781\n",
      "====> Epoch: 272 Average loss: 138.1940\n",
      "====> Test set loss: 139.3582\n",
      "Train Epoch: 273 [0/697932 (0%)]\tLoss: 137.593500\n",
      "Train Epoch: 273 [100000/697932 (14%)]\tLoss: 138.894297\n",
      "Train Epoch: 273 [200000/697932 (29%)]\tLoss: 138.355047\n",
      "Train Epoch: 273 [300000/697932 (43%)]\tLoss: 139.579406\n",
      "Train Epoch: 273 [400000/697932 (57%)]\tLoss: 139.620688\n",
      "Train Epoch: 273 [500000/697932 (72%)]\tLoss: 137.676328\n",
      "Train Epoch: 273 [600000/697932 (86%)]\tLoss: 137.491500\n",
      "====> Epoch: 273 Average loss: 138.2115\n",
      "====> Test set loss: 139.4467\n",
      "Train Epoch: 274 [0/697932 (0%)]\tLoss: 137.587203\n",
      "Train Epoch: 274 [100000/697932 (14%)]\tLoss: 139.198234\n",
      "Train Epoch: 274 [200000/697932 (29%)]\tLoss: 138.329563\n",
      "Train Epoch: 274 [300000/697932 (43%)]\tLoss: 139.536687\n",
      "Train Epoch: 274 [400000/697932 (57%)]\tLoss: 137.663219\n",
      "Train Epoch: 274 [500000/697932 (72%)]\tLoss: 138.754750\n",
      "Train Epoch: 274 [600000/697932 (86%)]\tLoss: 138.964109\n",
      "====> Epoch: 274 Average loss: 138.2084\n",
      "====> Test set loss: 139.5914\n",
      "Train Epoch: 275 [0/697932 (0%)]\tLoss: 139.978312\n",
      "Train Epoch: 275 [100000/697932 (14%)]\tLoss: 139.788750\n",
      "Train Epoch: 275 [200000/697932 (29%)]\tLoss: 138.048359\n",
      "Train Epoch: 275 [300000/697932 (43%)]\tLoss: 137.730781\n",
      "Train Epoch: 275 [400000/697932 (57%)]\tLoss: 138.575422\n",
      "Train Epoch: 275 [500000/697932 (72%)]\tLoss: 136.703094\n",
      "Train Epoch: 275 [600000/697932 (86%)]\tLoss: 140.235781\n",
      "====> Epoch: 275 Average loss: 138.2042\n",
      "====> Test set loss: 139.3124\n",
      "Train Epoch: 276 [0/697932 (0%)]\tLoss: 135.669187\n",
      "Train Epoch: 276 [100000/697932 (14%)]\tLoss: 138.438750\n",
      "Train Epoch: 276 [200000/697932 (29%)]\tLoss: 138.762672\n",
      "Train Epoch: 276 [300000/697932 (43%)]\tLoss: 138.878047\n",
      "Train Epoch: 276 [400000/697932 (57%)]\tLoss: 137.505141\n",
      "Train Epoch: 276 [500000/697932 (72%)]\tLoss: 139.177344\n",
      "Train Epoch: 276 [600000/697932 (86%)]\tLoss: 140.259703\n",
      "====> Epoch: 276 Average loss: 138.2068\n",
      "====> Test set loss: 139.3212\n",
      "Train Epoch: 277 [0/697932 (0%)]\tLoss: 136.057000\n",
      "Train Epoch: 277 [100000/697932 (14%)]\tLoss: 137.953281\n",
      "Train Epoch: 277 [200000/697932 (29%)]\tLoss: 138.926297\n",
      "Train Epoch: 277 [300000/697932 (43%)]\tLoss: 138.247938\n",
      "Train Epoch: 277 [400000/697932 (57%)]\tLoss: 137.121719\n",
      "Train Epoch: 277 [500000/697932 (72%)]\tLoss: 136.967563\n",
      "Train Epoch: 277 [600000/697932 (86%)]\tLoss: 140.402938\n",
      "====> Epoch: 277 Average loss: 138.1944\n",
      "====> Test set loss: 139.3346\n",
      "Train Epoch: 278 [0/697932 (0%)]\tLoss: 136.446266\n",
      "Train Epoch: 278 [100000/697932 (14%)]\tLoss: 138.015437\n",
      "Train Epoch: 278 [200000/697932 (29%)]\tLoss: 137.052328\n",
      "Train Epoch: 278 [300000/697932 (43%)]\tLoss: 135.628297\n",
      "Train Epoch: 278 [400000/697932 (57%)]\tLoss: 139.647437\n",
      "Train Epoch: 278 [500000/697932 (72%)]\tLoss: 136.609922\n",
      "Train Epoch: 278 [600000/697932 (86%)]\tLoss: 138.367078\n",
      "====> Epoch: 278 Average loss: 138.1833\n",
      "====> Test set loss: 139.3356\n",
      "Train Epoch: 279 [0/697932 (0%)]\tLoss: 139.422844\n",
      "Train Epoch: 279 [100000/697932 (14%)]\tLoss: 137.856437\n",
      "Train Epoch: 279 [200000/697932 (29%)]\tLoss: 137.771781\n",
      "Train Epoch: 279 [300000/697932 (43%)]\tLoss: 136.434547\n",
      "Train Epoch: 279 [400000/697932 (57%)]\tLoss: 141.283187\n",
      "Train Epoch: 279 [500000/697932 (72%)]\tLoss: 138.840391\n",
      "Train Epoch: 279 [600000/697932 (86%)]\tLoss: 137.594203\n",
      "====> Epoch: 279 Average loss: 138.1831\n",
      "====> Test set loss: 139.2652\n",
      "Train Epoch: 280 [0/697932 (0%)]\tLoss: 137.141984\n",
      "Train Epoch: 280 [100000/697932 (14%)]\tLoss: 139.045531\n",
      "Train Epoch: 280 [200000/697932 (29%)]\tLoss: 137.653016\n",
      "Train Epoch: 280 [300000/697932 (43%)]\tLoss: 139.680250\n",
      "Train Epoch: 280 [400000/697932 (57%)]\tLoss: 138.556219\n",
      "Train Epoch: 280 [500000/697932 (72%)]\tLoss: 138.370516\n",
      "Train Epoch: 280 [600000/697932 (86%)]\tLoss: 137.957562\n",
      "====> Epoch: 280 Average loss: 138.1697\n",
      "====> Test set loss: 139.4386\n",
      "Train Epoch: 281 [0/697932 (0%)]\tLoss: 138.760875\n",
      "Train Epoch: 281 [100000/697932 (14%)]\tLoss: 137.302172\n",
      "Train Epoch: 281 [200000/697932 (29%)]\tLoss: 138.778938\n",
      "Train Epoch: 281 [300000/697932 (43%)]\tLoss: 139.260656\n",
      "Train Epoch: 281 [400000/697932 (57%)]\tLoss: 138.977578\n",
      "Train Epoch: 281 [500000/697932 (72%)]\tLoss: 137.371500\n",
      "Train Epoch: 281 [600000/697932 (86%)]\tLoss: 136.726313\n",
      "====> Epoch: 281 Average loss: 138.1717\n",
      "====> Test set loss: 139.2181\n",
      "Train Epoch: 282 [0/697932 (0%)]\tLoss: 139.127781\n",
      "Train Epoch: 282 [100000/697932 (14%)]\tLoss: 138.860844\n",
      "Train Epoch: 282 [200000/697932 (29%)]\tLoss: 137.136812\n",
      "Train Epoch: 282 [300000/697932 (43%)]\tLoss: 138.823656\n",
      "Train Epoch: 282 [400000/697932 (57%)]\tLoss: 138.284562\n",
      "Train Epoch: 282 [500000/697932 (72%)]\tLoss: 139.422063\n",
      "Train Epoch: 282 [600000/697932 (86%)]\tLoss: 139.670000\n",
      "====> Epoch: 282 Average loss: 138.1845\n",
      "====> Test set loss: 139.3312\n",
      "Train Epoch: 283 [0/697932 (0%)]\tLoss: 137.780547\n",
      "Train Epoch: 283 [100000/697932 (14%)]\tLoss: 135.342766\n",
      "Train Epoch: 283 [200000/697932 (29%)]\tLoss: 138.084375\n",
      "Train Epoch: 283 [300000/697932 (43%)]\tLoss: 138.388203\n",
      "Train Epoch: 283 [400000/697932 (57%)]\tLoss: 139.714562\n",
      "Train Epoch: 283 [500000/697932 (72%)]\tLoss: 141.139656\n",
      "Train Epoch: 283 [600000/697932 (86%)]\tLoss: 138.441937\n",
      "====> Epoch: 283 Average loss: 138.1606\n",
      "====> Test set loss: 139.2383\n",
      "Train Epoch: 284 [0/697932 (0%)]\tLoss: 134.199594\n",
      "Train Epoch: 284 [100000/697932 (14%)]\tLoss: 139.529000\n",
      "Train Epoch: 284 [200000/697932 (29%)]\tLoss: 139.051984\n",
      "Train Epoch: 284 [300000/697932 (43%)]\tLoss: 140.311031\n",
      "Train Epoch: 284 [400000/697932 (57%)]\tLoss: 139.540719\n",
      "Train Epoch: 284 [500000/697932 (72%)]\tLoss: 138.408594\n",
      "Train Epoch: 284 [600000/697932 (86%)]\tLoss: 138.052406\n",
      "====> Epoch: 284 Average loss: 138.1734\n",
      "====> Test set loss: 139.2850\n",
      "Train Epoch: 285 [0/697932 (0%)]\tLoss: 138.979813\n",
      "Train Epoch: 285 [100000/697932 (14%)]\tLoss: 139.943219\n",
      "Train Epoch: 285 [200000/697932 (29%)]\tLoss: 138.808094\n",
      "Train Epoch: 285 [300000/697932 (43%)]\tLoss: 139.932141\n",
      "Train Epoch: 285 [400000/697932 (57%)]\tLoss: 137.516094\n",
      "Train Epoch: 285 [500000/697932 (72%)]\tLoss: 138.063875\n",
      "Train Epoch: 285 [600000/697932 (86%)]\tLoss: 138.220719\n",
      "====> Epoch: 285 Average loss: 138.1661\n",
      "====> Test set loss: 139.3478\n",
      "Train Epoch: 286 [0/697932 (0%)]\tLoss: 138.326000\n",
      "Train Epoch: 286 [100000/697932 (14%)]\tLoss: 139.141000\n",
      "Train Epoch: 286 [200000/697932 (29%)]\tLoss: 138.039203\n",
      "Train Epoch: 286 [300000/697932 (43%)]\tLoss: 139.071641\n",
      "Train Epoch: 286 [400000/697932 (57%)]\tLoss: 137.241469\n",
      "Train Epoch: 286 [500000/697932 (72%)]\tLoss: 140.049313\n",
      "Train Epoch: 286 [600000/697932 (86%)]\tLoss: 138.020031\n",
      "====> Epoch: 286 Average loss: 138.1600\n",
      "====> Test set loss: 139.2981\n",
      "Train Epoch: 287 [0/697932 (0%)]\tLoss: 136.702578\n",
      "Train Epoch: 287 [100000/697932 (14%)]\tLoss: 137.908828\n",
      "Train Epoch: 287 [200000/697932 (29%)]\tLoss: 138.541578\n",
      "Train Epoch: 287 [300000/697932 (43%)]\tLoss: 137.262625\n",
      "Train Epoch: 287 [400000/697932 (57%)]\tLoss: 138.162422\n",
      "Train Epoch: 287 [500000/697932 (72%)]\tLoss: 139.780578\n",
      "Train Epoch: 287 [600000/697932 (86%)]\tLoss: 137.591516\n",
      "====> Epoch: 287 Average loss: 138.1491\n",
      "====> Test set loss: 139.3953\n",
      "Train Epoch: 288 [0/697932 (0%)]\tLoss: 139.089687\n",
      "Train Epoch: 288 [100000/697932 (14%)]\tLoss: 139.894062\n",
      "Train Epoch: 288 [200000/697932 (29%)]\tLoss: 138.581891\n",
      "Train Epoch: 288 [300000/697932 (43%)]\tLoss: 139.272312\n",
      "Train Epoch: 288 [400000/697932 (57%)]\tLoss: 137.884953\n",
      "Train Epoch: 288 [500000/697932 (72%)]\tLoss: 137.909375\n",
      "Train Epoch: 288 [600000/697932 (86%)]\tLoss: 137.576469\n",
      "====> Epoch: 288 Average loss: 138.1616\n",
      "====> Test set loss: 139.4433\n",
      "Train Epoch: 289 [0/697932 (0%)]\tLoss: 138.527734\n",
      "Train Epoch: 289 [100000/697932 (14%)]\tLoss: 137.743969\n",
      "Train Epoch: 289 [200000/697932 (29%)]\tLoss: 136.566234\n",
      "Train Epoch: 289 [300000/697932 (43%)]\tLoss: 137.067813\n",
      "Train Epoch: 289 [400000/697932 (57%)]\tLoss: 139.166031\n",
      "Train Epoch: 289 [500000/697932 (72%)]\tLoss: 138.707625\n",
      "Train Epoch: 289 [600000/697932 (86%)]\tLoss: 138.797297\n",
      "====> Epoch: 289 Average loss: 138.1385\n",
      "====> Test set loss: 139.2965\n",
      "Train Epoch: 290 [0/697932 (0%)]\tLoss: 136.818547\n",
      "Train Epoch: 290 [100000/697932 (14%)]\tLoss: 137.974469\n",
      "Train Epoch: 290 [200000/697932 (29%)]\tLoss: 140.744781\n",
      "Train Epoch: 290 [300000/697932 (43%)]\tLoss: 137.348094\n",
      "Train Epoch: 290 [400000/697932 (57%)]\tLoss: 137.780234\n",
      "Train Epoch: 290 [500000/697932 (72%)]\tLoss: 138.505031\n",
      "Train Epoch: 290 [600000/697932 (86%)]\tLoss: 140.015688\n",
      "====> Epoch: 290 Average loss: 138.1530\n",
      "====> Test set loss: 139.4393\n",
      "Train Epoch: 291 [0/697932 (0%)]\tLoss: 137.962281\n",
      "Train Epoch: 291 [100000/697932 (14%)]\tLoss: 137.638703\n",
      "Train Epoch: 291 [200000/697932 (29%)]\tLoss: 138.845391\n",
      "Train Epoch: 291 [300000/697932 (43%)]\tLoss: 137.056797\n",
      "Train Epoch: 291 [400000/697932 (57%)]\tLoss: 139.737844\n",
      "Train Epoch: 291 [500000/697932 (72%)]\tLoss: 138.213875\n",
      "Train Epoch: 291 [600000/697932 (86%)]\tLoss: 139.164359\n",
      "====> Epoch: 291 Average loss: 138.1437\n",
      "====> Test set loss: 139.4866\n",
      "Train Epoch: 292 [0/697932 (0%)]\tLoss: 138.433781\n",
      "Train Epoch: 292 [100000/697932 (14%)]\tLoss: 137.661578\n",
      "Train Epoch: 292 [200000/697932 (29%)]\tLoss: 137.459500\n",
      "Train Epoch: 292 [300000/697932 (43%)]\tLoss: 138.087312\n",
      "Train Epoch: 292 [400000/697932 (57%)]\tLoss: 136.978391\n",
      "Train Epoch: 292 [500000/697932 (72%)]\tLoss: 138.805922\n",
      "Train Epoch: 292 [600000/697932 (86%)]\tLoss: 138.016766\n",
      "====> Epoch: 292 Average loss: 138.1419\n",
      "====> Test set loss: 139.3118\n",
      "Train Epoch: 293 [0/697932 (0%)]\tLoss: 137.702313\n",
      "Train Epoch: 293 [100000/697932 (14%)]\tLoss: 137.783281\n",
      "Train Epoch: 293 [200000/697932 (29%)]\tLoss: 138.557641\n",
      "Train Epoch: 293 [300000/697932 (43%)]\tLoss: 136.218422\n",
      "Train Epoch: 293 [400000/697932 (57%)]\tLoss: 139.411125\n",
      "Train Epoch: 293 [500000/697932 (72%)]\tLoss: 136.089875\n",
      "Train Epoch: 293 [600000/697932 (86%)]\tLoss: 138.489875\n",
      "====> Epoch: 293 Average loss: 138.1551\n",
      "====> Test set loss: 139.3284\n",
      "Train Epoch: 294 [0/697932 (0%)]\tLoss: 135.934281\n",
      "Train Epoch: 294 [100000/697932 (14%)]\tLoss: 138.267344\n",
      "Train Epoch: 294 [200000/697932 (29%)]\tLoss: 136.113094\n",
      "Train Epoch: 294 [300000/697932 (43%)]\tLoss: 138.141375\n",
      "Train Epoch: 294 [400000/697932 (57%)]\tLoss: 137.517031\n",
      "Train Epoch: 294 [500000/697932 (72%)]\tLoss: 138.151312\n",
      "Train Epoch: 294 [600000/697932 (86%)]\tLoss: 138.386422\n",
      "====> Epoch: 294 Average loss: 138.1276\n",
      "====> Test set loss: 139.6810\n",
      "Train Epoch: 295 [0/697932 (0%)]\tLoss: 138.736094\n",
      "Train Epoch: 295 [100000/697932 (14%)]\tLoss: 138.427000\n",
      "Train Epoch: 295 [200000/697932 (29%)]\tLoss: 136.729344\n",
      "Train Epoch: 295 [300000/697932 (43%)]\tLoss: 138.741531\n",
      "Train Epoch: 295 [400000/697932 (57%)]\tLoss: 139.739141\n",
      "Train Epoch: 295 [500000/697932 (72%)]\tLoss: 138.573594\n",
      "Train Epoch: 295 [600000/697932 (86%)]\tLoss: 138.460078\n",
      "====> Epoch: 295 Average loss: 138.1294\n",
      "====> Test set loss: 139.2905\n",
      "Train Epoch: 296 [0/697932 (0%)]\tLoss: 137.804188\n",
      "Train Epoch: 296 [100000/697932 (14%)]\tLoss: 138.465156\n",
      "Train Epoch: 296 [200000/697932 (29%)]\tLoss: 136.991672\n",
      "Train Epoch: 296 [300000/697932 (43%)]\tLoss: 138.451906\n",
      "Train Epoch: 296 [400000/697932 (57%)]\tLoss: 137.232734\n",
      "Train Epoch: 296 [500000/697932 (72%)]\tLoss: 137.377234\n",
      "Train Epoch: 296 [600000/697932 (86%)]\tLoss: 139.012594\n",
      "====> Epoch: 296 Average loss: 138.1262\n",
      "====> Test set loss: 139.2597\n",
      "Train Epoch: 297 [0/697932 (0%)]\tLoss: 138.806437\n",
      "Train Epoch: 297 [100000/697932 (14%)]\tLoss: 137.997828\n",
      "Train Epoch: 297 [200000/697932 (29%)]\tLoss: 135.172937\n",
      "Train Epoch: 297 [300000/697932 (43%)]\tLoss: 138.407938\n",
      "Train Epoch: 297 [400000/697932 (57%)]\tLoss: 138.816203\n",
      "Train Epoch: 297 [500000/697932 (72%)]\tLoss: 137.307781\n",
      "Train Epoch: 297 [600000/697932 (86%)]\tLoss: 141.121328\n",
      "====> Epoch: 297 Average loss: 138.1143\n",
      "====> Test set loss: 139.2644\n",
      "Train Epoch: 298 [0/697932 (0%)]\tLoss: 137.244656\n",
      "Train Epoch: 298 [100000/697932 (14%)]\tLoss: 136.722563\n",
      "Train Epoch: 298 [200000/697932 (29%)]\tLoss: 137.077078\n",
      "Train Epoch: 298 [300000/697932 (43%)]\tLoss: 136.429156\n",
      "Train Epoch: 298 [400000/697932 (57%)]\tLoss: 138.499766\n",
      "Train Epoch: 298 [500000/697932 (72%)]\tLoss: 136.846516\n",
      "Train Epoch: 298 [600000/697932 (86%)]\tLoss: 139.050078\n",
      "====> Epoch: 298 Average loss: 138.1092\n",
      "====> Test set loss: 139.2848\n",
      "Train Epoch: 299 [0/697932 (0%)]\tLoss: 137.963000\n",
      "Train Epoch: 299 [100000/697932 (14%)]\tLoss: 137.907734\n",
      "Train Epoch: 299 [200000/697932 (29%)]\tLoss: 136.905719\n",
      "Train Epoch: 299 [300000/697932 (43%)]\tLoss: 138.244234\n",
      "Train Epoch: 299 [400000/697932 (57%)]\tLoss: 136.789688\n",
      "Train Epoch: 299 [500000/697932 (72%)]\tLoss: 138.033797\n",
      "Train Epoch: 299 [600000/697932 (86%)]\tLoss: 137.932781\n",
      "====> Epoch: 299 Average loss: 138.1224\n",
      "====> Test set loss: 139.2734\n",
      "Train Epoch: 300 [0/697932 (0%)]\tLoss: 135.589266\n",
      "Train Epoch: 300 [100000/697932 (14%)]\tLoss: 137.742516\n",
      "Train Epoch: 300 [200000/697932 (29%)]\tLoss: 138.844203\n",
      "Train Epoch: 300 [300000/697932 (43%)]\tLoss: 139.407531\n",
      "Train Epoch: 300 [400000/697932 (57%)]\tLoss: 138.659203\n",
      "Train Epoch: 300 [500000/697932 (72%)]\tLoss: 137.773156\n",
      "Train Epoch: 300 [600000/697932 (86%)]\tLoss: 138.047141\n",
      "====> Epoch: 300 Average loss: 138.1110\n",
      "====> Test set loss: 139.3557\n",
      "Train Epoch: 301 [0/697932 (0%)]\tLoss: 140.009844\n",
      "Train Epoch: 301 [100000/697932 (14%)]\tLoss: 138.001109\n",
      "Train Epoch: 301 [200000/697932 (29%)]\tLoss: 136.786250\n",
      "Train Epoch: 301 [300000/697932 (43%)]\tLoss: 138.390250\n",
      "Train Epoch: 301 [400000/697932 (57%)]\tLoss: 139.287719\n",
      "Train Epoch: 301 [500000/697932 (72%)]\tLoss: 140.307859\n",
      "Train Epoch: 301 [600000/697932 (86%)]\tLoss: 137.811250\n",
      "====> Epoch: 301 Average loss: 138.0921\n",
      "====> Test set loss: 139.4073\n",
      "Train Epoch: 302 [0/697932 (0%)]\tLoss: 139.360516\n",
      "Train Epoch: 302 [100000/697932 (14%)]\tLoss: 137.834031\n",
      "Train Epoch: 302 [200000/697932 (29%)]\tLoss: 137.779469\n",
      "Train Epoch: 302 [300000/697932 (43%)]\tLoss: 136.601328\n",
      "Train Epoch: 302 [400000/697932 (57%)]\tLoss: 137.788750\n",
      "Train Epoch: 302 [500000/697932 (72%)]\tLoss: 138.128797\n",
      "Train Epoch: 302 [600000/697932 (86%)]\tLoss: 138.605250\n",
      "====> Epoch: 302 Average loss: 138.1140\n",
      "====> Test set loss: 139.3808\n",
      "Train Epoch: 303 [0/697932 (0%)]\tLoss: 138.264109\n",
      "Train Epoch: 303 [100000/697932 (14%)]\tLoss: 137.254953\n",
      "Train Epoch: 303 [200000/697932 (29%)]\tLoss: 136.817781\n",
      "Train Epoch: 303 [300000/697932 (43%)]\tLoss: 138.831109\n",
      "Train Epoch: 303 [400000/697932 (57%)]\tLoss: 138.619172\n",
      "Train Epoch: 303 [500000/697932 (72%)]\tLoss: 139.272516\n",
      "Train Epoch: 303 [600000/697932 (86%)]\tLoss: 137.127813\n",
      "====> Epoch: 303 Average loss: 138.0888\n",
      "====> Test set loss: 139.3718\n",
      "Train Epoch: 304 [0/697932 (0%)]\tLoss: 140.430969\n",
      "Train Epoch: 304 [100000/697932 (14%)]\tLoss: 138.375031\n",
      "Train Epoch: 304 [200000/697932 (29%)]\tLoss: 138.019078\n",
      "Train Epoch: 304 [300000/697932 (43%)]\tLoss: 139.820984\n",
      "Train Epoch: 304 [400000/697932 (57%)]\tLoss: 137.871813\n",
      "Train Epoch: 304 [500000/697932 (72%)]\tLoss: 137.258531\n",
      "Train Epoch: 304 [600000/697932 (86%)]\tLoss: 138.355000\n",
      "====> Epoch: 304 Average loss: 138.1021\n",
      "====> Test set loss: 139.3910\n",
      "Train Epoch: 305 [0/697932 (0%)]\tLoss: 139.232328\n",
      "Train Epoch: 305 [100000/697932 (14%)]\tLoss: 137.016469\n",
      "Train Epoch: 305 [200000/697932 (29%)]\tLoss: 137.176922\n",
      "Train Epoch: 305 [300000/697932 (43%)]\tLoss: 137.231141\n",
      "Train Epoch: 305 [400000/697932 (57%)]\tLoss: 136.709594\n",
      "Train Epoch: 305 [500000/697932 (72%)]\tLoss: 137.280359\n",
      "Train Epoch: 305 [600000/697932 (86%)]\tLoss: 139.203953\n",
      "====> Epoch: 305 Average loss: 138.1029\n",
      "====> Test set loss: 139.2486\n",
      "Train Epoch: 306 [0/697932 (0%)]\tLoss: 136.782922\n",
      "Train Epoch: 306 [100000/697932 (14%)]\tLoss: 137.868469\n",
      "Train Epoch: 306 [200000/697932 (29%)]\tLoss: 138.881188\n",
      "Train Epoch: 306 [300000/697932 (43%)]\tLoss: 138.952562\n",
      "Train Epoch: 306 [400000/697932 (57%)]\tLoss: 141.234500\n",
      "Train Epoch: 306 [500000/697932 (72%)]\tLoss: 136.155969\n",
      "Train Epoch: 306 [600000/697932 (86%)]\tLoss: 139.141906\n",
      "====> Epoch: 306 Average loss: 138.0980\n",
      "====> Test set loss: 139.2717\n",
      "Train Epoch: 307 [0/697932 (0%)]\tLoss: 141.991234\n",
      "Train Epoch: 307 [100000/697932 (14%)]\tLoss: 137.839031\n",
      "Train Epoch: 307 [200000/697932 (29%)]\tLoss: 136.636625\n",
      "Train Epoch: 307 [300000/697932 (43%)]\tLoss: 136.588313\n",
      "Train Epoch: 307 [400000/697932 (57%)]\tLoss: 138.931844\n",
      "Train Epoch: 307 [500000/697932 (72%)]\tLoss: 137.142156\n",
      "Train Epoch: 307 [600000/697932 (86%)]\tLoss: 139.120531\n",
      "====> Epoch: 307 Average loss: 138.0685\n",
      "====> Test set loss: 139.2681\n",
      "Train Epoch: 308 [0/697932 (0%)]\tLoss: 138.146156\n",
      "Train Epoch: 308 [100000/697932 (14%)]\tLoss: 136.660078\n",
      "Train Epoch: 308 [200000/697932 (29%)]\tLoss: 138.339234\n",
      "Train Epoch: 308 [300000/697932 (43%)]\tLoss: 138.014250\n",
      "Train Epoch: 308 [400000/697932 (57%)]\tLoss: 138.406781\n",
      "Train Epoch: 308 [500000/697932 (72%)]\tLoss: 137.079281\n",
      "Train Epoch: 308 [600000/697932 (86%)]\tLoss: 139.147156\n",
      "====> Epoch: 308 Average loss: 138.1057\n",
      "====> Test set loss: 139.3472\n",
      "Train Epoch: 309 [0/697932 (0%)]\tLoss: 137.054469\n",
      "Train Epoch: 309 [100000/697932 (14%)]\tLoss: 139.171781\n",
      "Train Epoch: 309 [200000/697932 (29%)]\tLoss: 137.697906\n",
      "Train Epoch: 309 [300000/697932 (43%)]\tLoss: 138.734828\n",
      "Train Epoch: 309 [400000/697932 (57%)]\tLoss: 137.521391\n",
      "Train Epoch: 309 [500000/697932 (72%)]\tLoss: 137.676984\n",
      "Train Epoch: 309 [600000/697932 (86%)]\tLoss: 137.695531\n",
      "====> Epoch: 309 Average loss: 138.0881\n",
      "====> Test set loss: 139.3908\n",
      "Train Epoch: 310 [0/697932 (0%)]\tLoss: 138.663281\n",
      "Train Epoch: 310 [100000/697932 (14%)]\tLoss: 139.006766\n",
      "Train Epoch: 310 [200000/697932 (29%)]\tLoss: 137.513875\n",
      "Train Epoch: 310 [300000/697932 (43%)]\tLoss: 137.874234\n",
      "Train Epoch: 310 [400000/697932 (57%)]\tLoss: 137.510516\n",
      "Train Epoch: 310 [500000/697932 (72%)]\tLoss: 136.906703\n",
      "Train Epoch: 310 [600000/697932 (86%)]\tLoss: 137.946297\n",
      "====> Epoch: 310 Average loss: 138.0878\n",
      "====> Test set loss: 139.3255\n",
      "Train Epoch: 311 [0/697932 (0%)]\tLoss: 137.349047\n",
      "Train Epoch: 311 [100000/697932 (14%)]\tLoss: 140.738156\n",
      "Train Epoch: 311 [200000/697932 (29%)]\tLoss: 140.019547\n",
      "Train Epoch: 311 [300000/697932 (43%)]\tLoss: 139.712406\n",
      "Train Epoch: 311 [400000/697932 (57%)]\tLoss: 136.208578\n",
      "Train Epoch: 311 [500000/697932 (72%)]\tLoss: 136.584656\n",
      "Train Epoch: 311 [600000/697932 (86%)]\tLoss: 137.905828\n",
      "====> Epoch: 311 Average loss: 138.0749\n",
      "====> Test set loss: 139.3996\n",
      "Train Epoch: 312 [0/697932 (0%)]\tLoss: 137.322563\n",
      "Train Epoch: 312 [100000/697932 (14%)]\tLoss: 138.704625\n",
      "Train Epoch: 312 [200000/697932 (29%)]\tLoss: 135.821906\n",
      "Train Epoch: 312 [300000/697932 (43%)]\tLoss: 139.080625\n",
      "Train Epoch: 312 [400000/697932 (57%)]\tLoss: 138.989250\n",
      "Train Epoch: 312 [500000/697932 (72%)]\tLoss: 136.612234\n",
      "Train Epoch: 312 [600000/697932 (86%)]\tLoss: 138.629625\n",
      "====> Epoch: 312 Average loss: 138.0844\n",
      "====> Test set loss: 139.2349\n",
      "Train Epoch: 313 [0/697932 (0%)]\tLoss: 140.667953\n",
      "Train Epoch: 313 [100000/697932 (14%)]\tLoss: 137.149828\n",
      "Train Epoch: 313 [200000/697932 (29%)]\tLoss: 136.809469\n",
      "Train Epoch: 313 [300000/697932 (43%)]\tLoss: 135.942469\n",
      "Train Epoch: 313 [400000/697932 (57%)]\tLoss: 137.945500\n",
      "Train Epoch: 313 [500000/697932 (72%)]\tLoss: 138.862984\n",
      "Train Epoch: 313 [600000/697932 (86%)]\tLoss: 138.025625\n",
      "====> Epoch: 313 Average loss: 138.0860\n",
      "====> Test set loss: 139.3019\n",
      "Train Epoch: 314 [0/697932 (0%)]\tLoss: 137.494047\n",
      "Train Epoch: 314 [100000/697932 (14%)]\tLoss: 136.154313\n",
      "Train Epoch: 314 [200000/697932 (29%)]\tLoss: 138.206219\n",
      "Train Epoch: 314 [300000/697932 (43%)]\tLoss: 139.273094\n",
      "Train Epoch: 314 [400000/697932 (57%)]\tLoss: 140.189422\n",
      "Train Epoch: 314 [500000/697932 (72%)]\tLoss: 139.262969\n",
      "Train Epoch: 314 [600000/697932 (86%)]\tLoss: 137.946063\n",
      "====> Epoch: 314 Average loss: 138.0759\n",
      "====> Test set loss: 139.2350\n",
      "Train Epoch: 315 [0/697932 (0%)]\tLoss: 139.097672\n",
      "Train Epoch: 315 [100000/697932 (14%)]\tLoss: 136.830797\n",
      "Train Epoch: 315 [200000/697932 (29%)]\tLoss: 140.548578\n",
      "Train Epoch: 315 [300000/697932 (43%)]\tLoss: 139.198234\n",
      "Train Epoch: 315 [400000/697932 (57%)]\tLoss: 137.572203\n",
      "Train Epoch: 315 [500000/697932 (72%)]\tLoss: 139.423734\n",
      "Train Epoch: 315 [600000/697932 (86%)]\tLoss: 139.163109\n",
      "====> Epoch: 315 Average loss: 138.0565\n",
      "====> Test set loss: 139.2843\n",
      "Train Epoch: 316 [0/697932 (0%)]\tLoss: 137.087187\n",
      "Train Epoch: 316 [100000/697932 (14%)]\tLoss: 138.042563\n",
      "Train Epoch: 316 [200000/697932 (29%)]\tLoss: 138.435563\n",
      "Train Epoch: 316 [300000/697932 (43%)]\tLoss: 135.397219\n",
      "Train Epoch: 316 [400000/697932 (57%)]\tLoss: 138.844844\n",
      "Train Epoch: 316 [500000/697932 (72%)]\tLoss: 137.009078\n",
      "Train Epoch: 316 [600000/697932 (86%)]\tLoss: 139.961500\n",
      "====> Epoch: 316 Average loss: 138.0753\n",
      "====> Test set loss: 139.3238\n",
      "Train Epoch: 317 [0/697932 (0%)]\tLoss: 138.596313\n",
      "Train Epoch: 317 [100000/697932 (14%)]\tLoss: 136.973406\n",
      "Train Epoch: 317 [200000/697932 (29%)]\tLoss: 137.220422\n",
      "Train Epoch: 317 [300000/697932 (43%)]\tLoss: 138.154703\n",
      "Train Epoch: 317 [400000/697932 (57%)]\tLoss: 139.243188\n",
      "Train Epoch: 317 [500000/697932 (72%)]\tLoss: 138.356281\n",
      "Train Epoch: 317 [600000/697932 (86%)]\tLoss: 136.491281\n",
      "====> Epoch: 317 Average loss: 138.0599\n",
      "====> Test set loss: 139.3356\n",
      "Train Epoch: 318 [0/697932 (0%)]\tLoss: 138.945594\n",
      "Train Epoch: 318 [100000/697932 (14%)]\tLoss: 137.302766\n",
      "Train Epoch: 318 [200000/697932 (29%)]\tLoss: 136.969141\n",
      "Train Epoch: 318 [300000/697932 (43%)]\tLoss: 137.496266\n",
      "Train Epoch: 318 [400000/697932 (57%)]\tLoss: 136.850375\n",
      "Train Epoch: 318 [500000/697932 (72%)]\tLoss: 138.052469\n",
      "Train Epoch: 318 [600000/697932 (86%)]\tLoss: 139.260656\n",
      "====> Epoch: 318 Average loss: 138.0660\n",
      "====> Test set loss: 139.3047\n",
      "Train Epoch: 319 [0/697932 (0%)]\tLoss: 137.288641\n",
      "Train Epoch: 319 [100000/697932 (14%)]\tLoss: 137.257922\n",
      "Train Epoch: 319 [200000/697932 (29%)]\tLoss: 135.386953\n",
      "Train Epoch: 319 [300000/697932 (43%)]\tLoss: 137.824563\n",
      "Train Epoch: 319 [400000/697932 (57%)]\tLoss: 138.310922\n",
      "Train Epoch: 319 [500000/697932 (72%)]\tLoss: 139.486063\n",
      "Train Epoch: 319 [600000/697932 (86%)]\tLoss: 139.226594\n",
      "====> Epoch: 319 Average loss: 138.0515\n",
      "====> Test set loss: 139.2881\n",
      "Train Epoch: 320 [0/697932 (0%)]\tLoss: 139.067266\n",
      "Train Epoch: 320 [100000/697932 (14%)]\tLoss: 135.677453\n",
      "Train Epoch: 320 [200000/697932 (29%)]\tLoss: 137.019344\n",
      "Train Epoch: 320 [300000/697932 (43%)]\tLoss: 139.475250\n",
      "Train Epoch: 320 [400000/697932 (57%)]\tLoss: 136.985094\n",
      "Train Epoch: 320 [500000/697932 (72%)]\tLoss: 137.485719\n",
      "Train Epoch: 320 [600000/697932 (86%)]\tLoss: 138.065438\n",
      "====> Epoch: 320 Average loss: 138.0574\n",
      "====> Test set loss: 139.2639\n",
      "Train Epoch: 321 [0/697932 (0%)]\tLoss: 136.868141\n",
      "Train Epoch: 321 [100000/697932 (14%)]\tLoss: 137.699844\n",
      "Train Epoch: 321 [200000/697932 (29%)]\tLoss: 136.955047\n",
      "Train Epoch: 321 [300000/697932 (43%)]\tLoss: 137.611437\n",
      "Train Epoch: 321 [400000/697932 (57%)]\tLoss: 137.685516\n",
      "Train Epoch: 321 [500000/697932 (72%)]\tLoss: 138.586359\n",
      "Train Epoch: 321 [600000/697932 (86%)]\tLoss: 138.194500\n",
      "====> Epoch: 321 Average loss: 138.0527\n",
      "====> Test set loss: 139.2370\n",
      "Train Epoch: 322 [0/697932 (0%)]\tLoss: 136.716062\n",
      "Train Epoch: 322 [100000/697932 (14%)]\tLoss: 137.803969\n",
      "Train Epoch: 322 [200000/697932 (29%)]\tLoss: 139.229312\n",
      "Train Epoch: 322 [300000/697932 (43%)]\tLoss: 138.133938\n",
      "Train Epoch: 322 [400000/697932 (57%)]\tLoss: 136.785812\n",
      "Train Epoch: 322 [500000/697932 (72%)]\tLoss: 137.331000\n",
      "Train Epoch: 322 [600000/697932 (86%)]\tLoss: 138.311109\n",
      "====> Epoch: 322 Average loss: 138.0538\n",
      "====> Test set loss: 139.3479\n",
      "Train Epoch: 323 [0/697932 (0%)]\tLoss: 138.540281\n",
      "Train Epoch: 323 [100000/697932 (14%)]\tLoss: 136.582391\n",
      "Train Epoch: 323 [200000/697932 (29%)]\tLoss: 136.358672\n",
      "Train Epoch: 323 [300000/697932 (43%)]\tLoss: 138.977375\n",
      "Train Epoch: 323 [400000/697932 (57%)]\tLoss: 137.410859\n",
      "Train Epoch: 323 [500000/697932 (72%)]\tLoss: 137.646547\n",
      "Train Epoch: 323 [600000/697932 (86%)]\tLoss: 139.987531\n",
      "====> Epoch: 323 Average loss: 138.0466\n",
      "====> Test set loss: 139.3465\n",
      "Train Epoch: 324 [0/697932 (0%)]\tLoss: 136.510844\n",
      "Train Epoch: 324 [100000/697932 (14%)]\tLoss: 136.268250\n",
      "Train Epoch: 324 [200000/697932 (29%)]\tLoss: 137.542969\n",
      "Train Epoch: 324 [300000/697932 (43%)]\tLoss: 137.930969\n",
      "Train Epoch: 324 [400000/697932 (57%)]\tLoss: 138.296844\n",
      "Train Epoch: 324 [500000/697932 (72%)]\tLoss: 138.831453\n",
      "Train Epoch: 324 [600000/697932 (86%)]\tLoss: 138.507531\n",
      "====> Epoch: 324 Average loss: 138.0402\n",
      "====> Test set loss: 139.3157\n",
      "Train Epoch: 325 [0/697932 (0%)]\tLoss: 137.145703\n",
      "Train Epoch: 325 [100000/697932 (14%)]\tLoss: 137.658125\n",
      "Train Epoch: 325 [200000/697932 (29%)]\tLoss: 139.615312\n",
      "Train Epoch: 325 [300000/697932 (43%)]\tLoss: 137.931281\n",
      "Train Epoch: 325 [400000/697932 (57%)]\tLoss: 136.860781\n",
      "Train Epoch: 325 [500000/697932 (72%)]\tLoss: 136.331156\n",
      "Train Epoch: 325 [600000/697932 (86%)]\tLoss: 139.081781\n",
      "====> Epoch: 325 Average loss: 138.0606\n",
      "====> Test set loss: 139.2795\n",
      "Train Epoch: 326 [0/697932 (0%)]\tLoss: 138.761594\n",
      "Train Epoch: 326 [100000/697932 (14%)]\tLoss: 137.891672\n",
      "Train Epoch: 326 [200000/697932 (29%)]\tLoss: 139.319203\n",
      "Train Epoch: 326 [300000/697932 (43%)]\tLoss: 138.372875\n",
      "Train Epoch: 326 [400000/697932 (57%)]\tLoss: 140.393031\n",
      "Train Epoch: 326 [500000/697932 (72%)]\tLoss: 137.948156\n",
      "Train Epoch: 326 [600000/697932 (86%)]\tLoss: 137.354641\n",
      "====> Epoch: 326 Average loss: 138.0300\n",
      "====> Test set loss: 139.2822\n",
      "Train Epoch: 327 [0/697932 (0%)]\tLoss: 135.556656\n",
      "Train Epoch: 327 [100000/697932 (14%)]\tLoss: 138.851734\n",
      "Train Epoch: 327 [200000/697932 (29%)]\tLoss: 138.992875\n",
      "Train Epoch: 327 [300000/697932 (43%)]\tLoss: 139.097406\n",
      "Train Epoch: 327 [400000/697932 (57%)]\tLoss: 140.227125\n",
      "Train Epoch: 327 [500000/697932 (72%)]\tLoss: 138.347813\n",
      "Train Epoch: 327 [600000/697932 (86%)]\tLoss: 139.854547\n",
      "====> Epoch: 327 Average loss: 138.0402\n",
      "====> Test set loss: 139.3094\n",
      "Train Epoch: 328 [0/697932 (0%)]\tLoss: 135.854437\n",
      "Train Epoch: 328 [100000/697932 (14%)]\tLoss: 136.287844\n",
      "Train Epoch: 328 [200000/697932 (29%)]\tLoss: 138.870984\n",
      "Train Epoch: 328 [300000/697932 (43%)]\tLoss: 139.382438\n",
      "Train Epoch: 328 [400000/697932 (57%)]\tLoss: 138.213156\n",
      "Train Epoch: 328 [500000/697932 (72%)]\tLoss: 138.006391\n",
      "Train Epoch: 328 [600000/697932 (86%)]\tLoss: 138.362625\n",
      "====> Epoch: 328 Average loss: 138.0355\n",
      "====> Test set loss: 139.2481\n",
      "Train Epoch: 329 [0/697932 (0%)]\tLoss: 137.635063\n",
      "Train Epoch: 329 [100000/697932 (14%)]\tLoss: 139.012547\n",
      "Train Epoch: 329 [200000/697932 (29%)]\tLoss: 138.951922\n",
      "Train Epoch: 329 [300000/697932 (43%)]\tLoss: 135.956187\n",
      "Train Epoch: 329 [400000/697932 (57%)]\tLoss: 137.378719\n",
      "Train Epoch: 329 [500000/697932 (72%)]\tLoss: 137.393859\n",
      "Train Epoch: 329 [600000/697932 (86%)]\tLoss: 137.989500\n",
      "====> Epoch: 329 Average loss: 138.0201\n",
      "====> Test set loss: 139.2723\n",
      "Train Epoch: 330 [0/697932 (0%)]\tLoss: 137.598656\n",
      "Train Epoch: 330 [100000/697932 (14%)]\tLoss: 138.143875\n",
      "Train Epoch: 330 [200000/697932 (29%)]\tLoss: 138.103938\n",
      "Train Epoch: 330 [300000/697932 (43%)]\tLoss: 139.014281\n",
      "Train Epoch: 330 [400000/697932 (57%)]\tLoss: 139.946172\n",
      "Train Epoch: 330 [500000/697932 (72%)]\tLoss: 138.511094\n",
      "Train Epoch: 330 [600000/697932 (86%)]\tLoss: 137.951625\n",
      "====> Epoch: 330 Average loss: 138.0334\n",
      "====> Test set loss: 139.2472\n",
      "Train Epoch: 331 [0/697932 (0%)]\tLoss: 135.648781\n",
      "Train Epoch: 331 [100000/697932 (14%)]\tLoss: 138.435594\n",
      "Train Epoch: 331 [200000/697932 (29%)]\tLoss: 137.566531\n",
      "Train Epoch: 331 [300000/697932 (43%)]\tLoss: 138.213406\n",
      "Train Epoch: 331 [400000/697932 (57%)]\tLoss: 135.289094\n",
      "Train Epoch: 331 [500000/697932 (72%)]\tLoss: 138.821188\n",
      "Train Epoch: 331 [600000/697932 (86%)]\tLoss: 139.192438\n",
      "====> Epoch: 331 Average loss: 138.0184\n",
      "====> Test set loss: 139.1939\n",
      "Train Epoch: 332 [0/697932 (0%)]\tLoss: 138.365187\n",
      "Train Epoch: 332 [100000/697932 (14%)]\tLoss: 137.893375\n",
      "Train Epoch: 332 [200000/697932 (29%)]\tLoss: 137.292297\n",
      "Train Epoch: 332 [300000/697932 (43%)]\tLoss: 138.085672\n",
      "Train Epoch: 332 [400000/697932 (57%)]\tLoss: 138.071141\n",
      "Train Epoch: 332 [500000/697932 (72%)]\tLoss: 139.806000\n",
      "Train Epoch: 332 [600000/697932 (86%)]\tLoss: 138.743531\n",
      "====> Epoch: 332 Average loss: 138.0100\n",
      "====> Test set loss: 139.2848\n",
      "Train Epoch: 333 [0/697932 (0%)]\tLoss: 136.798047\n",
      "Train Epoch: 333 [100000/697932 (14%)]\tLoss: 137.108250\n",
      "Train Epoch: 333 [200000/697932 (29%)]\tLoss: 136.897625\n",
      "Train Epoch: 333 [300000/697932 (43%)]\tLoss: 138.528141\n",
      "Train Epoch: 333 [400000/697932 (57%)]\tLoss: 136.475953\n",
      "Train Epoch: 333 [500000/697932 (72%)]\tLoss: 138.555484\n",
      "Train Epoch: 333 [600000/697932 (86%)]\tLoss: 137.728281\n",
      "====> Epoch: 333 Average loss: 138.0146\n",
      "====> Test set loss: 139.3685\n",
      "Train Epoch: 334 [0/697932 (0%)]\tLoss: 135.657703\n",
      "Train Epoch: 334 [100000/697932 (14%)]\tLoss: 137.336172\n",
      "Train Epoch: 334 [200000/697932 (29%)]\tLoss: 137.318969\n",
      "Train Epoch: 334 [300000/697932 (43%)]\tLoss: 138.958469\n",
      "Train Epoch: 334 [400000/697932 (57%)]\tLoss: 136.681516\n",
      "Train Epoch: 334 [500000/697932 (72%)]\tLoss: 138.766766\n",
      "Train Epoch: 334 [600000/697932 (86%)]\tLoss: 139.551453\n",
      "====> Epoch: 334 Average loss: 138.0191\n",
      "====> Test set loss: 139.2481\n",
      "Train Epoch: 335 [0/697932 (0%)]\tLoss: 138.183531\n",
      "Train Epoch: 335 [100000/697932 (14%)]\tLoss: 137.748297\n",
      "Train Epoch: 335 [200000/697932 (29%)]\tLoss: 137.938453\n",
      "Train Epoch: 335 [300000/697932 (43%)]\tLoss: 137.787078\n",
      "Train Epoch: 335 [400000/697932 (57%)]\tLoss: 138.341641\n",
      "Train Epoch: 335 [500000/697932 (72%)]\tLoss: 138.942828\n",
      "Train Epoch: 335 [600000/697932 (86%)]\tLoss: 137.259625\n",
      "====> Epoch: 335 Average loss: 138.0193\n",
      "====> Test set loss: 139.2750\n",
      "Train Epoch: 336 [0/697932 (0%)]\tLoss: 135.418531\n",
      "Train Epoch: 336 [100000/697932 (14%)]\tLoss: 138.636156\n",
      "Train Epoch: 336 [200000/697932 (29%)]\tLoss: 139.399578\n",
      "Train Epoch: 336 [300000/697932 (43%)]\tLoss: 135.880766\n",
      "Train Epoch: 336 [400000/697932 (57%)]\tLoss: 139.293766\n",
      "Train Epoch: 336 [500000/697932 (72%)]\tLoss: 138.488031\n",
      "Train Epoch: 336 [600000/697932 (86%)]\tLoss: 139.291672\n",
      "====> Epoch: 336 Average loss: 138.0151\n",
      "====> Test set loss: 139.1916\n",
      "Train Epoch: 337 [0/697932 (0%)]\tLoss: 139.104125\n",
      "Train Epoch: 337 [100000/697932 (14%)]\tLoss: 139.436703\n",
      "Train Epoch: 337 [200000/697932 (29%)]\tLoss: 139.710797\n",
      "Train Epoch: 337 [300000/697932 (43%)]\tLoss: 137.788828\n",
      "Train Epoch: 337 [400000/697932 (57%)]\tLoss: 138.507156\n",
      "Train Epoch: 337 [500000/697932 (72%)]\tLoss: 138.174187\n",
      "Train Epoch: 337 [600000/697932 (86%)]\tLoss: 138.249234\n",
      "====> Epoch: 337 Average loss: 138.0068\n",
      "====> Test set loss: 139.2905\n",
      "Train Epoch: 338 [0/697932 (0%)]\tLoss: 138.613219\n",
      "Train Epoch: 338 [100000/697932 (14%)]\tLoss: 138.418266\n",
      "Train Epoch: 338 [200000/697932 (29%)]\tLoss: 138.108969\n",
      "Train Epoch: 338 [300000/697932 (43%)]\tLoss: 137.440125\n",
      "Train Epoch: 338 [400000/697932 (57%)]\tLoss: 139.645266\n",
      "Train Epoch: 338 [500000/697932 (72%)]\tLoss: 137.089687\n",
      "Train Epoch: 338 [600000/697932 (86%)]\tLoss: 136.424641\n",
      "====> Epoch: 338 Average loss: 137.9954\n",
      "====> Test set loss: 139.2716\n",
      "Train Epoch: 339 [0/697932 (0%)]\tLoss: 139.985094\n",
      "Train Epoch: 339 [100000/697932 (14%)]\tLoss: 138.736953\n",
      "Train Epoch: 339 [200000/697932 (29%)]\tLoss: 138.104031\n",
      "Train Epoch: 339 [300000/697932 (43%)]\tLoss: 138.838687\n",
      "Train Epoch: 339 [400000/697932 (57%)]\tLoss: 137.908266\n",
      "Train Epoch: 339 [500000/697932 (72%)]\tLoss: 139.003609\n",
      "Train Epoch: 339 [600000/697932 (86%)]\tLoss: 136.763813\n",
      "====> Epoch: 339 Average loss: 138.0100\n",
      "====> Test set loss: 139.2335\n",
      "Train Epoch: 340 [0/697932 (0%)]\tLoss: 137.344578\n",
      "Train Epoch: 340 [100000/697932 (14%)]\tLoss: 138.439219\n",
      "Train Epoch: 340 [200000/697932 (29%)]\tLoss: 139.012172\n",
      "Train Epoch: 340 [300000/697932 (43%)]\tLoss: 138.698000\n",
      "Train Epoch: 340 [400000/697932 (57%)]\tLoss: 136.036188\n",
      "Train Epoch: 340 [500000/697932 (72%)]\tLoss: 137.438531\n",
      "Train Epoch: 340 [600000/697932 (86%)]\tLoss: 138.215234\n",
      "====> Epoch: 340 Average loss: 138.0064\n",
      "====> Test set loss: 139.2214\n",
      "Train Epoch: 341 [0/697932 (0%)]\tLoss: 138.968969\n",
      "Train Epoch: 341 [100000/697932 (14%)]\tLoss: 138.581969\n",
      "Train Epoch: 341 [200000/697932 (29%)]\tLoss: 136.571531\n",
      "Train Epoch: 341 [300000/697932 (43%)]\tLoss: 136.257812\n",
      "Train Epoch: 341 [400000/697932 (57%)]\tLoss: 136.311156\n",
      "Train Epoch: 341 [500000/697932 (72%)]\tLoss: 138.075359\n",
      "Train Epoch: 341 [600000/697932 (86%)]\tLoss: 139.988297\n",
      "====> Epoch: 341 Average loss: 137.9939\n",
      "====> Test set loss: 139.1400\n",
      "Train Epoch: 342 [0/697932 (0%)]\tLoss: 138.545219\n",
      "Train Epoch: 342 [100000/697932 (14%)]\tLoss: 137.191563\n",
      "Train Epoch: 342 [200000/697932 (29%)]\tLoss: 138.822078\n",
      "Train Epoch: 342 [300000/697932 (43%)]\tLoss: 137.932531\n",
      "Train Epoch: 342 [400000/697932 (57%)]\tLoss: 137.136188\n",
      "Train Epoch: 342 [500000/697932 (72%)]\tLoss: 136.943844\n",
      "Train Epoch: 342 [600000/697932 (86%)]\tLoss: 138.060641\n",
      "====> Epoch: 342 Average loss: 137.9990\n",
      "====> Test set loss: 139.2958\n",
      "Train Epoch: 343 [0/697932 (0%)]\tLoss: 138.585438\n",
      "Train Epoch: 343 [100000/697932 (14%)]\tLoss: 137.112109\n",
      "Train Epoch: 343 [200000/697932 (29%)]\tLoss: 136.295656\n",
      "Train Epoch: 343 [300000/697932 (43%)]\tLoss: 136.686375\n",
      "Train Epoch: 343 [400000/697932 (57%)]\tLoss: 138.528656\n",
      "Train Epoch: 343 [500000/697932 (72%)]\tLoss: 137.554094\n",
      "Train Epoch: 343 [600000/697932 (86%)]\tLoss: 136.455656\n",
      "====> Epoch: 343 Average loss: 138.0003\n",
      "====> Test set loss: 139.3730\n",
      "Train Epoch: 344 [0/697932 (0%)]\tLoss: 138.676688\n",
      "Train Epoch: 344 [100000/697932 (14%)]\tLoss: 138.741688\n",
      "Train Epoch: 344 [200000/697932 (29%)]\tLoss: 137.501984\n",
      "Train Epoch: 344 [300000/697932 (43%)]\tLoss: 137.648906\n",
      "Train Epoch: 344 [400000/697932 (57%)]\tLoss: 138.050500\n",
      "Train Epoch: 344 [500000/697932 (72%)]\tLoss: 137.809313\n",
      "Train Epoch: 344 [600000/697932 (86%)]\tLoss: 138.122859\n",
      "====> Epoch: 344 Average loss: 137.9850\n",
      "====> Test set loss: 139.3104\n",
      "Train Epoch: 345 [0/697932 (0%)]\tLoss: 137.410406\n",
      "Train Epoch: 345 [100000/697932 (14%)]\tLoss: 137.578469\n",
      "Train Epoch: 345 [200000/697932 (29%)]\tLoss: 137.778078\n",
      "Train Epoch: 345 [300000/697932 (43%)]\tLoss: 139.661063\n",
      "Train Epoch: 345 [400000/697932 (57%)]\tLoss: 138.577172\n",
      "Train Epoch: 345 [500000/697932 (72%)]\tLoss: 138.120156\n",
      "Train Epoch: 345 [600000/697932 (86%)]\tLoss: 138.227625\n",
      "====> Epoch: 345 Average loss: 137.9982\n",
      "====> Test set loss: 139.2824\n",
      "Train Epoch: 346 [0/697932 (0%)]\tLoss: 140.157563\n",
      "Train Epoch: 346 [100000/697932 (14%)]\tLoss: 138.693359\n",
      "Train Epoch: 346 [200000/697932 (29%)]\tLoss: 138.387719\n",
      "Train Epoch: 346 [300000/697932 (43%)]\tLoss: 138.079688\n",
      "Train Epoch: 346 [400000/697932 (57%)]\tLoss: 137.893406\n",
      "Train Epoch: 346 [500000/697932 (72%)]\tLoss: 137.168422\n",
      "Train Epoch: 346 [600000/697932 (86%)]\tLoss: 138.334516\n",
      "====> Epoch: 346 Average loss: 137.9672\n",
      "====> Test set loss: 139.1861\n",
      "Train Epoch: 347 [0/697932 (0%)]\tLoss: 138.144703\n",
      "Train Epoch: 347 [100000/697932 (14%)]\tLoss: 136.487016\n",
      "Train Epoch: 347 [200000/697932 (29%)]\tLoss: 137.466922\n",
      "Train Epoch: 347 [300000/697932 (43%)]\tLoss: 137.941844\n",
      "Train Epoch: 347 [400000/697932 (57%)]\tLoss: 137.398859\n",
      "Train Epoch: 347 [500000/697932 (72%)]\tLoss: 134.923969\n",
      "Train Epoch: 347 [600000/697932 (86%)]\tLoss: 138.258094\n",
      "====> Epoch: 347 Average loss: 137.9723\n",
      "====> Test set loss: 139.1623\n",
      "Train Epoch: 348 [0/697932 (0%)]\tLoss: 137.857859\n",
      "Train Epoch: 348 [100000/697932 (14%)]\tLoss: 138.095906\n",
      "Train Epoch: 348 [200000/697932 (29%)]\tLoss: 137.412359\n",
      "Train Epoch: 348 [300000/697932 (43%)]\tLoss: 138.524188\n",
      "Train Epoch: 348 [400000/697932 (57%)]\tLoss: 136.827828\n",
      "Train Epoch: 348 [500000/697932 (72%)]\tLoss: 139.232672\n",
      "Train Epoch: 348 [600000/697932 (86%)]\tLoss: 139.163938\n",
      "====> Epoch: 348 Average loss: 137.9705\n",
      "====> Test set loss: 139.2440\n",
      "Train Epoch: 349 [0/697932 (0%)]\tLoss: 137.247750\n",
      "Train Epoch: 349 [100000/697932 (14%)]\tLoss: 137.506094\n",
      "Train Epoch: 349 [200000/697932 (29%)]\tLoss: 138.046375\n",
      "Train Epoch: 349 [300000/697932 (43%)]\tLoss: 136.592266\n",
      "Train Epoch: 349 [400000/697932 (57%)]\tLoss: 137.554500\n",
      "Train Epoch: 349 [500000/697932 (72%)]\tLoss: 135.995578\n",
      "Train Epoch: 349 [600000/697932 (86%)]\tLoss: 136.331266\n",
      "====> Epoch: 349 Average loss: 137.9890\n",
      "====> Test set loss: 139.2651\n",
      "Train Epoch: 350 [0/697932 (0%)]\tLoss: 136.445812\n",
      "Train Epoch: 350 [100000/697932 (14%)]\tLoss: 139.888109\n",
      "Train Epoch: 350 [200000/697932 (29%)]\tLoss: 136.595422\n",
      "Train Epoch: 350 [300000/697932 (43%)]\tLoss: 137.489781\n",
      "Train Epoch: 350 [400000/697932 (57%)]\tLoss: 138.149016\n",
      "Train Epoch: 350 [500000/697932 (72%)]\tLoss: 139.148281\n",
      "Train Epoch: 350 [600000/697932 (86%)]\tLoss: 139.038813\n",
      "====> Epoch: 350 Average loss: 137.9769\n",
      "====> Test set loss: 139.3338\n",
      "Train Epoch: 351 [0/697932 (0%)]\tLoss: 138.696750\n",
      "Train Epoch: 351 [100000/697932 (14%)]\tLoss: 139.180234\n",
      "Train Epoch: 351 [200000/697932 (29%)]\tLoss: 137.730172\n",
      "Train Epoch: 351 [300000/697932 (43%)]\tLoss: 137.650359\n",
      "Train Epoch: 351 [400000/697932 (57%)]\tLoss: 138.145156\n",
      "Train Epoch: 351 [500000/697932 (72%)]\tLoss: 137.805313\n",
      "Train Epoch: 351 [600000/697932 (86%)]\tLoss: 137.311094\n",
      "====> Epoch: 351 Average loss: 137.9652\n",
      "====> Test set loss: 139.2794\n",
      "Train Epoch: 352 [0/697932 (0%)]\tLoss: 137.912609\n",
      "Train Epoch: 352 [100000/697932 (14%)]\tLoss: 138.299688\n",
      "Train Epoch: 352 [200000/697932 (29%)]\tLoss: 137.729500\n",
      "Train Epoch: 352 [300000/697932 (43%)]\tLoss: 138.520484\n",
      "Train Epoch: 352 [400000/697932 (57%)]\tLoss: 136.789250\n",
      "Train Epoch: 352 [500000/697932 (72%)]\tLoss: 139.092281\n",
      "Train Epoch: 352 [600000/697932 (86%)]\tLoss: 138.287234\n",
      "====> Epoch: 352 Average loss: 137.9694\n",
      "====> Test set loss: 139.2311\n",
      "Train Epoch: 353 [0/697932 (0%)]\tLoss: 136.989984\n",
      "Train Epoch: 353 [100000/697932 (14%)]\tLoss: 137.702313\n",
      "Train Epoch: 353 [200000/697932 (29%)]\tLoss: 136.747969\n",
      "Train Epoch: 353 [300000/697932 (43%)]\tLoss: 138.367766\n",
      "Train Epoch: 353 [400000/697932 (57%)]\tLoss: 139.006031\n",
      "Train Epoch: 353 [500000/697932 (72%)]\tLoss: 139.510750\n",
      "Train Epoch: 353 [600000/697932 (86%)]\tLoss: 137.498719\n",
      "====> Epoch: 353 Average loss: 137.9532\n",
      "====> Test set loss: 139.2000\n",
      "Train Epoch: 354 [0/697932 (0%)]\tLoss: 139.352766\n",
      "Train Epoch: 354 [100000/697932 (14%)]\tLoss: 138.252828\n",
      "Train Epoch: 354 [200000/697932 (29%)]\tLoss: 137.242250\n",
      "Train Epoch: 354 [300000/697932 (43%)]\tLoss: 135.906672\n",
      "Train Epoch: 354 [400000/697932 (57%)]\tLoss: 135.669031\n",
      "Train Epoch: 354 [500000/697932 (72%)]\tLoss: 138.229328\n",
      "Train Epoch: 354 [600000/697932 (86%)]\tLoss: 138.128781\n",
      "====> Epoch: 354 Average loss: 137.9686\n",
      "====> Test set loss: 139.2509\n",
      "Train Epoch: 355 [0/697932 (0%)]\tLoss: 138.316125\n",
      "Train Epoch: 355 [100000/697932 (14%)]\tLoss: 136.830984\n",
      "Train Epoch: 355 [200000/697932 (29%)]\tLoss: 138.193625\n",
      "Train Epoch: 355 [300000/697932 (43%)]\tLoss: 139.359781\n",
      "Train Epoch: 355 [400000/697932 (57%)]\tLoss: 139.444734\n",
      "Train Epoch: 355 [500000/697932 (72%)]\tLoss: 135.955234\n",
      "Train Epoch: 355 [600000/697932 (86%)]\tLoss: 139.653484\n",
      "====> Epoch: 355 Average loss: 137.9550\n",
      "====> Test set loss: 139.2249\n",
      "Train Epoch: 356 [0/697932 (0%)]\tLoss: 138.710766\n",
      "Train Epoch: 356 [100000/697932 (14%)]\tLoss: 137.892422\n",
      "Train Epoch: 356 [200000/697932 (29%)]\tLoss: 138.984969\n",
      "Train Epoch: 356 [300000/697932 (43%)]\tLoss: 137.975141\n",
      "Train Epoch: 356 [400000/697932 (57%)]\tLoss: 138.307953\n",
      "Train Epoch: 356 [500000/697932 (72%)]\tLoss: 137.671734\n",
      "Train Epoch: 356 [600000/697932 (86%)]\tLoss: 139.119219\n",
      "====> Epoch: 356 Average loss: 137.9588\n",
      "====> Test set loss: 139.2783\n",
      "Train Epoch: 357 [0/697932 (0%)]\tLoss: 137.477406\n",
      "Train Epoch: 357 [100000/697932 (14%)]\tLoss: 137.714375\n",
      "Train Epoch: 357 [200000/697932 (29%)]\tLoss: 139.514672\n",
      "Train Epoch: 357 [300000/697932 (43%)]\tLoss: 137.525937\n",
      "Train Epoch: 357 [400000/697932 (57%)]\tLoss: 137.777844\n",
      "Train Epoch: 357 [500000/697932 (72%)]\tLoss: 138.898969\n",
      "Train Epoch: 357 [600000/697932 (86%)]\tLoss: 136.969219\n",
      "====> Epoch: 357 Average loss: 137.9671\n",
      "====> Test set loss: 139.2934\n",
      "Train Epoch: 358 [0/697932 (0%)]\tLoss: 135.208188\n",
      "Train Epoch: 358 [100000/697932 (14%)]\tLoss: 138.372656\n",
      "Train Epoch: 358 [200000/697932 (29%)]\tLoss: 137.280656\n",
      "Train Epoch: 358 [300000/697932 (43%)]\tLoss: 137.381937\n",
      "Train Epoch: 358 [400000/697932 (57%)]\tLoss: 137.543234\n",
      "Train Epoch: 358 [500000/697932 (72%)]\tLoss: 138.260766\n",
      "Train Epoch: 358 [600000/697932 (86%)]\tLoss: 138.491891\n",
      "====> Epoch: 358 Average loss: 137.9597\n",
      "====> Test set loss: 139.2912\n",
      "Train Epoch: 359 [0/697932 (0%)]\tLoss: 138.157016\n",
      "Train Epoch: 359 [100000/697932 (14%)]\tLoss: 138.776469\n",
      "Train Epoch: 359 [200000/697932 (29%)]\tLoss: 140.247969\n",
      "Train Epoch: 359 [300000/697932 (43%)]\tLoss: 138.222391\n",
      "Train Epoch: 359 [400000/697932 (57%)]\tLoss: 138.213641\n",
      "Train Epoch: 359 [500000/697932 (72%)]\tLoss: 138.395516\n",
      "Train Epoch: 359 [600000/697932 (86%)]\tLoss: 137.840094\n",
      "====> Epoch: 359 Average loss: 137.9539\n",
      "====> Test set loss: 139.1692\n",
      "Train Epoch: 360 [0/697932 (0%)]\tLoss: 136.855219\n",
      "Train Epoch: 360 [100000/697932 (14%)]\tLoss: 139.188453\n",
      "Train Epoch: 360 [200000/697932 (29%)]\tLoss: 137.979062\n",
      "Train Epoch: 360 [300000/697932 (43%)]\tLoss: 138.762250\n",
      "Train Epoch: 360 [400000/697932 (57%)]\tLoss: 138.211813\n",
      "Train Epoch: 360 [500000/697932 (72%)]\tLoss: 138.424563\n",
      "Train Epoch: 360 [600000/697932 (86%)]\tLoss: 137.278703\n",
      "====> Epoch: 360 Average loss: 137.9446\n",
      "====> Test set loss: 139.2147\n",
      "Train Epoch: 361 [0/697932 (0%)]\tLoss: 138.560672\n",
      "Train Epoch: 361 [100000/697932 (14%)]\tLoss: 135.330813\n",
      "Train Epoch: 361 [200000/697932 (29%)]\tLoss: 139.953891\n",
      "Train Epoch: 361 [300000/697932 (43%)]\tLoss: 135.545391\n",
      "Train Epoch: 361 [400000/697932 (57%)]\tLoss: 138.100063\n",
      "Train Epoch: 361 [500000/697932 (72%)]\tLoss: 137.420562\n",
      "Train Epoch: 361 [600000/697932 (86%)]\tLoss: 138.533719\n",
      "====> Epoch: 361 Average loss: 137.9413\n",
      "====> Test set loss: 139.2241\n",
      "Train Epoch: 362 [0/697932 (0%)]\tLoss: 136.283437\n",
      "Train Epoch: 362 [100000/697932 (14%)]\tLoss: 138.623312\n",
      "Train Epoch: 362 [200000/697932 (29%)]\tLoss: 137.341750\n",
      "Train Epoch: 362 [300000/697932 (43%)]\tLoss: 137.350437\n",
      "Train Epoch: 362 [400000/697932 (57%)]\tLoss: 137.658953\n",
      "Train Epoch: 362 [500000/697932 (72%)]\tLoss: 137.379781\n",
      "Train Epoch: 362 [600000/697932 (86%)]\tLoss: 138.537109\n",
      "====> Epoch: 362 Average loss: 137.9404\n",
      "====> Test set loss: 139.2179\n",
      "Train Epoch: 363 [0/697932 (0%)]\tLoss: 137.347406\n",
      "Train Epoch: 363 [100000/697932 (14%)]\tLoss: 138.355391\n",
      "Train Epoch: 363 [200000/697932 (29%)]\tLoss: 137.313234\n",
      "Train Epoch: 363 [300000/697932 (43%)]\tLoss: 138.447094\n",
      "Train Epoch: 363 [400000/697932 (57%)]\tLoss: 139.245328\n",
      "Train Epoch: 363 [500000/697932 (72%)]\tLoss: 136.469094\n",
      "Train Epoch: 363 [600000/697932 (86%)]\tLoss: 139.255922\n",
      "====> Epoch: 363 Average loss: 137.9480\n",
      "====> Test set loss: 139.2235\n",
      "Train Epoch: 364 [0/697932 (0%)]\tLoss: 138.167188\n",
      "Train Epoch: 364 [100000/697932 (14%)]\tLoss: 137.961484\n",
      "Train Epoch: 364 [200000/697932 (29%)]\tLoss: 136.445641\n",
      "Train Epoch: 364 [300000/697932 (43%)]\tLoss: 138.647250\n",
      "Train Epoch: 364 [400000/697932 (57%)]\tLoss: 139.131094\n",
      "Train Epoch: 364 [500000/697932 (72%)]\tLoss: 137.764281\n",
      "Train Epoch: 364 [600000/697932 (86%)]\tLoss: 139.065953\n",
      "====> Epoch: 364 Average loss: 137.9310\n",
      "====> Test set loss: 139.3252\n",
      "Train Epoch: 365 [0/697932 (0%)]\tLoss: 136.714906\n",
      "Train Epoch: 365 [100000/697932 (14%)]\tLoss: 137.895594\n",
      "Train Epoch: 365 [200000/697932 (29%)]\tLoss: 137.258563\n",
      "Train Epoch: 365 [300000/697932 (43%)]\tLoss: 138.458219\n",
      "Train Epoch: 365 [400000/697932 (57%)]\tLoss: 137.137563\n",
      "Train Epoch: 365 [500000/697932 (72%)]\tLoss: 137.977563\n",
      "Train Epoch: 365 [600000/697932 (86%)]\tLoss: 139.258844\n",
      "====> Epoch: 365 Average loss: 137.9276\n",
      "====> Test set loss: 139.1498\n",
      "Train Epoch: 366 [0/697932 (0%)]\tLoss: 136.847266\n",
      "Train Epoch: 366 [100000/697932 (14%)]\tLoss: 138.269281\n",
      "Train Epoch: 366 [200000/697932 (29%)]\tLoss: 137.785219\n",
      "Train Epoch: 366 [300000/697932 (43%)]\tLoss: 137.758422\n",
      "Train Epoch: 366 [400000/697932 (57%)]\tLoss: 138.755797\n",
      "Train Epoch: 366 [500000/697932 (72%)]\tLoss: 137.829438\n",
      "Train Epoch: 366 [600000/697932 (86%)]\tLoss: 137.398156\n",
      "====> Epoch: 366 Average loss: 137.9427\n",
      "====> Test set loss: 139.2298\n",
      "Train Epoch: 367 [0/697932 (0%)]\tLoss: 136.669875\n",
      "Train Epoch: 367 [100000/697932 (14%)]\tLoss: 137.806344\n",
      "Train Epoch: 367 [200000/697932 (29%)]\tLoss: 136.273484\n",
      "Train Epoch: 367 [300000/697932 (43%)]\tLoss: 137.761812\n",
      "Train Epoch: 367 [400000/697932 (57%)]\tLoss: 140.170719\n",
      "Train Epoch: 367 [500000/697932 (72%)]\tLoss: 138.731031\n",
      "Train Epoch: 367 [600000/697932 (86%)]\tLoss: 139.398562\n",
      "====> Epoch: 367 Average loss: 137.9447\n",
      "====> Test set loss: 139.3095\n",
      "Train Epoch: 368 [0/697932 (0%)]\tLoss: 137.938938\n",
      "Train Epoch: 368 [100000/697932 (14%)]\tLoss: 137.563719\n",
      "Train Epoch: 368 [200000/697932 (29%)]\tLoss: 137.628844\n",
      "Train Epoch: 368 [300000/697932 (43%)]\tLoss: 140.008969\n",
      "Train Epoch: 368 [400000/697932 (57%)]\tLoss: 139.015688\n",
      "Train Epoch: 368 [500000/697932 (72%)]\tLoss: 136.759766\n",
      "Train Epoch: 368 [600000/697932 (86%)]\tLoss: 137.686297\n",
      "====> Epoch: 368 Average loss: 137.9336\n",
      "====> Test set loss: 139.2023\n",
      "Train Epoch: 369 [0/697932 (0%)]\tLoss: 138.884172\n",
      "Train Epoch: 369 [100000/697932 (14%)]\tLoss: 138.938484\n",
      "Train Epoch: 369 [200000/697932 (29%)]\tLoss: 138.886250\n",
      "Train Epoch: 369 [300000/697932 (43%)]\tLoss: 137.188187\n",
      "Train Epoch: 369 [400000/697932 (57%)]\tLoss: 137.210375\n",
      "Train Epoch: 369 [500000/697932 (72%)]\tLoss: 138.415797\n",
      "Train Epoch: 369 [600000/697932 (86%)]\tLoss: 138.000469\n",
      "====> Epoch: 369 Average loss: 137.9239\n",
      "====> Test set loss: 139.2063\n",
      "Train Epoch: 370 [0/697932 (0%)]\tLoss: 136.641750\n",
      "Train Epoch: 370 [100000/697932 (14%)]\tLoss: 136.020938\n",
      "Train Epoch: 370 [200000/697932 (29%)]\tLoss: 139.822188\n",
      "Train Epoch: 370 [300000/697932 (43%)]\tLoss: 138.249578\n",
      "Train Epoch: 370 [400000/697932 (57%)]\tLoss: 139.233313\n",
      "Train Epoch: 370 [500000/697932 (72%)]\tLoss: 137.504359\n",
      "Train Epoch: 370 [600000/697932 (86%)]\tLoss: 138.890688\n",
      "====> Epoch: 370 Average loss: 137.9225\n",
      "====> Test set loss: 139.1459\n",
      "Train Epoch: 371 [0/697932 (0%)]\tLoss: 135.566203\n",
      "Train Epoch: 371 [100000/697932 (14%)]\tLoss: 137.732359\n",
      "Train Epoch: 371 [200000/697932 (29%)]\tLoss: 138.101094\n",
      "Train Epoch: 371 [300000/697932 (43%)]\tLoss: 138.505109\n",
      "Train Epoch: 371 [400000/697932 (57%)]\tLoss: 137.513828\n",
      "Train Epoch: 371 [500000/697932 (72%)]\tLoss: 139.843234\n",
      "Train Epoch: 371 [600000/697932 (86%)]\tLoss: 139.919250\n",
      "====> Epoch: 371 Average loss: 137.9427\n",
      "====> Test set loss: 139.3446\n",
      "Train Epoch: 372 [0/697932 (0%)]\tLoss: 136.528437\n",
      "Train Epoch: 372 [100000/697932 (14%)]\tLoss: 139.189484\n",
      "Train Epoch: 372 [200000/697932 (29%)]\tLoss: 139.389328\n",
      "Train Epoch: 372 [300000/697932 (43%)]\tLoss: 137.365922\n",
      "Train Epoch: 372 [400000/697932 (57%)]\tLoss: 137.047219\n",
      "Train Epoch: 372 [500000/697932 (72%)]\tLoss: 137.749156\n",
      "Train Epoch: 372 [600000/697932 (86%)]\tLoss: 137.423797\n",
      "====> Epoch: 372 Average loss: 137.9185\n",
      "====> Test set loss: 139.2543\n",
      "Train Epoch: 373 [0/697932 (0%)]\tLoss: 136.689672\n",
      "Train Epoch: 373 [100000/697932 (14%)]\tLoss: 137.073969\n",
      "Train Epoch: 373 [200000/697932 (29%)]\tLoss: 136.481250\n",
      "Train Epoch: 373 [300000/697932 (43%)]\tLoss: 139.291047\n",
      "Train Epoch: 373 [400000/697932 (57%)]\tLoss: 138.002672\n",
      "Train Epoch: 373 [500000/697932 (72%)]\tLoss: 136.944750\n",
      "Train Epoch: 373 [600000/697932 (86%)]\tLoss: 136.566766\n",
      "====> Epoch: 373 Average loss: 137.9209\n",
      "====> Test set loss: 139.1762\n",
      "Train Epoch: 374 [0/697932 (0%)]\tLoss: 137.671734\n",
      "Train Epoch: 374 [100000/697932 (14%)]\tLoss: 138.985641\n",
      "Train Epoch: 374 [200000/697932 (29%)]\tLoss: 137.476234\n",
      "Train Epoch: 374 [300000/697932 (43%)]\tLoss: 138.390656\n",
      "Train Epoch: 374 [400000/697932 (57%)]\tLoss: 138.416891\n",
      "Train Epoch: 374 [500000/697932 (72%)]\tLoss: 137.634156\n",
      "Train Epoch: 374 [600000/697932 (86%)]\tLoss: 137.740156\n",
      "====> Epoch: 374 Average loss: 137.9162\n",
      "====> Test set loss: 139.1468\n",
      "Train Epoch: 375 [0/697932 (0%)]\tLoss: 137.049563\n",
      "Train Epoch: 375 [100000/697932 (14%)]\tLoss: 140.602625\n",
      "Train Epoch: 375 [200000/697932 (29%)]\tLoss: 139.035656\n",
      "Train Epoch: 375 [300000/697932 (43%)]\tLoss: 136.469687\n",
      "Train Epoch: 375 [400000/697932 (57%)]\tLoss: 137.604469\n",
      "Train Epoch: 375 [500000/697932 (72%)]\tLoss: 138.105875\n",
      "Train Epoch: 375 [600000/697932 (86%)]\tLoss: 137.806938\n",
      "====> Epoch: 375 Average loss: 137.9070\n",
      "====> Test set loss: 139.1499\n",
      "Train Epoch: 376 [0/697932 (0%)]\tLoss: 136.142281\n",
      "Train Epoch: 376 [100000/697932 (14%)]\tLoss: 138.506750\n",
      "Train Epoch: 376 [200000/697932 (29%)]\tLoss: 138.094578\n",
      "Train Epoch: 376 [300000/697932 (43%)]\tLoss: 137.448813\n",
      "Train Epoch: 376 [400000/697932 (57%)]\tLoss: 136.389500\n",
      "Train Epoch: 376 [500000/697932 (72%)]\tLoss: 139.301594\n",
      "Train Epoch: 376 [600000/697932 (86%)]\tLoss: 138.197188\n",
      "====> Epoch: 376 Average loss: 137.9023\n",
      "====> Test set loss: 139.1187\n",
      "Train Epoch: 377 [0/697932 (0%)]\tLoss: 138.801219\n",
      "Train Epoch: 377 [100000/697932 (14%)]\tLoss: 138.239469\n",
      "Train Epoch: 377 [200000/697932 (29%)]\tLoss: 136.672656\n",
      "Train Epoch: 377 [300000/697932 (43%)]\tLoss: 137.980328\n",
      "Train Epoch: 377 [400000/697932 (57%)]\tLoss: 137.988953\n",
      "Train Epoch: 377 [500000/697932 (72%)]\tLoss: 135.860422\n",
      "Train Epoch: 377 [600000/697932 (86%)]\tLoss: 137.935484\n",
      "====> Epoch: 377 Average loss: 137.9117\n",
      "====> Test set loss: 139.1748\n",
      "Train Epoch: 378 [0/697932 (0%)]\tLoss: 137.647844\n",
      "Train Epoch: 378 [100000/697932 (14%)]\tLoss: 139.090000\n",
      "Train Epoch: 378 [200000/697932 (29%)]\tLoss: 138.893797\n",
      "Train Epoch: 378 [300000/697932 (43%)]\tLoss: 139.387375\n",
      "Train Epoch: 378 [400000/697932 (57%)]\tLoss: 134.874141\n",
      "Train Epoch: 378 [500000/697932 (72%)]\tLoss: 138.319078\n",
      "Train Epoch: 378 [600000/697932 (86%)]\tLoss: 138.832109\n",
      "====> Epoch: 378 Average loss: 137.9134\n",
      "====> Test set loss: 139.1495\n",
      "Train Epoch: 379 [0/697932 (0%)]\tLoss: 140.133219\n",
      "Train Epoch: 379 [100000/697932 (14%)]\tLoss: 138.872906\n",
      "Train Epoch: 379 [200000/697932 (29%)]\tLoss: 136.907484\n",
      "Train Epoch: 379 [300000/697932 (43%)]\tLoss: 137.586656\n",
      "Train Epoch: 379 [400000/697932 (57%)]\tLoss: 138.095734\n",
      "Train Epoch: 379 [500000/697932 (72%)]\tLoss: 137.268594\n",
      "Train Epoch: 379 [600000/697932 (86%)]\tLoss: 137.391172\n",
      "====> Epoch: 379 Average loss: 137.9062\n",
      "====> Test set loss: 139.1171\n",
      "Train Epoch: 380 [0/697932 (0%)]\tLoss: 138.131969\n",
      "Train Epoch: 380 [100000/697932 (14%)]\tLoss: 139.863969\n",
      "Train Epoch: 380 [200000/697932 (29%)]\tLoss: 137.349578\n",
      "Train Epoch: 380 [300000/697932 (43%)]\tLoss: 136.519969\n",
      "Train Epoch: 380 [400000/697932 (57%)]\tLoss: 136.585859\n",
      "Train Epoch: 380 [500000/697932 (72%)]\tLoss: 136.804594\n",
      "Train Epoch: 380 [600000/697932 (86%)]\tLoss: 139.384828\n",
      "====> Epoch: 380 Average loss: 137.8869\n",
      "====> Test set loss: 139.2785\n",
      "Train Epoch: 381 [0/697932 (0%)]\tLoss: 135.971422\n",
      "Train Epoch: 381 [100000/697932 (14%)]\tLoss: 139.010922\n",
      "Train Epoch: 381 [200000/697932 (29%)]\tLoss: 136.591484\n",
      "Train Epoch: 381 [300000/697932 (43%)]\tLoss: 138.228688\n",
      "Train Epoch: 381 [400000/697932 (57%)]\tLoss: 138.832328\n",
      "Train Epoch: 381 [500000/697932 (72%)]\tLoss: 135.971109\n",
      "Train Epoch: 381 [600000/697932 (86%)]\tLoss: 138.906484\n",
      "====> Epoch: 381 Average loss: 137.9130\n",
      "====> Test set loss: 139.1733\n",
      "Train Epoch: 382 [0/697932 (0%)]\tLoss: 137.902141\n",
      "Train Epoch: 382 [100000/697932 (14%)]\tLoss: 136.672453\n",
      "Train Epoch: 382 [200000/697932 (29%)]\tLoss: 137.886484\n",
      "Train Epoch: 382 [300000/697932 (43%)]\tLoss: 137.500266\n",
      "Train Epoch: 382 [400000/697932 (57%)]\tLoss: 136.260109\n",
      "Train Epoch: 382 [500000/697932 (72%)]\tLoss: 139.504375\n",
      "Train Epoch: 382 [600000/697932 (86%)]\tLoss: 138.369891\n",
      "====> Epoch: 382 Average loss: 137.9045\n",
      "====> Test set loss: 139.1238\n",
      "Train Epoch: 383 [0/697932 (0%)]\tLoss: 135.608250\n",
      "Train Epoch: 383 [100000/697932 (14%)]\tLoss: 138.300531\n",
      "Train Epoch: 383 [200000/697932 (29%)]\tLoss: 136.578234\n",
      "Train Epoch: 383 [300000/697932 (43%)]\tLoss: 136.787203\n",
      "Train Epoch: 383 [400000/697932 (57%)]\tLoss: 137.481484\n",
      "Train Epoch: 383 [500000/697932 (72%)]\tLoss: 137.775672\n",
      "Train Epoch: 383 [600000/697932 (86%)]\tLoss: 135.490094\n",
      "====> Epoch: 383 Average loss: 137.8999\n",
      "====> Test set loss: 139.1513\n",
      "Train Epoch: 384 [0/697932 (0%)]\tLoss: 139.307484\n",
      "Train Epoch: 384 [100000/697932 (14%)]\tLoss: 140.495297\n",
      "Train Epoch: 384 [200000/697932 (29%)]\tLoss: 139.329281\n",
      "Train Epoch: 384 [300000/697932 (43%)]\tLoss: 136.394734\n",
      "Train Epoch: 384 [400000/697932 (57%)]\tLoss: 138.318094\n",
      "Train Epoch: 384 [500000/697932 (72%)]\tLoss: 138.235406\n",
      "Train Epoch: 384 [600000/697932 (86%)]\tLoss: 138.985391\n",
      "====> Epoch: 384 Average loss: 137.9009\n",
      "====> Test set loss: 139.1343\n",
      "Train Epoch: 385 [0/697932 (0%)]\tLoss: 137.894141\n",
      "Train Epoch: 385 [100000/697932 (14%)]\tLoss: 137.239484\n",
      "Train Epoch: 385 [200000/697932 (29%)]\tLoss: 137.811187\n",
      "Train Epoch: 385 [300000/697932 (43%)]\tLoss: 138.979078\n",
      "Train Epoch: 385 [400000/697932 (57%)]\tLoss: 138.219344\n",
      "Train Epoch: 385 [500000/697932 (72%)]\tLoss: 137.035000\n",
      "Train Epoch: 385 [600000/697932 (86%)]\tLoss: 138.760844\n",
      "====> Epoch: 385 Average loss: 137.9060\n",
      "====> Test set loss: 139.2762\n",
      "Train Epoch: 386 [0/697932 (0%)]\tLoss: 139.389844\n",
      "Train Epoch: 386 [100000/697932 (14%)]\tLoss: 138.931437\n",
      "Train Epoch: 386 [200000/697932 (29%)]\tLoss: 137.484141\n",
      "Train Epoch: 386 [300000/697932 (43%)]\tLoss: 134.874906\n",
      "Train Epoch: 386 [400000/697932 (57%)]\tLoss: 138.451094\n",
      "Train Epoch: 386 [500000/697932 (72%)]\tLoss: 139.955703\n",
      "Train Epoch: 386 [600000/697932 (86%)]\tLoss: 140.264406\n",
      "====> Epoch: 386 Average loss: 137.8878\n",
      "====> Test set loss: 139.1300\n",
      "Train Epoch: 387 [0/697932 (0%)]\tLoss: 137.986250\n",
      "Train Epoch: 387 [100000/697932 (14%)]\tLoss: 137.817906\n",
      "Train Epoch: 387 [200000/697932 (29%)]\tLoss: 138.636000\n",
      "Train Epoch: 387 [300000/697932 (43%)]\tLoss: 137.275391\n",
      "Train Epoch: 387 [400000/697932 (57%)]\tLoss: 138.728156\n",
      "Train Epoch: 387 [500000/697932 (72%)]\tLoss: 138.470750\n",
      "Train Epoch: 387 [600000/697932 (86%)]\tLoss: 137.006625\n",
      "====> Epoch: 387 Average loss: 137.8889\n",
      "====> Test set loss: 139.1310\n",
      "Train Epoch: 388 [0/697932 (0%)]\tLoss: 138.083906\n",
      "Train Epoch: 388 [100000/697932 (14%)]\tLoss: 136.628219\n",
      "Train Epoch: 388 [200000/697932 (29%)]\tLoss: 136.860328\n",
      "Train Epoch: 388 [300000/697932 (43%)]\tLoss: 139.292266\n",
      "Train Epoch: 388 [400000/697932 (57%)]\tLoss: 136.130063\n",
      "Train Epoch: 388 [500000/697932 (72%)]\tLoss: 138.337672\n",
      "Train Epoch: 388 [600000/697932 (86%)]\tLoss: 139.479156\n",
      "====> Epoch: 388 Average loss: 137.8920\n",
      "====> Test set loss: 139.1936\n",
      "Train Epoch: 389 [0/697932 (0%)]\tLoss: 138.073656\n",
      "Train Epoch: 389 [100000/697932 (14%)]\tLoss: 137.156766\n",
      "Train Epoch: 389 [200000/697932 (29%)]\tLoss: 137.799375\n",
      "Train Epoch: 389 [300000/697932 (43%)]\tLoss: 138.013438\n",
      "Train Epoch: 389 [400000/697932 (57%)]\tLoss: 138.207766\n",
      "Train Epoch: 389 [500000/697932 (72%)]\tLoss: 137.833609\n",
      "Train Epoch: 389 [600000/697932 (86%)]\tLoss: 138.070922\n",
      "====> Epoch: 389 Average loss: 137.8828\n",
      "====> Test set loss: 139.1842\n",
      "Train Epoch: 390 [0/697932 (0%)]\tLoss: 138.598516\n",
      "Train Epoch: 390 [100000/697932 (14%)]\tLoss: 136.132828\n",
      "Train Epoch: 390 [200000/697932 (29%)]\tLoss: 136.486578\n",
      "Train Epoch: 390 [300000/697932 (43%)]\tLoss: 138.449922\n",
      "Train Epoch: 390 [400000/697932 (57%)]\tLoss: 139.847156\n",
      "Train Epoch: 390 [500000/697932 (72%)]\tLoss: 137.063500\n",
      "Train Epoch: 390 [600000/697932 (86%)]\tLoss: 139.015203\n",
      "====> Epoch: 390 Average loss: 137.8829\n",
      "====> Test set loss: 139.2493\n",
      "Train Epoch: 391 [0/697932 (0%)]\tLoss: 139.065453\n",
      "Train Epoch: 391 [100000/697932 (14%)]\tLoss: 136.719156\n",
      "Train Epoch: 391 [200000/697932 (29%)]\tLoss: 139.301047\n",
      "Train Epoch: 391 [300000/697932 (43%)]\tLoss: 136.283031\n",
      "Train Epoch: 391 [400000/697932 (57%)]\tLoss: 137.325547\n",
      "Train Epoch: 391 [500000/697932 (72%)]\tLoss: 137.103078\n",
      "Train Epoch: 391 [600000/697932 (86%)]\tLoss: 136.070141\n",
      "====> Epoch: 391 Average loss: 137.8904\n",
      "====> Test set loss: 139.3130\n",
      "Train Epoch: 392 [0/697932 (0%)]\tLoss: 137.677969\n",
      "Train Epoch: 392 [100000/697932 (14%)]\tLoss: 136.982828\n",
      "Train Epoch: 392 [200000/697932 (29%)]\tLoss: 138.819609\n",
      "Train Epoch: 392 [300000/697932 (43%)]\tLoss: 138.512922\n",
      "Train Epoch: 392 [400000/697932 (57%)]\tLoss: 137.297203\n",
      "Train Epoch: 392 [500000/697932 (72%)]\tLoss: 137.506063\n",
      "Train Epoch: 392 [600000/697932 (86%)]\tLoss: 138.462969\n",
      "====> Epoch: 392 Average loss: 137.8830\n",
      "====> Test set loss: 139.1082\n",
      "Train Epoch: 393 [0/697932 (0%)]\tLoss: 139.260516\n",
      "Train Epoch: 393 [100000/697932 (14%)]\tLoss: 139.234656\n",
      "Train Epoch: 393 [200000/697932 (29%)]\tLoss: 138.490094\n",
      "Train Epoch: 393 [300000/697932 (43%)]\tLoss: 138.341781\n",
      "Train Epoch: 393 [400000/697932 (57%)]\tLoss: 136.847750\n",
      "Train Epoch: 393 [500000/697932 (72%)]\tLoss: 138.712469\n",
      "Train Epoch: 393 [600000/697932 (86%)]\tLoss: 136.577750\n",
      "====> Epoch: 393 Average loss: 137.8737\n",
      "====> Test set loss: 139.1048\n",
      "Train Epoch: 394 [0/697932 (0%)]\tLoss: 138.431328\n",
      "Train Epoch: 394 [100000/697932 (14%)]\tLoss: 138.741406\n",
      "Train Epoch: 394 [200000/697932 (29%)]\tLoss: 136.313875\n",
      "Train Epoch: 394 [300000/697932 (43%)]\tLoss: 138.592375\n",
      "Train Epoch: 394 [400000/697932 (57%)]\tLoss: 139.145844\n",
      "Train Epoch: 394 [500000/697932 (72%)]\tLoss: 138.582422\n",
      "Train Epoch: 394 [600000/697932 (86%)]\tLoss: 137.627109\n",
      "====> Epoch: 394 Average loss: 137.8809\n",
      "====> Test set loss: 139.1766\n",
      "Train Epoch: 395 [0/697932 (0%)]\tLoss: 137.645266\n",
      "Train Epoch: 395 [100000/697932 (14%)]\tLoss: 138.115750\n",
      "Train Epoch: 395 [200000/697932 (29%)]\tLoss: 138.068016\n",
      "Train Epoch: 395 [300000/697932 (43%)]\tLoss: 138.162094\n",
      "Train Epoch: 395 [400000/697932 (57%)]\tLoss: 138.008266\n",
      "Train Epoch: 395 [500000/697932 (72%)]\tLoss: 137.644656\n",
      "Train Epoch: 395 [600000/697932 (86%)]\tLoss: 139.899500\n",
      "====> Epoch: 395 Average loss: 137.8683\n",
      "====> Test set loss: 139.1491\n",
      "Train Epoch: 396 [0/697932 (0%)]\tLoss: 137.646312\n",
      "Train Epoch: 396 [100000/697932 (14%)]\tLoss: 137.783703\n",
      "Train Epoch: 396 [200000/697932 (29%)]\tLoss: 136.388813\n",
      "Train Epoch: 396 [300000/697932 (43%)]\tLoss: 138.663984\n",
      "Train Epoch: 396 [400000/697932 (57%)]\tLoss: 137.788813\n",
      "Train Epoch: 396 [500000/697932 (72%)]\tLoss: 136.402000\n",
      "Train Epoch: 396 [600000/697932 (86%)]\tLoss: 136.405828\n",
      "====> Epoch: 396 Average loss: 137.8701\n",
      "====> Test set loss: 139.1148\n",
      "Train Epoch: 397 [0/697932 (0%)]\tLoss: 137.213766\n",
      "Train Epoch: 397 [100000/697932 (14%)]\tLoss: 138.010031\n",
      "Train Epoch: 397 [200000/697932 (29%)]\tLoss: 137.089297\n",
      "Train Epoch: 397 [300000/697932 (43%)]\tLoss: 138.596141\n",
      "Train Epoch: 397 [400000/697932 (57%)]\tLoss: 139.981625\n",
      "Train Epoch: 397 [500000/697932 (72%)]\tLoss: 137.039000\n",
      "Train Epoch: 397 [600000/697932 (86%)]\tLoss: 137.277437\n",
      "====> Epoch: 397 Average loss: 137.8719\n",
      "====> Test set loss: 139.2674\n",
      "Train Epoch: 398 [0/697932 (0%)]\tLoss: 136.821594\n",
      "Train Epoch: 398 [100000/697932 (14%)]\tLoss: 137.992219\n",
      "Train Epoch: 398 [200000/697932 (29%)]\tLoss: 136.928687\n",
      "Train Epoch: 398 [300000/697932 (43%)]\tLoss: 138.730328\n",
      "Train Epoch: 398 [400000/697932 (57%)]\tLoss: 137.358609\n",
      "Train Epoch: 398 [500000/697932 (72%)]\tLoss: 137.653031\n",
      "Train Epoch: 398 [600000/697932 (86%)]\tLoss: 139.327313\n",
      "====> Epoch: 398 Average loss: 137.8753\n",
      "====> Test set loss: 139.2495\n",
      "Train Epoch: 399 [0/697932 (0%)]\tLoss: 136.043734\n",
      "Train Epoch: 399 [100000/697932 (14%)]\tLoss: 138.133156\n",
      "Train Epoch: 399 [200000/697932 (29%)]\tLoss: 138.880500\n",
      "Train Epoch: 399 [300000/697932 (43%)]\tLoss: 136.256594\n",
      "Train Epoch: 399 [400000/697932 (57%)]\tLoss: 138.326531\n",
      "Train Epoch: 399 [500000/697932 (72%)]\tLoss: 136.983328\n",
      "Train Epoch: 399 [600000/697932 (86%)]\tLoss: 140.039016\n",
      "====> Epoch: 399 Average loss: 137.8667\n",
      "====> Test set loss: 139.1298\n",
      "Train Epoch: 400 [0/697932 (0%)]\tLoss: 136.206766\n",
      "Train Epoch: 400 [100000/697932 (14%)]\tLoss: 137.911281\n",
      "Train Epoch: 400 [200000/697932 (29%)]\tLoss: 136.789094\n",
      "Train Epoch: 400 [300000/697932 (43%)]\tLoss: 138.824094\n",
      "Train Epoch: 400 [400000/697932 (57%)]\tLoss: 136.437844\n",
      "Train Epoch: 400 [500000/697932 (72%)]\tLoss: 138.780719\n",
      "Train Epoch: 400 [600000/697932 (86%)]\tLoss: 139.124125\n",
      "====> Epoch: 400 Average loss: 137.8706\n",
      "====> Test set loss: 139.2805\n",
      "Train Epoch: 401 [0/697932 (0%)]\tLoss: 137.995703\n",
      "Train Epoch: 401 [100000/697932 (14%)]\tLoss: 139.679047\n",
      "Train Epoch: 401 [200000/697932 (29%)]\tLoss: 139.370031\n",
      "Train Epoch: 401 [300000/697932 (43%)]\tLoss: 137.519891\n",
      "Train Epoch: 401 [400000/697932 (57%)]\tLoss: 138.004188\n",
      "Train Epoch: 401 [500000/697932 (72%)]\tLoss: 136.183875\n",
      "Train Epoch: 401 [600000/697932 (86%)]\tLoss: 137.844203\n",
      "====> Epoch: 401 Average loss: 137.8605\n",
      "====> Test set loss: 139.1380\n",
      "Train Epoch: 402 [0/697932 (0%)]\tLoss: 139.673687\n",
      "Train Epoch: 402 [100000/697932 (14%)]\tLoss: 137.780609\n",
      "Train Epoch: 402 [200000/697932 (29%)]\tLoss: 134.452828\n",
      "Train Epoch: 402 [300000/697932 (43%)]\tLoss: 139.028734\n",
      "Train Epoch: 402 [400000/697932 (57%)]\tLoss: 140.491750\n",
      "Train Epoch: 402 [500000/697932 (72%)]\tLoss: 136.144547\n",
      "Train Epoch: 402 [600000/697932 (86%)]\tLoss: 138.006125\n",
      "====> Epoch: 402 Average loss: 137.8676\n",
      "====> Test set loss: 139.0874\n",
      "Train Epoch: 403 [0/697932 (0%)]\tLoss: 136.670312\n",
      "Train Epoch: 403 [100000/697932 (14%)]\tLoss: 138.697641\n",
      "Train Epoch: 403 [200000/697932 (29%)]\tLoss: 139.472141\n",
      "Train Epoch: 403 [300000/697932 (43%)]\tLoss: 137.686719\n",
      "Train Epoch: 403 [400000/697932 (57%)]\tLoss: 138.872562\n",
      "Train Epoch: 403 [500000/697932 (72%)]\tLoss: 137.747531\n",
      "Train Epoch: 403 [600000/697932 (86%)]\tLoss: 139.282094\n",
      "====> Epoch: 403 Average loss: 137.8492\n",
      "====> Test set loss: 139.2267\n",
      "Train Epoch: 404 [0/697932 (0%)]\tLoss: 137.253703\n",
      "Train Epoch: 404 [100000/697932 (14%)]\tLoss: 139.017156\n",
      "Train Epoch: 404 [200000/697932 (29%)]\tLoss: 138.016406\n",
      "Train Epoch: 404 [300000/697932 (43%)]\tLoss: 137.902172\n",
      "Train Epoch: 404 [400000/697932 (57%)]\tLoss: 138.387000\n",
      "Train Epoch: 404 [500000/697932 (72%)]\tLoss: 135.876062\n",
      "Train Epoch: 404 [600000/697932 (86%)]\tLoss: 138.561406\n",
      "====> Epoch: 404 Average loss: 137.8457\n",
      "====> Test set loss: 139.1648\n",
      "Train Epoch: 405 [0/697932 (0%)]\tLoss: 134.713125\n",
      "Train Epoch: 405 [100000/697932 (14%)]\tLoss: 137.609344\n",
      "Train Epoch: 405 [200000/697932 (29%)]\tLoss: 137.005313\n",
      "Train Epoch: 405 [300000/697932 (43%)]\tLoss: 136.450141\n",
      "Train Epoch: 405 [400000/697932 (57%)]\tLoss: 138.075359\n",
      "Train Epoch: 405 [500000/697932 (72%)]\tLoss: 139.478891\n",
      "Train Epoch: 405 [600000/697932 (86%)]\tLoss: 135.445766\n",
      "====> Epoch: 405 Average loss: 137.8495\n",
      "====> Test set loss: 139.1017\n",
      "Train Epoch: 406 [0/697932 (0%)]\tLoss: 138.101969\n",
      "Train Epoch: 406 [100000/697932 (14%)]\tLoss: 135.704078\n",
      "Train Epoch: 406 [200000/697932 (29%)]\tLoss: 138.222422\n",
      "Train Epoch: 406 [300000/697932 (43%)]\tLoss: 137.700750\n",
      "Train Epoch: 406 [400000/697932 (57%)]\tLoss: 138.451531\n",
      "Train Epoch: 406 [500000/697932 (72%)]\tLoss: 137.813734\n",
      "Train Epoch: 406 [600000/697932 (86%)]\tLoss: 138.811703\n",
      "====> Epoch: 406 Average loss: 137.8413\n",
      "====> Test set loss: 139.1602\n",
      "Train Epoch: 407 [0/697932 (0%)]\tLoss: 137.294734\n",
      "Train Epoch: 407 [100000/697932 (14%)]\tLoss: 138.987937\n",
      "Train Epoch: 407 [200000/697932 (29%)]\tLoss: 137.350203\n",
      "Train Epoch: 407 [300000/697932 (43%)]\tLoss: 138.876922\n",
      "Train Epoch: 407 [400000/697932 (57%)]\tLoss: 135.276891\n",
      "Train Epoch: 407 [500000/697932 (72%)]\tLoss: 136.871563\n",
      "Train Epoch: 407 [600000/697932 (86%)]\tLoss: 136.781906\n",
      "====> Epoch: 407 Average loss: 137.8621\n",
      "====> Test set loss: 139.0934\n",
      "Train Epoch: 408 [0/697932 (0%)]\tLoss: 138.123266\n",
      "Train Epoch: 408 [100000/697932 (14%)]\tLoss: 140.155328\n",
      "Train Epoch: 408 [200000/697932 (29%)]\tLoss: 135.957406\n",
      "Train Epoch: 408 [300000/697932 (43%)]\tLoss: 137.651000\n",
      "Train Epoch: 408 [400000/697932 (57%)]\tLoss: 137.850500\n",
      "Train Epoch: 408 [500000/697932 (72%)]\tLoss: 137.671078\n",
      "Train Epoch: 408 [600000/697932 (86%)]\tLoss: 137.001563\n",
      "====> Epoch: 408 Average loss: 137.8479\n",
      "====> Test set loss: 139.1968\n",
      "Train Epoch: 409 [0/697932 (0%)]\tLoss: 137.333516\n",
      "Train Epoch: 409 [100000/697932 (14%)]\tLoss: 137.172734\n",
      "Train Epoch: 409 [200000/697932 (29%)]\tLoss: 138.584078\n",
      "Train Epoch: 409 [300000/697932 (43%)]\tLoss: 136.006406\n",
      "Train Epoch: 409 [400000/697932 (57%)]\tLoss: 137.967437\n",
      "Train Epoch: 409 [500000/697932 (72%)]\tLoss: 138.360500\n",
      "Train Epoch: 409 [600000/697932 (86%)]\tLoss: 136.206281\n",
      "====> Epoch: 409 Average loss: 137.8461\n",
      "====> Test set loss: 139.2299\n",
      "Train Epoch: 410 [0/697932 (0%)]\tLoss: 138.382062\n",
      "Train Epoch: 410 [100000/697932 (14%)]\tLoss: 137.642094\n",
      "Train Epoch: 410 [200000/697932 (29%)]\tLoss: 138.843063\n",
      "Train Epoch: 410 [300000/697932 (43%)]\tLoss: 136.623906\n",
      "Train Epoch: 410 [400000/697932 (57%)]\tLoss: 135.296906\n",
      "Train Epoch: 410 [500000/697932 (72%)]\tLoss: 139.291094\n",
      "Train Epoch: 410 [600000/697932 (86%)]\tLoss: 139.463578\n",
      "====> Epoch: 410 Average loss: 137.8473\n",
      "====> Test set loss: 139.1139\n",
      "Train Epoch: 411 [0/697932 (0%)]\tLoss: 137.594156\n",
      "Train Epoch: 411 [100000/697932 (14%)]\tLoss: 136.699344\n",
      "Train Epoch: 411 [200000/697932 (29%)]\tLoss: 137.444953\n",
      "Train Epoch: 411 [300000/697932 (43%)]\tLoss: 137.820047\n",
      "Train Epoch: 411 [400000/697932 (57%)]\tLoss: 135.285969\n",
      "Train Epoch: 411 [500000/697932 (72%)]\tLoss: 138.419297\n",
      "Train Epoch: 411 [600000/697932 (86%)]\tLoss: 139.374437\n",
      "====> Epoch: 411 Average loss: 137.8492\n",
      "====> Test set loss: 139.1057\n",
      "Train Epoch: 412 [0/697932 (0%)]\tLoss: 138.936516\n",
      "Train Epoch: 412 [100000/697932 (14%)]\tLoss: 137.486219\n",
      "Train Epoch: 412 [200000/697932 (29%)]\tLoss: 138.149438\n",
      "Train Epoch: 412 [300000/697932 (43%)]\tLoss: 140.352953\n",
      "Train Epoch: 412 [400000/697932 (57%)]\tLoss: 136.079688\n",
      "Train Epoch: 412 [500000/697932 (72%)]\tLoss: 136.487234\n",
      "Train Epoch: 412 [600000/697932 (86%)]\tLoss: 136.533516\n",
      "====> Epoch: 412 Average loss: 137.8225\n",
      "====> Test set loss: 139.1272\n",
      "Train Epoch: 413 [0/697932 (0%)]\tLoss: 137.898469\n",
      "Train Epoch: 413 [100000/697932 (14%)]\tLoss: 136.107891\n",
      "Train Epoch: 413 [200000/697932 (29%)]\tLoss: 137.490750\n",
      "Train Epoch: 413 [300000/697932 (43%)]\tLoss: 139.207812\n",
      "Train Epoch: 413 [400000/697932 (57%)]\tLoss: 136.288531\n",
      "Train Epoch: 413 [500000/697932 (72%)]\tLoss: 141.524828\n",
      "Train Epoch: 413 [600000/697932 (86%)]\tLoss: 136.960719\n",
      "====> Epoch: 413 Average loss: 137.8321\n",
      "====> Test set loss: 139.1663\n",
      "Train Epoch: 414 [0/697932 (0%)]\tLoss: 139.793125\n",
      "Train Epoch: 414 [100000/697932 (14%)]\tLoss: 137.791391\n",
      "Train Epoch: 414 [200000/697932 (29%)]\tLoss: 136.823453\n",
      "Train Epoch: 414 [300000/697932 (43%)]\tLoss: 139.114406\n",
      "Train Epoch: 414 [400000/697932 (57%)]\tLoss: 136.549297\n",
      "Train Epoch: 414 [500000/697932 (72%)]\tLoss: 139.116109\n",
      "Train Epoch: 414 [600000/697932 (86%)]\tLoss: 136.709766\n",
      "====> Epoch: 414 Average loss: 137.8499\n",
      "====> Test set loss: 139.1974\n",
      "Train Epoch: 415 [0/697932 (0%)]\tLoss: 138.140391\n",
      "Train Epoch: 415 [100000/697932 (14%)]\tLoss: 137.749500\n",
      "Train Epoch: 415 [200000/697932 (29%)]\tLoss: 138.802750\n",
      "Train Epoch: 415 [300000/697932 (43%)]\tLoss: 135.766219\n",
      "Train Epoch: 415 [400000/697932 (57%)]\tLoss: 138.323672\n",
      "Train Epoch: 415 [500000/697932 (72%)]\tLoss: 135.993984\n",
      "Train Epoch: 415 [600000/697932 (86%)]\tLoss: 136.785000\n",
      "====> Epoch: 415 Average loss: 137.8425\n",
      "====> Test set loss: 139.0707\n",
      "Train Epoch: 416 [0/697932 (0%)]\tLoss: 137.352422\n",
      "Train Epoch: 416 [100000/697932 (14%)]\tLoss: 135.005875\n",
      "Train Epoch: 416 [200000/697932 (29%)]\tLoss: 138.858859\n",
      "Train Epoch: 416 [300000/697932 (43%)]\tLoss: 137.136844\n",
      "Train Epoch: 416 [400000/697932 (57%)]\tLoss: 137.541328\n",
      "Train Epoch: 416 [500000/697932 (72%)]\tLoss: 139.167500\n",
      "Train Epoch: 416 [600000/697932 (86%)]\tLoss: 136.809953\n",
      "====> Epoch: 416 Average loss: 137.8324\n",
      "====> Test set loss: 139.1877\n",
      "Train Epoch: 417 [0/697932 (0%)]\tLoss: 138.855375\n",
      "Train Epoch: 417 [100000/697932 (14%)]\tLoss: 136.901672\n",
      "Train Epoch: 417 [200000/697932 (29%)]\tLoss: 137.701781\n",
      "Train Epoch: 417 [300000/697932 (43%)]\tLoss: 138.813312\n",
      "Train Epoch: 417 [400000/697932 (57%)]\tLoss: 136.649188\n",
      "Train Epoch: 417 [500000/697932 (72%)]\tLoss: 138.194312\n",
      "Train Epoch: 417 [600000/697932 (86%)]\tLoss: 137.012016\n",
      "====> Epoch: 417 Average loss: 137.8151\n",
      "====> Test set loss: 139.1058\n",
      "Train Epoch: 418 [0/697932 (0%)]\tLoss: 136.837828\n",
      "Train Epoch: 418 [100000/697932 (14%)]\tLoss: 139.610984\n",
      "Train Epoch: 418 [200000/697932 (29%)]\tLoss: 139.074328\n",
      "Train Epoch: 418 [300000/697932 (43%)]\tLoss: 137.181766\n",
      "Train Epoch: 418 [400000/697932 (57%)]\tLoss: 137.348047\n",
      "Train Epoch: 418 [500000/697932 (72%)]\tLoss: 138.289969\n",
      "Train Epoch: 418 [600000/697932 (86%)]\tLoss: 139.486156\n",
      "====> Epoch: 418 Average loss: 137.8331\n",
      "====> Test set loss: 139.1190\n",
      "Train Epoch: 419 [0/697932 (0%)]\tLoss: 139.525984\n",
      "Train Epoch: 419 [100000/697932 (14%)]\tLoss: 138.968219\n",
      "Train Epoch: 419 [200000/697932 (29%)]\tLoss: 138.594344\n",
      "Train Epoch: 419 [300000/697932 (43%)]\tLoss: 136.908078\n",
      "Train Epoch: 419 [400000/697932 (57%)]\tLoss: 135.881922\n",
      "Train Epoch: 419 [500000/697932 (72%)]\tLoss: 137.809828\n",
      "Train Epoch: 419 [600000/697932 (86%)]\tLoss: 138.256516\n",
      "====> Epoch: 419 Average loss: 137.8371\n",
      "====> Test set loss: 139.1972\n",
      "Train Epoch: 420 [0/697932 (0%)]\tLoss: 138.390656\n",
      "Train Epoch: 420 [100000/697932 (14%)]\tLoss: 137.440359\n",
      "Train Epoch: 420 [200000/697932 (29%)]\tLoss: 139.651813\n",
      "Train Epoch: 420 [300000/697932 (43%)]\tLoss: 138.551125\n",
      "Train Epoch: 420 [400000/697932 (57%)]\tLoss: 140.472375\n",
      "Train Epoch: 420 [500000/697932 (72%)]\tLoss: 139.617984\n",
      "Train Epoch: 420 [600000/697932 (86%)]\tLoss: 135.811672\n",
      "====> Epoch: 420 Average loss: 137.8182\n",
      "====> Test set loss: 139.2181\n",
      "Train Epoch: 421 [0/697932 (0%)]\tLoss: 140.163266\n",
      "Train Epoch: 421 [100000/697932 (14%)]\tLoss: 136.542375\n",
      "Train Epoch: 421 [200000/697932 (29%)]\tLoss: 138.714266\n",
      "Train Epoch: 421 [300000/697932 (43%)]\tLoss: 137.151328\n",
      "Train Epoch: 421 [400000/697932 (57%)]\tLoss: 138.073563\n",
      "Train Epoch: 421 [500000/697932 (72%)]\tLoss: 138.019703\n",
      "Train Epoch: 421 [600000/697932 (86%)]\tLoss: 139.489656\n",
      "====> Epoch: 421 Average loss: 137.8157\n",
      "====> Test set loss: 139.0857\n",
      "Train Epoch: 422 [0/697932 (0%)]\tLoss: 137.952781\n",
      "Train Epoch: 422 [100000/697932 (14%)]\tLoss: 138.210578\n",
      "Train Epoch: 422 [200000/697932 (29%)]\tLoss: 136.896437\n",
      "Train Epoch: 422 [300000/697932 (43%)]\tLoss: 136.885047\n",
      "Train Epoch: 422 [400000/697932 (57%)]\tLoss: 137.792750\n",
      "Train Epoch: 422 [500000/697932 (72%)]\tLoss: 138.924609\n",
      "Train Epoch: 422 [600000/697932 (86%)]\tLoss: 136.909047\n",
      "====> Epoch: 422 Average loss: 137.8122\n",
      "====> Test set loss: 139.2145\n",
      "Train Epoch: 423 [0/697932 (0%)]\tLoss: 138.765422\n",
      "Train Epoch: 423 [100000/697932 (14%)]\tLoss: 136.913187\n",
      "Train Epoch: 423 [200000/697932 (29%)]\tLoss: 138.807172\n",
      "Train Epoch: 423 [300000/697932 (43%)]\tLoss: 136.848344\n",
      "Train Epoch: 423 [400000/697932 (57%)]\tLoss: 137.723938\n",
      "Train Epoch: 423 [500000/697932 (72%)]\tLoss: 136.808969\n",
      "Train Epoch: 423 [600000/697932 (86%)]\tLoss: 138.226203\n",
      "====> Epoch: 423 Average loss: 137.8372\n",
      "====> Test set loss: 139.1030\n",
      "Train Epoch: 424 [0/697932 (0%)]\tLoss: 137.532594\n",
      "Train Epoch: 424 [100000/697932 (14%)]\tLoss: 138.349063\n",
      "Train Epoch: 424 [200000/697932 (29%)]\tLoss: 136.624641\n",
      "Train Epoch: 424 [300000/697932 (43%)]\tLoss: 137.408781\n",
      "Train Epoch: 424 [400000/697932 (57%)]\tLoss: 137.112344\n",
      "Train Epoch: 424 [500000/697932 (72%)]\tLoss: 138.357609\n",
      "Train Epoch: 424 [600000/697932 (86%)]\tLoss: 137.954953\n",
      "====> Epoch: 424 Average loss: 137.8190\n",
      "====> Test set loss: 139.0752\n",
      "Train Epoch: 425 [0/697932 (0%)]\tLoss: 138.514438\n",
      "Train Epoch: 425 [100000/697932 (14%)]\tLoss: 140.211062\n",
      "Train Epoch: 425 [200000/697932 (29%)]\tLoss: 139.857641\n",
      "Train Epoch: 425 [300000/697932 (43%)]\tLoss: 137.597750\n",
      "Train Epoch: 425 [400000/697932 (57%)]\tLoss: 135.101406\n",
      "Train Epoch: 425 [500000/697932 (72%)]\tLoss: 137.213156\n",
      "Train Epoch: 425 [600000/697932 (86%)]\tLoss: 138.082266\n",
      "====> Epoch: 425 Average loss: 137.8299\n",
      "====> Test set loss: 139.0894\n",
      "Train Epoch: 426 [0/697932 (0%)]\tLoss: 137.339969\n",
      "Train Epoch: 426 [100000/697932 (14%)]\tLoss: 136.334922\n",
      "Train Epoch: 426 [200000/697932 (29%)]\tLoss: 137.089750\n",
      "Train Epoch: 426 [300000/697932 (43%)]\tLoss: 135.629078\n",
      "Train Epoch: 426 [400000/697932 (57%)]\tLoss: 138.107609\n",
      "Train Epoch: 426 [500000/697932 (72%)]\tLoss: 137.710797\n",
      "Train Epoch: 426 [600000/697932 (86%)]\tLoss: 137.236469\n",
      "====> Epoch: 426 Average loss: 137.8083\n",
      "====> Test set loss: 139.0819\n",
      "Train Epoch: 427 [0/697932 (0%)]\tLoss: 136.999047\n",
      "Train Epoch: 427 [100000/697932 (14%)]\tLoss: 136.811438\n",
      "Train Epoch: 427 [200000/697932 (29%)]\tLoss: 138.368781\n",
      "Train Epoch: 427 [300000/697932 (43%)]\tLoss: 138.810328\n",
      "Train Epoch: 427 [400000/697932 (57%)]\tLoss: 138.348062\n",
      "Train Epoch: 427 [500000/697932 (72%)]\tLoss: 137.406563\n",
      "Train Epoch: 427 [600000/697932 (86%)]\tLoss: 136.616578\n",
      "====> Epoch: 427 Average loss: 137.8194\n",
      "====> Test set loss: 139.0911\n",
      "Train Epoch: 428 [0/697932 (0%)]\tLoss: 138.227328\n",
      "Train Epoch: 428 [100000/697932 (14%)]\tLoss: 137.762812\n",
      "Train Epoch: 428 [200000/697932 (29%)]\tLoss: 138.057906\n",
      "Train Epoch: 428 [300000/697932 (43%)]\tLoss: 140.243172\n",
      "Train Epoch: 428 [400000/697932 (57%)]\tLoss: 138.282734\n",
      "Train Epoch: 428 [500000/697932 (72%)]\tLoss: 138.820172\n",
      "Train Epoch: 428 [600000/697932 (86%)]\tLoss: 137.213844\n",
      "====> Epoch: 428 Average loss: 137.8074\n",
      "====> Test set loss: 139.2469\n",
      "Train Epoch: 429 [0/697932 (0%)]\tLoss: 139.172406\n",
      "Train Epoch: 429 [100000/697932 (14%)]\tLoss: 136.656969\n",
      "Train Epoch: 429 [200000/697932 (29%)]\tLoss: 137.268359\n",
      "Train Epoch: 429 [300000/697932 (43%)]\tLoss: 137.889031\n",
      "Train Epoch: 429 [400000/697932 (57%)]\tLoss: 139.318078\n",
      "Train Epoch: 429 [500000/697932 (72%)]\tLoss: 138.152875\n",
      "Train Epoch: 429 [600000/697932 (86%)]\tLoss: 137.821609\n",
      "====> Epoch: 429 Average loss: 137.8016\n",
      "====> Test set loss: 139.2854\n",
      "Train Epoch: 430 [0/697932 (0%)]\tLoss: 138.683437\n",
      "Train Epoch: 430 [100000/697932 (14%)]\tLoss: 138.038094\n",
      "Train Epoch: 430 [200000/697932 (29%)]\tLoss: 138.217625\n",
      "Train Epoch: 430 [300000/697932 (43%)]\tLoss: 136.275359\n",
      "Train Epoch: 430 [400000/697932 (57%)]\tLoss: 139.095875\n",
      "Train Epoch: 430 [500000/697932 (72%)]\tLoss: 135.786391\n",
      "Train Epoch: 430 [600000/697932 (86%)]\tLoss: 136.756859\n",
      "====> Epoch: 430 Average loss: 137.7941\n",
      "====> Test set loss: 139.0604\n",
      "Train Epoch: 431 [0/697932 (0%)]\tLoss: 136.455625\n",
      "Train Epoch: 431 [100000/697932 (14%)]\tLoss: 139.226219\n",
      "Train Epoch: 431 [200000/697932 (29%)]\tLoss: 138.071000\n",
      "Train Epoch: 431 [300000/697932 (43%)]\tLoss: 139.340313\n",
      "Train Epoch: 431 [400000/697932 (57%)]\tLoss: 137.990750\n",
      "Train Epoch: 431 [500000/697932 (72%)]\tLoss: 138.932344\n",
      "Train Epoch: 431 [600000/697932 (86%)]\tLoss: 136.129516\n",
      "====> Epoch: 431 Average loss: 137.8113\n",
      "====> Test set loss: 139.1405\n",
      "Train Epoch: 432 [0/697932 (0%)]\tLoss: 137.654125\n",
      "Train Epoch: 432 [100000/697932 (14%)]\tLoss: 137.678516\n",
      "Train Epoch: 432 [200000/697932 (29%)]\tLoss: 136.743406\n",
      "Train Epoch: 432 [300000/697932 (43%)]\tLoss: 137.715141\n",
      "Train Epoch: 432 [400000/697932 (57%)]\tLoss: 137.384312\n",
      "Train Epoch: 432 [500000/697932 (72%)]\tLoss: 138.934672\n",
      "Train Epoch: 432 [600000/697932 (86%)]\tLoss: 137.902062\n",
      "====> Epoch: 432 Average loss: 137.8083\n",
      "====> Test set loss: 139.1576\n",
      "Train Epoch: 433 [0/697932 (0%)]\tLoss: 138.798094\n",
      "Train Epoch: 433 [100000/697932 (14%)]\tLoss: 137.982297\n",
      "Train Epoch: 433 [200000/697932 (29%)]\tLoss: 137.206922\n",
      "Train Epoch: 433 [300000/697932 (43%)]\tLoss: 137.929688\n",
      "Train Epoch: 433 [400000/697932 (57%)]\tLoss: 136.737406\n",
      "Train Epoch: 433 [500000/697932 (72%)]\tLoss: 138.766719\n",
      "Train Epoch: 433 [600000/697932 (86%)]\tLoss: 139.127016\n",
      "====> Epoch: 433 Average loss: 137.8069\n",
      "====> Test set loss: 139.1354\n",
      "Train Epoch: 434 [0/697932 (0%)]\tLoss: 138.268687\n",
      "Train Epoch: 434 [100000/697932 (14%)]\tLoss: 137.961016\n",
      "Train Epoch: 434 [200000/697932 (29%)]\tLoss: 137.636984\n",
      "Train Epoch: 434 [300000/697932 (43%)]\tLoss: 137.884719\n",
      "Train Epoch: 434 [400000/697932 (57%)]\tLoss: 136.284406\n",
      "Train Epoch: 434 [500000/697932 (72%)]\tLoss: 136.735234\n",
      "Train Epoch: 434 [600000/697932 (86%)]\tLoss: 136.292156\n",
      "====> Epoch: 434 Average loss: 137.7948\n",
      "====> Test set loss: 139.1556\n",
      "Train Epoch: 435 [0/697932 (0%)]\tLoss: 138.321219\n",
      "Train Epoch: 435 [100000/697932 (14%)]\tLoss: 136.934609\n",
      "Train Epoch: 435 [200000/697932 (29%)]\tLoss: 137.664688\n",
      "Train Epoch: 435 [300000/697932 (43%)]\tLoss: 136.818453\n",
      "Train Epoch: 435 [400000/697932 (57%)]\tLoss: 139.325469\n",
      "Train Epoch: 435 [500000/697932 (72%)]\tLoss: 137.773250\n",
      "Train Epoch: 435 [600000/697932 (86%)]\tLoss: 137.432813\n",
      "====> Epoch: 435 Average loss: 137.8005\n",
      "====> Test set loss: 139.2337\n",
      "Train Epoch: 436 [0/697932 (0%)]\tLoss: 137.731063\n",
      "Train Epoch: 436 [100000/697932 (14%)]\tLoss: 138.190719\n",
      "Train Epoch: 436 [200000/697932 (29%)]\tLoss: 138.303594\n",
      "Train Epoch: 436 [300000/697932 (43%)]\tLoss: 137.339812\n",
      "Train Epoch: 436 [400000/697932 (57%)]\tLoss: 140.500078\n",
      "Train Epoch: 436 [500000/697932 (72%)]\tLoss: 138.329891\n",
      "Train Epoch: 436 [600000/697932 (86%)]\tLoss: 135.348844\n",
      "====> Epoch: 436 Average loss: 137.7979\n",
      "====> Test set loss: 139.0888\n",
      "Train Epoch: 437 [0/697932 (0%)]\tLoss: 139.442813\n",
      "Train Epoch: 437 [100000/697932 (14%)]\tLoss: 138.162531\n",
      "Train Epoch: 437 [200000/697932 (29%)]\tLoss: 136.236641\n",
      "Train Epoch: 437 [300000/697932 (43%)]\tLoss: 138.841234\n",
      "Train Epoch: 437 [400000/697932 (57%)]\tLoss: 137.647562\n",
      "Train Epoch: 437 [500000/697932 (72%)]\tLoss: 141.106375\n",
      "Train Epoch: 437 [600000/697932 (86%)]\tLoss: 137.952250\n",
      "====> Epoch: 437 Average loss: 137.8024\n",
      "====> Test set loss: 139.1038\n",
      "Train Epoch: 438 [0/697932 (0%)]\tLoss: 136.843969\n",
      "Train Epoch: 438 [100000/697932 (14%)]\tLoss: 135.154937\n",
      "Train Epoch: 438 [200000/697932 (29%)]\tLoss: 138.094234\n",
      "Train Epoch: 438 [300000/697932 (43%)]\tLoss: 139.136516\n",
      "Train Epoch: 438 [400000/697932 (57%)]\tLoss: 137.216766\n",
      "Train Epoch: 438 [500000/697932 (72%)]\tLoss: 135.876516\n",
      "Train Epoch: 438 [600000/697932 (86%)]\tLoss: 137.859719\n",
      "====> Epoch: 438 Average loss: 137.7827\n",
      "====> Test set loss: 139.1600\n",
      "Train Epoch: 439 [0/697932 (0%)]\tLoss: 137.059719\n",
      "Train Epoch: 439 [100000/697932 (14%)]\tLoss: 138.023531\n",
      "Train Epoch: 439 [200000/697932 (29%)]\tLoss: 138.361000\n",
      "Train Epoch: 439 [300000/697932 (43%)]\tLoss: 137.575922\n",
      "Train Epoch: 439 [400000/697932 (57%)]\tLoss: 138.427172\n",
      "Train Epoch: 439 [500000/697932 (72%)]\tLoss: 136.767687\n",
      "Train Epoch: 439 [600000/697932 (86%)]\tLoss: 138.117422\n",
      "====> Epoch: 439 Average loss: 137.7908\n",
      "====> Test set loss: 139.1643\n",
      "Train Epoch: 440 [0/697932 (0%)]\tLoss: 138.754219\n",
      "Train Epoch: 440 [100000/697932 (14%)]\tLoss: 137.348531\n",
      "Train Epoch: 440 [200000/697932 (29%)]\tLoss: 138.217813\n",
      "Train Epoch: 440 [300000/697932 (43%)]\tLoss: 138.260234\n",
      "Train Epoch: 440 [400000/697932 (57%)]\tLoss: 136.410687\n",
      "Train Epoch: 440 [500000/697932 (72%)]\tLoss: 138.606766\n",
      "Train Epoch: 440 [600000/697932 (86%)]\tLoss: 136.733609\n",
      "====> Epoch: 440 Average loss: 137.8016\n",
      "====> Test set loss: 139.2468\n",
      "Train Epoch: 441 [0/697932 (0%)]\tLoss: 139.433375\n",
      "Train Epoch: 441 [100000/697932 (14%)]\tLoss: 137.666969\n",
      "Train Epoch: 441 [200000/697932 (29%)]\tLoss: 138.592641\n",
      "Train Epoch: 441 [300000/697932 (43%)]\tLoss: 136.823672\n",
      "Train Epoch: 441 [400000/697932 (57%)]\tLoss: 138.342141\n",
      "Train Epoch: 441 [500000/697932 (72%)]\tLoss: 137.879719\n",
      "Train Epoch: 441 [600000/697932 (86%)]\tLoss: 137.910609\n",
      "====> Epoch: 441 Average loss: 137.7902\n",
      "====> Test set loss: 139.1554\n",
      "Train Epoch: 442 [0/697932 (0%)]\tLoss: 136.598062\n",
      "Train Epoch: 442 [100000/697932 (14%)]\tLoss: 139.576016\n",
      "Train Epoch: 442 [200000/697932 (29%)]\tLoss: 137.524500\n",
      "Train Epoch: 442 [300000/697932 (43%)]\tLoss: 137.364531\n",
      "Train Epoch: 442 [400000/697932 (57%)]\tLoss: 138.455062\n",
      "Train Epoch: 442 [500000/697932 (72%)]\tLoss: 138.602234\n",
      "Train Epoch: 442 [600000/697932 (86%)]\tLoss: 136.924422\n",
      "====> Epoch: 442 Average loss: 137.7857\n",
      "====> Test set loss: 139.1687\n",
      "Train Epoch: 443 [0/697932 (0%)]\tLoss: 140.406328\n",
      "Train Epoch: 443 [100000/697932 (14%)]\tLoss: 139.102375\n",
      "Train Epoch: 443 [200000/697932 (29%)]\tLoss: 136.725156\n",
      "Train Epoch: 443 [300000/697932 (43%)]\tLoss: 138.967953\n",
      "Train Epoch: 443 [400000/697932 (57%)]\tLoss: 138.686531\n",
      "Train Epoch: 443 [500000/697932 (72%)]\tLoss: 136.595250\n",
      "Train Epoch: 443 [600000/697932 (86%)]\tLoss: 137.386750\n",
      "====> Epoch: 443 Average loss: 137.7808\n",
      "====> Test set loss: 139.1115\n",
      "Train Epoch: 444 [0/697932 (0%)]\tLoss: 138.054375\n",
      "Train Epoch: 444 [100000/697932 (14%)]\tLoss: 139.234984\n",
      "Train Epoch: 444 [200000/697932 (29%)]\tLoss: 135.609344\n",
      "Train Epoch: 444 [300000/697932 (43%)]\tLoss: 135.916641\n",
      "Train Epoch: 444 [400000/697932 (57%)]\tLoss: 137.878062\n",
      "Train Epoch: 444 [500000/697932 (72%)]\tLoss: 137.210438\n",
      "Train Epoch: 444 [600000/697932 (86%)]\tLoss: 135.264719\n",
      "====> Epoch: 444 Average loss: 137.7808\n",
      "====> Test set loss: 139.1381\n",
      "Train Epoch: 445 [0/697932 (0%)]\tLoss: 138.460000\n",
      "Train Epoch: 445 [100000/697932 (14%)]\tLoss: 138.131203\n",
      "Train Epoch: 445 [200000/697932 (29%)]\tLoss: 138.749172\n",
      "Train Epoch: 445 [300000/697932 (43%)]\tLoss: 137.402781\n",
      "Train Epoch: 445 [400000/697932 (57%)]\tLoss: 137.779875\n",
      "Train Epoch: 445 [500000/697932 (72%)]\tLoss: 135.779203\n",
      "Train Epoch: 445 [600000/697932 (86%)]\tLoss: 134.901203\n",
      "====> Epoch: 445 Average loss: 137.7797\n",
      "====> Test set loss: 139.1298\n",
      "Train Epoch: 446 [0/697932 (0%)]\tLoss: 136.201344\n",
      "Train Epoch: 446 [100000/697932 (14%)]\tLoss: 137.220078\n",
      "Train Epoch: 446 [200000/697932 (29%)]\tLoss: 137.204609\n",
      "Train Epoch: 446 [300000/697932 (43%)]\tLoss: 138.460703\n",
      "Train Epoch: 446 [400000/697932 (57%)]\tLoss: 138.686359\n",
      "Train Epoch: 446 [500000/697932 (72%)]\tLoss: 139.534141\n",
      "Train Epoch: 446 [600000/697932 (86%)]\tLoss: 139.807906\n",
      "====> Epoch: 446 Average loss: 137.7727\n",
      "====> Test set loss: 139.1674\n",
      "Train Epoch: 447 [0/697932 (0%)]\tLoss: 136.312062\n",
      "Train Epoch: 447 [100000/697932 (14%)]\tLoss: 137.778953\n",
      "Train Epoch: 447 [200000/697932 (29%)]\tLoss: 139.548438\n",
      "Train Epoch: 447 [300000/697932 (43%)]\tLoss: 137.646359\n",
      "Train Epoch: 447 [400000/697932 (57%)]\tLoss: 138.924453\n",
      "Train Epoch: 447 [500000/697932 (72%)]\tLoss: 138.421188\n",
      "Train Epoch: 447 [600000/697932 (86%)]\tLoss: 138.924484\n",
      "====> Epoch: 447 Average loss: 137.7898\n",
      "====> Test set loss: 139.1948\n",
      "Train Epoch: 448 [0/697932 (0%)]\tLoss: 138.268188\n",
      "Train Epoch: 448 [100000/697932 (14%)]\tLoss: 139.851984\n",
      "Train Epoch: 448 [200000/697932 (29%)]\tLoss: 135.650344\n",
      "Train Epoch: 448 [300000/697932 (43%)]\tLoss: 138.117891\n",
      "Train Epoch: 448 [400000/697932 (57%)]\tLoss: 137.272016\n",
      "Train Epoch: 448 [500000/697932 (72%)]\tLoss: 136.170437\n",
      "Train Epoch: 448 [600000/697932 (86%)]\tLoss: 137.559531\n",
      "====> Epoch: 448 Average loss: 137.7866\n",
      "====> Test set loss: 139.0648\n",
      "Train Epoch: 449 [0/697932 (0%)]\tLoss: 136.328188\n",
      "Train Epoch: 449 [100000/697932 (14%)]\tLoss: 137.284312\n",
      "Train Epoch: 449 [200000/697932 (29%)]\tLoss: 136.920344\n",
      "Train Epoch: 449 [300000/697932 (43%)]\tLoss: 139.425484\n",
      "Train Epoch: 449 [400000/697932 (57%)]\tLoss: 138.409078\n",
      "Train Epoch: 449 [500000/697932 (72%)]\tLoss: 137.988000\n",
      "Train Epoch: 449 [600000/697932 (86%)]\tLoss: 137.301437\n",
      "====> Epoch: 449 Average loss: 137.7749\n",
      "====> Test set loss: 139.1624\n",
      "Train Epoch: 450 [0/697932 (0%)]\tLoss: 136.368687\n",
      "Train Epoch: 450 [100000/697932 (14%)]\tLoss: 136.767969\n",
      "Train Epoch: 450 [200000/697932 (29%)]\tLoss: 135.826172\n",
      "Train Epoch: 450 [300000/697932 (43%)]\tLoss: 137.412781\n",
      "Train Epoch: 450 [400000/697932 (57%)]\tLoss: 137.950938\n",
      "Train Epoch: 450 [500000/697932 (72%)]\tLoss: 137.382703\n",
      "Train Epoch: 450 [600000/697932 (86%)]\tLoss: 137.160578\n",
      "====> Epoch: 450 Average loss: 137.7759\n",
      "====> Test set loss: 139.1278\n",
      "Train Epoch: 451 [0/697932 (0%)]\tLoss: 140.323359\n",
      "Train Epoch: 451 [100000/697932 (14%)]\tLoss: 137.926187\n",
      "Train Epoch: 451 [200000/697932 (29%)]\tLoss: 138.754297\n",
      "Train Epoch: 451 [300000/697932 (43%)]\tLoss: 136.408797\n",
      "Train Epoch: 451 [400000/697932 (57%)]\tLoss: 137.808781\n",
      "Train Epoch: 451 [500000/697932 (72%)]\tLoss: 138.126203\n",
      "Train Epoch: 451 [600000/697932 (86%)]\tLoss: 137.913000\n",
      "====> Epoch: 451 Average loss: 137.7688\n",
      "====> Test set loss: 139.0577\n",
      "Train Epoch: 452 [0/697932 (0%)]\tLoss: 138.144953\n",
      "Train Epoch: 452 [100000/697932 (14%)]\tLoss: 136.608797\n",
      "Train Epoch: 452 [200000/697932 (29%)]\tLoss: 139.407422\n",
      "Train Epoch: 452 [300000/697932 (43%)]\tLoss: 136.508094\n",
      "Train Epoch: 452 [400000/697932 (57%)]\tLoss: 137.609297\n",
      "Train Epoch: 452 [500000/697932 (72%)]\tLoss: 137.143219\n",
      "Train Epoch: 452 [600000/697932 (86%)]\tLoss: 135.611203\n",
      "====> Epoch: 452 Average loss: 137.7702\n",
      "====> Test set loss: 139.1392\n",
      "Train Epoch: 453 [0/697932 (0%)]\tLoss: 138.165312\n",
      "Train Epoch: 453 [100000/697932 (14%)]\tLoss: 137.857531\n",
      "Train Epoch: 453 [200000/697932 (29%)]\tLoss: 136.476687\n",
      "Train Epoch: 453 [300000/697932 (43%)]\tLoss: 138.707156\n",
      "Train Epoch: 453 [400000/697932 (57%)]\tLoss: 139.497359\n",
      "Train Epoch: 453 [500000/697932 (72%)]\tLoss: 137.320031\n",
      "Train Epoch: 453 [600000/697932 (86%)]\tLoss: 138.481219\n",
      "====> Epoch: 453 Average loss: 137.7724\n",
      "====> Test set loss: 139.1132\n",
      "Train Epoch: 454 [0/697932 (0%)]\tLoss: 137.287828\n",
      "Train Epoch: 454 [100000/697932 (14%)]\tLoss: 135.616422\n",
      "Train Epoch: 454 [200000/697932 (29%)]\tLoss: 136.907219\n",
      "Train Epoch: 454 [300000/697932 (43%)]\tLoss: 136.283047\n",
      "Train Epoch: 454 [400000/697932 (57%)]\tLoss: 138.761812\n",
      "Train Epoch: 454 [500000/697932 (72%)]\tLoss: 138.200859\n",
      "Train Epoch: 454 [600000/697932 (86%)]\tLoss: 138.189672\n",
      "====> Epoch: 454 Average loss: 137.7691\n",
      "====> Test set loss: 139.0545\n",
      "Train Epoch: 455 [0/697932 (0%)]\tLoss: 137.048531\n",
      "Train Epoch: 455 [100000/697932 (14%)]\tLoss: 137.579312\n",
      "Train Epoch: 455 [200000/697932 (29%)]\tLoss: 139.928734\n",
      "Train Epoch: 455 [300000/697932 (43%)]\tLoss: 136.606766\n",
      "Train Epoch: 455 [400000/697932 (57%)]\tLoss: 137.792469\n",
      "Train Epoch: 455 [500000/697932 (72%)]\tLoss: 138.834422\n",
      "Train Epoch: 455 [600000/697932 (86%)]\tLoss: 137.909031\n",
      "====> Epoch: 455 Average loss: 137.7623\n",
      "====> Test set loss: 139.1931\n",
      "Train Epoch: 456 [0/697932 (0%)]\tLoss: 137.026125\n",
      "Train Epoch: 456 [100000/697932 (14%)]\tLoss: 137.602719\n",
      "Train Epoch: 456 [200000/697932 (29%)]\tLoss: 136.543719\n",
      "Train Epoch: 456 [300000/697932 (43%)]\tLoss: 137.296578\n",
      "Train Epoch: 456 [400000/697932 (57%)]\tLoss: 136.324922\n",
      "Train Epoch: 456 [500000/697932 (72%)]\tLoss: 135.906672\n",
      "Train Epoch: 456 [600000/697932 (86%)]\tLoss: 137.217156\n",
      "====> Epoch: 456 Average loss: 137.7608\n",
      "====> Test set loss: 139.0390\n",
      "Train Epoch: 457 [0/697932 (0%)]\tLoss: 136.526172\n",
      "Train Epoch: 457 [100000/697932 (14%)]\tLoss: 137.543500\n",
      "Train Epoch: 457 [200000/697932 (29%)]\tLoss: 137.711391\n",
      "Train Epoch: 457 [300000/697932 (43%)]\tLoss: 138.694344\n",
      "Train Epoch: 457 [400000/697932 (57%)]\tLoss: 139.015109\n",
      "Train Epoch: 457 [500000/697932 (72%)]\tLoss: 138.186438\n",
      "Train Epoch: 457 [600000/697932 (86%)]\tLoss: 138.716797\n",
      "====> Epoch: 457 Average loss: 137.7618\n",
      "====> Test set loss: 139.0802\n",
      "Train Epoch: 458 [0/697932 (0%)]\tLoss: 137.658984\n",
      "Train Epoch: 458 [100000/697932 (14%)]\tLoss: 137.734531\n",
      "Train Epoch: 458 [200000/697932 (29%)]\tLoss: 137.875656\n",
      "Train Epoch: 458 [300000/697932 (43%)]\tLoss: 135.955156\n",
      "Train Epoch: 458 [400000/697932 (57%)]\tLoss: 138.683297\n",
      "Train Epoch: 458 [500000/697932 (72%)]\tLoss: 139.836641\n",
      "Train Epoch: 458 [600000/697932 (86%)]\tLoss: 138.697094\n",
      "====> Epoch: 458 Average loss: 137.7557\n",
      "====> Test set loss: 139.1711\n",
      "Train Epoch: 459 [0/697932 (0%)]\tLoss: 136.534719\n",
      "Train Epoch: 459 [100000/697932 (14%)]\tLoss: 138.131469\n",
      "Train Epoch: 459 [200000/697932 (29%)]\tLoss: 139.438500\n",
      "Train Epoch: 459 [300000/697932 (43%)]\tLoss: 138.293703\n",
      "Train Epoch: 459 [400000/697932 (57%)]\tLoss: 137.747406\n",
      "Train Epoch: 459 [500000/697932 (72%)]\tLoss: 138.839391\n",
      "Train Epoch: 459 [600000/697932 (86%)]\tLoss: 137.479359\n",
      "====> Epoch: 459 Average loss: 137.7386\n",
      "====> Test set loss: 139.0581\n",
      "Train Epoch: 460 [0/697932 (0%)]\tLoss: 137.502094\n",
      "Train Epoch: 460 [100000/697932 (14%)]\tLoss: 138.200703\n",
      "Train Epoch: 460 [200000/697932 (29%)]\tLoss: 137.636641\n",
      "Train Epoch: 460 [300000/697932 (43%)]\tLoss: 139.800969\n",
      "Train Epoch: 460 [400000/697932 (57%)]\tLoss: 137.505547\n",
      "Train Epoch: 460 [500000/697932 (72%)]\tLoss: 138.155344\n",
      "Train Epoch: 460 [600000/697932 (86%)]\tLoss: 136.063094\n",
      "====> Epoch: 460 Average loss: 137.7647\n",
      "====> Test set loss: 139.0907\n",
      "Train Epoch: 461 [0/697932 (0%)]\tLoss: 135.990969\n",
      "Train Epoch: 461 [100000/697932 (14%)]\tLoss: 139.234609\n",
      "Train Epoch: 461 [200000/697932 (29%)]\tLoss: 137.299937\n",
      "Train Epoch: 461 [300000/697932 (43%)]\tLoss: 138.897484\n",
      "Train Epoch: 461 [400000/697932 (57%)]\tLoss: 138.680234\n",
      "Train Epoch: 461 [500000/697932 (72%)]\tLoss: 136.939156\n",
      "Train Epoch: 461 [600000/697932 (86%)]\tLoss: 139.081297\n",
      "====> Epoch: 461 Average loss: 137.7563\n",
      "====> Test set loss: 139.1426\n",
      "Train Epoch: 462 [0/697932 (0%)]\tLoss: 137.114469\n",
      "Train Epoch: 462 [100000/697932 (14%)]\tLoss: 137.751281\n",
      "Train Epoch: 462 [200000/697932 (29%)]\tLoss: 138.884266\n",
      "Train Epoch: 462 [300000/697932 (43%)]\tLoss: 136.774266\n",
      "Train Epoch: 462 [400000/697932 (57%)]\tLoss: 136.237203\n",
      "Train Epoch: 462 [500000/697932 (72%)]\tLoss: 137.987594\n",
      "Train Epoch: 462 [600000/697932 (86%)]\tLoss: 139.895438\n",
      "====> Epoch: 462 Average loss: 137.7467\n",
      "====> Test set loss: 139.1401\n",
      "Train Epoch: 463 [0/697932 (0%)]\tLoss: 136.603844\n",
      "Train Epoch: 463 [100000/697932 (14%)]\tLoss: 137.042844\n",
      "Train Epoch: 463 [200000/697932 (29%)]\tLoss: 137.244203\n",
      "Train Epoch: 463 [300000/697932 (43%)]\tLoss: 136.575578\n",
      "Train Epoch: 463 [400000/697932 (57%)]\tLoss: 138.833031\n",
      "Train Epoch: 463 [500000/697932 (72%)]\tLoss: 138.287906\n",
      "Train Epoch: 463 [600000/697932 (86%)]\tLoss: 137.932078\n",
      "====> Epoch: 463 Average loss: 137.7632\n",
      "====> Test set loss: 139.0588\n",
      "Train Epoch: 464 [0/697932 (0%)]\tLoss: 137.286812\n",
      "Train Epoch: 464 [100000/697932 (14%)]\tLoss: 138.598891\n",
      "Train Epoch: 464 [200000/697932 (29%)]\tLoss: 139.964406\n",
      "Train Epoch: 464 [300000/697932 (43%)]\tLoss: 136.922937\n",
      "Train Epoch: 464 [400000/697932 (57%)]\tLoss: 135.994828\n",
      "Train Epoch: 464 [500000/697932 (72%)]\tLoss: 137.661031\n",
      "Train Epoch: 464 [600000/697932 (86%)]\tLoss: 137.758906\n",
      "====> Epoch: 464 Average loss: 137.7441\n",
      "====> Test set loss: 139.0305\n",
      "Train Epoch: 465 [0/697932 (0%)]\tLoss: 138.038484\n",
      "Train Epoch: 465 [100000/697932 (14%)]\tLoss: 139.821750\n",
      "Train Epoch: 465 [200000/697932 (29%)]\tLoss: 139.537141\n",
      "Train Epoch: 465 [300000/697932 (43%)]\tLoss: 137.665047\n",
      "Train Epoch: 465 [400000/697932 (57%)]\tLoss: 137.760984\n",
      "Train Epoch: 465 [500000/697932 (72%)]\tLoss: 137.536156\n",
      "Train Epoch: 465 [600000/697932 (86%)]\tLoss: 138.074469\n",
      "====> Epoch: 465 Average loss: 137.7376\n",
      "====> Test set loss: 139.1094\n",
      "Train Epoch: 466 [0/697932 (0%)]\tLoss: 137.147188\n",
      "Train Epoch: 466 [100000/697932 (14%)]\tLoss: 137.516422\n",
      "Train Epoch: 466 [200000/697932 (29%)]\tLoss: 137.927047\n",
      "Train Epoch: 466 [300000/697932 (43%)]\tLoss: 137.726234\n",
      "Train Epoch: 466 [400000/697932 (57%)]\tLoss: 138.248766\n",
      "Train Epoch: 466 [500000/697932 (72%)]\tLoss: 135.880906\n",
      "Train Epoch: 466 [600000/697932 (86%)]\tLoss: 139.479453\n",
      "====> Epoch: 466 Average loss: 137.7486\n",
      "====> Test set loss: 139.1061\n",
      "Train Epoch: 467 [0/697932 (0%)]\tLoss: 137.177437\n",
      "Train Epoch: 467 [100000/697932 (14%)]\tLoss: 137.936719\n",
      "Train Epoch: 467 [200000/697932 (29%)]\tLoss: 137.505656\n",
      "Train Epoch: 467 [300000/697932 (43%)]\tLoss: 138.750906\n",
      "Train Epoch: 467 [400000/697932 (57%)]\tLoss: 137.629578\n",
      "Train Epoch: 467 [500000/697932 (72%)]\tLoss: 137.495625\n",
      "Train Epoch: 467 [600000/697932 (86%)]\tLoss: 137.189297\n",
      "====> Epoch: 467 Average loss: 137.7491\n",
      "====> Test set loss: 139.0785\n",
      "Train Epoch: 468 [0/697932 (0%)]\tLoss: 138.258344\n",
      "Train Epoch: 468 [100000/697932 (14%)]\tLoss: 139.019672\n",
      "Train Epoch: 468 [200000/697932 (29%)]\tLoss: 137.314141\n",
      "Train Epoch: 468 [300000/697932 (43%)]\tLoss: 137.618141\n",
      "Train Epoch: 468 [400000/697932 (57%)]\tLoss: 137.945359\n",
      "Train Epoch: 468 [500000/697932 (72%)]\tLoss: 136.976875\n",
      "Train Epoch: 468 [600000/697932 (86%)]\tLoss: 135.731266\n",
      "====> Epoch: 468 Average loss: 137.7335\n",
      "====> Test set loss: 139.0942\n",
      "Train Epoch: 469 [0/697932 (0%)]\tLoss: 136.450359\n",
      "Train Epoch: 469 [100000/697932 (14%)]\tLoss: 137.376078\n",
      "Train Epoch: 469 [200000/697932 (29%)]\tLoss: 136.181437\n",
      "Train Epoch: 469 [300000/697932 (43%)]\tLoss: 137.479594\n",
      "Train Epoch: 469 [400000/697932 (57%)]\tLoss: 136.131531\n",
      "Train Epoch: 469 [500000/697932 (72%)]\tLoss: 136.264672\n",
      "Train Epoch: 469 [600000/697932 (86%)]\tLoss: 138.159609\n",
      "====> Epoch: 469 Average loss: 137.7444\n",
      "====> Test set loss: 139.1521\n",
      "Train Epoch: 470 [0/697932 (0%)]\tLoss: 140.045000\n",
      "Train Epoch: 470 [100000/697932 (14%)]\tLoss: 137.201109\n",
      "Train Epoch: 470 [200000/697932 (29%)]\tLoss: 137.090406\n",
      "Train Epoch: 470 [300000/697932 (43%)]\tLoss: 137.081625\n",
      "Train Epoch: 470 [400000/697932 (57%)]\tLoss: 137.112406\n",
      "Train Epoch: 470 [500000/697932 (72%)]\tLoss: 136.607781\n",
      "Train Epoch: 470 [600000/697932 (86%)]\tLoss: 136.530984\n",
      "====> Epoch: 470 Average loss: 137.7360\n",
      "====> Test set loss: 139.1595\n",
      "Train Epoch: 471 [0/697932 (0%)]\tLoss: 138.782594\n",
      "Train Epoch: 471 [100000/697932 (14%)]\tLoss: 137.013953\n",
      "Train Epoch: 471 [200000/697932 (29%)]\tLoss: 138.077453\n",
      "Train Epoch: 471 [300000/697932 (43%)]\tLoss: 136.487859\n",
      "Train Epoch: 471 [400000/697932 (57%)]\tLoss: 136.633781\n",
      "Train Epoch: 471 [500000/697932 (72%)]\tLoss: 139.446656\n",
      "Train Epoch: 471 [600000/697932 (86%)]\tLoss: 136.311156\n",
      "====> Epoch: 471 Average loss: 137.7415\n",
      "====> Test set loss: 139.1602\n",
      "Train Epoch: 472 [0/697932 (0%)]\tLoss: 139.386719\n",
      "Train Epoch: 472 [100000/697932 (14%)]\tLoss: 138.123969\n",
      "Train Epoch: 472 [200000/697932 (29%)]\tLoss: 140.148063\n",
      "Train Epoch: 472 [300000/697932 (43%)]\tLoss: 138.100531\n",
      "Train Epoch: 472 [400000/697932 (57%)]\tLoss: 136.408000\n",
      "Train Epoch: 472 [500000/697932 (72%)]\tLoss: 137.516938\n",
      "Train Epoch: 472 [600000/697932 (86%)]\tLoss: 138.180406\n",
      "====> Epoch: 472 Average loss: 137.7343\n",
      "====> Test set loss: 139.0793\n",
      "Train Epoch: 473 [0/697932 (0%)]\tLoss: 138.422219\n",
      "Train Epoch: 473 [100000/697932 (14%)]\tLoss: 137.348672\n",
      "Train Epoch: 473 [200000/697932 (29%)]\tLoss: 138.897156\n",
      "Train Epoch: 473 [300000/697932 (43%)]\tLoss: 134.510266\n",
      "Train Epoch: 473 [400000/697932 (57%)]\tLoss: 139.166281\n",
      "Train Epoch: 473 [500000/697932 (72%)]\tLoss: 137.084344\n",
      "Train Epoch: 473 [600000/697932 (86%)]\tLoss: 138.835781\n",
      "====> Epoch: 473 Average loss: 137.7432\n",
      "====> Test set loss: 139.0561\n",
      "Train Epoch: 474 [0/697932 (0%)]\tLoss: 136.780094\n",
      "Train Epoch: 474 [100000/697932 (14%)]\tLoss: 136.425125\n",
      "Train Epoch: 474 [200000/697932 (29%)]\tLoss: 139.527969\n",
      "Train Epoch: 474 [300000/697932 (43%)]\tLoss: 136.841187\n",
      "Train Epoch: 474 [400000/697932 (57%)]\tLoss: 137.927531\n",
      "Train Epoch: 474 [500000/697932 (72%)]\tLoss: 137.758813\n",
      "Train Epoch: 474 [600000/697932 (86%)]\tLoss: 137.950453\n",
      "====> Epoch: 474 Average loss: 137.7243\n",
      "====> Test set loss: 139.0896\n",
      "Train Epoch: 475 [0/697932 (0%)]\tLoss: 137.793781\n",
      "Train Epoch: 475 [100000/697932 (14%)]\tLoss: 136.420875\n",
      "Train Epoch: 475 [200000/697932 (29%)]\tLoss: 137.450859\n",
      "Train Epoch: 475 [300000/697932 (43%)]\tLoss: 136.079094\n",
      "Train Epoch: 475 [400000/697932 (57%)]\tLoss: 137.338094\n",
      "Train Epoch: 475 [500000/697932 (72%)]\tLoss: 139.180625\n",
      "Train Epoch: 475 [600000/697932 (86%)]\tLoss: 139.255250\n",
      "====> Epoch: 475 Average loss: 137.7257\n",
      "====> Test set loss: 139.1185\n",
      "Train Epoch: 476 [0/697932 (0%)]\tLoss: 138.034250\n",
      "Train Epoch: 476 [100000/697932 (14%)]\tLoss: 137.760203\n",
      "Train Epoch: 476 [200000/697932 (29%)]\tLoss: 137.250875\n",
      "Train Epoch: 476 [300000/697932 (43%)]\tLoss: 139.483906\n",
      "Train Epoch: 476 [400000/697932 (57%)]\tLoss: 138.168078\n",
      "Train Epoch: 476 [500000/697932 (72%)]\tLoss: 137.935234\n",
      "Train Epoch: 476 [600000/697932 (86%)]\tLoss: 137.549953\n",
      "====> Epoch: 476 Average loss: 137.7362\n",
      "====> Test set loss: 139.1474\n",
      "Train Epoch: 477 [0/697932 (0%)]\tLoss: 136.499188\n",
      "Train Epoch: 477 [100000/697932 (14%)]\tLoss: 136.795266\n",
      "Train Epoch: 477 [200000/697932 (29%)]\tLoss: 138.254016\n",
      "Train Epoch: 477 [300000/697932 (43%)]\tLoss: 137.155906\n",
      "Train Epoch: 477 [400000/697932 (57%)]\tLoss: 136.294312\n",
      "Train Epoch: 477 [500000/697932 (72%)]\tLoss: 136.681828\n",
      "Train Epoch: 477 [600000/697932 (86%)]\tLoss: 137.359594\n",
      "====> Epoch: 477 Average loss: 137.7331\n",
      "====> Test set loss: 139.1038\n",
      "Train Epoch: 478 [0/697932 (0%)]\tLoss: 137.464000\n",
      "Train Epoch: 478 [100000/697932 (14%)]\tLoss: 136.094281\n",
      "Train Epoch: 478 [200000/697932 (29%)]\tLoss: 137.526516\n",
      "Train Epoch: 478 [300000/697932 (43%)]\tLoss: 136.257406\n",
      "Train Epoch: 478 [400000/697932 (57%)]\tLoss: 138.386562\n",
      "Train Epoch: 478 [500000/697932 (72%)]\tLoss: 136.269219\n",
      "Train Epoch: 478 [600000/697932 (86%)]\tLoss: 138.493562\n",
      "====> Epoch: 478 Average loss: 137.7229\n",
      "====> Test set loss: 139.2049\n",
      "Train Epoch: 479 [0/697932 (0%)]\tLoss: 137.255953\n",
      "Train Epoch: 479 [100000/697932 (14%)]\tLoss: 138.450578\n",
      "Train Epoch: 479 [200000/697932 (29%)]\tLoss: 139.082328\n",
      "Train Epoch: 479 [300000/697932 (43%)]\tLoss: 137.746000\n",
      "Train Epoch: 479 [400000/697932 (57%)]\tLoss: 137.601406\n",
      "Train Epoch: 479 [500000/697932 (72%)]\tLoss: 136.554156\n",
      "Train Epoch: 479 [600000/697932 (86%)]\tLoss: 136.395047\n",
      "====> Epoch: 479 Average loss: 137.7369\n",
      "====> Test set loss: 139.0851\n",
      "Train Epoch: 480 [0/697932 (0%)]\tLoss: 137.410422\n",
      "Train Epoch: 480 [100000/697932 (14%)]\tLoss: 137.499094\n",
      "Train Epoch: 480 [200000/697932 (29%)]\tLoss: 136.088531\n",
      "Train Epoch: 480 [300000/697932 (43%)]\tLoss: 137.338500\n",
      "Train Epoch: 480 [400000/697932 (57%)]\tLoss: 136.534828\n",
      "Train Epoch: 480 [500000/697932 (72%)]\tLoss: 138.870969\n",
      "Train Epoch: 480 [600000/697932 (86%)]\tLoss: 136.971375\n",
      "====> Epoch: 480 Average loss: 137.7091\n",
      "====> Test set loss: 139.0132\n",
      "Train Epoch: 481 [0/697932 (0%)]\tLoss: 135.975391\n",
      "Train Epoch: 481 [100000/697932 (14%)]\tLoss: 137.203891\n",
      "Train Epoch: 481 [200000/697932 (29%)]\tLoss: 136.581234\n",
      "Train Epoch: 481 [300000/697932 (43%)]\tLoss: 136.637078\n",
      "Train Epoch: 481 [400000/697932 (57%)]\tLoss: 139.474813\n",
      "Train Epoch: 481 [500000/697932 (72%)]\tLoss: 135.796109\n",
      "Train Epoch: 481 [600000/697932 (86%)]\tLoss: 136.573969\n",
      "====> Epoch: 481 Average loss: 137.7233\n",
      "====> Test set loss: 139.0853\n",
      "Train Epoch: 482 [0/697932 (0%)]\tLoss: 137.761797\n",
      "Train Epoch: 482 [100000/697932 (14%)]\tLoss: 136.341641\n",
      "Train Epoch: 482 [200000/697932 (29%)]\tLoss: 138.285094\n",
      "Train Epoch: 482 [300000/697932 (43%)]\tLoss: 138.287719\n",
      "Train Epoch: 482 [400000/697932 (57%)]\tLoss: 137.315406\n",
      "Train Epoch: 482 [500000/697932 (72%)]\tLoss: 136.522547\n",
      "Train Epoch: 482 [600000/697932 (86%)]\tLoss: 138.300172\n",
      "====> Epoch: 482 Average loss: 137.7337\n",
      "====> Test set loss: 139.0920\n",
      "Train Epoch: 483 [0/697932 (0%)]\tLoss: 136.718609\n",
      "Train Epoch: 483 [100000/697932 (14%)]\tLoss: 139.064828\n",
      "Train Epoch: 483 [200000/697932 (29%)]\tLoss: 139.158500\n",
      "Train Epoch: 483 [300000/697932 (43%)]\tLoss: 135.852406\n",
      "Train Epoch: 483 [400000/697932 (57%)]\tLoss: 136.914875\n",
      "Train Epoch: 483 [500000/697932 (72%)]\tLoss: 136.609141\n",
      "Train Epoch: 483 [600000/697932 (86%)]\tLoss: 138.080984\n",
      "====> Epoch: 483 Average loss: 137.7179\n",
      "====> Test set loss: 139.1733\n",
      "Train Epoch: 484 [0/697932 (0%)]\tLoss: 138.224484\n",
      "Train Epoch: 484 [100000/697932 (14%)]\tLoss: 139.839828\n",
      "Train Epoch: 484 [200000/697932 (29%)]\tLoss: 137.589031\n",
      "Train Epoch: 484 [300000/697932 (43%)]\tLoss: 136.712922\n",
      "Train Epoch: 484 [400000/697932 (57%)]\tLoss: 138.584016\n",
      "Train Epoch: 484 [500000/697932 (72%)]\tLoss: 136.291313\n",
      "Train Epoch: 484 [600000/697932 (86%)]\tLoss: 138.911687\n",
      "====> Epoch: 484 Average loss: 137.7156\n",
      "====> Test set loss: 139.0702\n",
      "Train Epoch: 485 [0/697932 (0%)]\tLoss: 137.279734\n",
      "Train Epoch: 485 [100000/697932 (14%)]\tLoss: 138.022250\n",
      "Train Epoch: 485 [200000/697932 (29%)]\tLoss: 136.380781\n",
      "Train Epoch: 485 [300000/697932 (43%)]\tLoss: 137.003125\n",
      "Train Epoch: 485 [400000/697932 (57%)]\tLoss: 138.026219\n",
      "Train Epoch: 485 [500000/697932 (72%)]\tLoss: 136.070734\n",
      "Train Epoch: 485 [600000/697932 (86%)]\tLoss: 138.847062\n",
      "====> Epoch: 485 Average loss: 137.7277\n",
      "====> Test set loss: 139.2309\n",
      "Train Epoch: 486 [0/697932 (0%)]\tLoss: 136.678656\n",
      "Train Epoch: 486 [100000/697932 (14%)]\tLoss: 138.067484\n",
      "Train Epoch: 486 [200000/697932 (29%)]\tLoss: 136.922125\n",
      "Train Epoch: 486 [300000/697932 (43%)]\tLoss: 136.740438\n",
      "Train Epoch: 486 [400000/697932 (57%)]\tLoss: 138.535672\n",
      "Train Epoch: 486 [500000/697932 (72%)]\tLoss: 140.250906\n",
      "Train Epoch: 486 [600000/697932 (86%)]\tLoss: 138.630734\n",
      "====> Epoch: 486 Average loss: 137.7058\n",
      "====> Test set loss: 139.0826\n",
      "Train Epoch: 487 [0/697932 (0%)]\tLoss: 138.197609\n",
      "Train Epoch: 487 [100000/697932 (14%)]\tLoss: 138.912594\n",
      "Train Epoch: 487 [200000/697932 (29%)]\tLoss: 137.246172\n",
      "Train Epoch: 487 [300000/697932 (43%)]\tLoss: 137.007187\n",
      "Train Epoch: 487 [400000/697932 (57%)]\tLoss: 139.184344\n",
      "Train Epoch: 487 [500000/697932 (72%)]\tLoss: 137.173000\n",
      "Train Epoch: 487 [600000/697932 (86%)]\tLoss: 137.734406\n",
      "====> Epoch: 487 Average loss: 137.7054\n",
      "====> Test set loss: 139.1987\n",
      "Train Epoch: 488 [0/697932 (0%)]\tLoss: 135.580500\n",
      "Train Epoch: 488 [100000/697932 (14%)]\tLoss: 138.815141\n",
      "Train Epoch: 488 [200000/697932 (29%)]\tLoss: 137.742953\n",
      "Train Epoch: 488 [300000/697932 (43%)]\tLoss: 139.091922\n",
      "Train Epoch: 488 [400000/697932 (57%)]\tLoss: 139.029875\n",
      "Train Epoch: 488 [500000/697932 (72%)]\tLoss: 138.257563\n",
      "Train Epoch: 488 [600000/697932 (86%)]\tLoss: 138.049422\n",
      "====> Epoch: 488 Average loss: 137.7016\n",
      "====> Test set loss: 139.2695\n",
      "Train Epoch: 489 [0/697932 (0%)]\tLoss: 138.729312\n",
      "Train Epoch: 489 [100000/697932 (14%)]\tLoss: 138.021047\n",
      "Train Epoch: 489 [200000/697932 (29%)]\tLoss: 136.999469\n",
      "Train Epoch: 489 [300000/697932 (43%)]\tLoss: 139.170500\n",
      "Train Epoch: 489 [400000/697932 (57%)]\tLoss: 137.397734\n",
      "Train Epoch: 489 [500000/697932 (72%)]\tLoss: 136.811891\n",
      "Train Epoch: 489 [600000/697932 (86%)]\tLoss: 137.161672\n",
      "====> Epoch: 489 Average loss: 137.7176\n",
      "====> Test set loss: 139.0177\n",
      "Train Epoch: 490 [0/697932 (0%)]\tLoss: 136.711312\n",
      "Train Epoch: 490 [100000/697932 (14%)]\tLoss: 137.180969\n",
      "Train Epoch: 490 [200000/697932 (29%)]\tLoss: 136.406375\n",
      "Train Epoch: 490 [300000/697932 (43%)]\tLoss: 137.080125\n",
      "Train Epoch: 490 [400000/697932 (57%)]\tLoss: 136.043641\n",
      "Train Epoch: 490 [500000/697932 (72%)]\tLoss: 138.076313\n",
      "Train Epoch: 490 [600000/697932 (86%)]\tLoss: 135.778391\n",
      "====> Epoch: 490 Average loss: 137.6995\n",
      "====> Test set loss: 139.0747\n",
      "Train Epoch: 491 [0/697932 (0%)]\tLoss: 137.133672\n",
      "Train Epoch: 491 [100000/697932 (14%)]\tLoss: 137.654531\n",
      "Train Epoch: 491 [200000/697932 (29%)]\tLoss: 137.704375\n",
      "Train Epoch: 491 [300000/697932 (43%)]\tLoss: 140.468531\n",
      "Train Epoch: 491 [400000/697932 (57%)]\tLoss: 137.644438\n",
      "Train Epoch: 491 [500000/697932 (72%)]\tLoss: 135.755750\n",
      "Train Epoch: 491 [600000/697932 (86%)]\tLoss: 136.824797\n",
      "====> Epoch: 491 Average loss: 137.7079\n",
      "====> Test set loss: 138.9965\n",
      "Train Epoch: 492 [0/697932 (0%)]\tLoss: 135.558250\n",
      "Train Epoch: 492 [100000/697932 (14%)]\tLoss: 139.411500\n",
      "Train Epoch: 492 [200000/697932 (29%)]\tLoss: 136.645391\n",
      "Train Epoch: 492 [300000/697932 (43%)]\tLoss: 137.512891\n",
      "Train Epoch: 492 [400000/697932 (57%)]\tLoss: 137.970406\n",
      "Train Epoch: 492 [500000/697932 (72%)]\tLoss: 136.058344\n",
      "Train Epoch: 492 [600000/697932 (86%)]\tLoss: 136.084109\n",
      "====> Epoch: 492 Average loss: 137.7117\n",
      "====> Test set loss: 139.0022\n",
      "Train Epoch: 493 [0/697932 (0%)]\tLoss: 137.990344\n",
      "Train Epoch: 493 [100000/697932 (14%)]\tLoss: 139.571422\n",
      "Train Epoch: 493 [200000/697932 (29%)]\tLoss: 137.636609\n",
      "Train Epoch: 493 [300000/697932 (43%)]\tLoss: 139.210312\n",
      "Train Epoch: 493 [400000/697932 (57%)]\tLoss: 138.741391\n",
      "Train Epoch: 493 [500000/697932 (72%)]\tLoss: 139.920688\n",
      "Train Epoch: 493 [600000/697932 (86%)]\tLoss: 140.233203\n",
      "====> Epoch: 493 Average loss: 137.7021\n",
      "====> Test set loss: 139.1901\n",
      "Train Epoch: 494 [0/697932 (0%)]\tLoss: 138.578422\n",
      "Train Epoch: 494 [100000/697932 (14%)]\tLoss: 138.524563\n",
      "Train Epoch: 494 [200000/697932 (29%)]\tLoss: 137.455062\n",
      "Train Epoch: 494 [300000/697932 (43%)]\tLoss: 138.267906\n",
      "Train Epoch: 494 [400000/697932 (57%)]\tLoss: 135.342141\n",
      "Train Epoch: 494 [500000/697932 (72%)]\tLoss: 138.584000\n",
      "Train Epoch: 494 [600000/697932 (86%)]\tLoss: 139.445141\n",
      "====> Epoch: 494 Average loss: 137.6998\n",
      "====> Test set loss: 139.1161\n",
      "Train Epoch: 495 [0/697932 (0%)]\tLoss: 136.557734\n",
      "Train Epoch: 495 [100000/697932 (14%)]\tLoss: 138.756859\n",
      "Train Epoch: 495 [200000/697932 (29%)]\tLoss: 137.002703\n",
      "Train Epoch: 495 [300000/697932 (43%)]\tLoss: 136.195844\n",
      "Train Epoch: 495 [400000/697932 (57%)]\tLoss: 137.538219\n",
      "Train Epoch: 495 [500000/697932 (72%)]\tLoss: 137.834828\n",
      "Train Epoch: 495 [600000/697932 (86%)]\tLoss: 137.210594\n",
      "====> Epoch: 495 Average loss: 137.6968\n",
      "====> Test set loss: 139.1199\n",
      "Train Epoch: 496 [0/697932 (0%)]\tLoss: 137.903781\n",
      "Train Epoch: 496 [100000/697932 (14%)]\tLoss: 139.561516\n",
      "Train Epoch: 496 [200000/697932 (29%)]\tLoss: 137.756766\n",
      "Train Epoch: 496 [300000/697932 (43%)]\tLoss: 137.258766\n",
      "Train Epoch: 496 [400000/697932 (57%)]\tLoss: 137.392344\n",
      "Train Epoch: 496 [500000/697932 (72%)]\tLoss: 137.723125\n",
      "Train Epoch: 496 [600000/697932 (86%)]\tLoss: 137.588656\n",
      "====> Epoch: 496 Average loss: 137.7026\n",
      "====> Test set loss: 139.0286\n",
      "Train Epoch: 497 [0/697932 (0%)]\tLoss: 139.175062\n",
      "Train Epoch: 497 [100000/697932 (14%)]\tLoss: 137.172781\n",
      "Train Epoch: 497 [200000/697932 (29%)]\tLoss: 138.326797\n",
      "Train Epoch: 497 [300000/697932 (43%)]\tLoss: 137.667234\n",
      "Train Epoch: 497 [400000/697932 (57%)]\tLoss: 138.736406\n",
      "Train Epoch: 497 [500000/697932 (72%)]\tLoss: 137.356125\n",
      "Train Epoch: 497 [600000/697932 (86%)]\tLoss: 138.572844\n",
      "====> Epoch: 497 Average loss: 137.6985\n",
      "====> Test set loss: 139.1377\n",
      "Train Epoch: 498 [0/697932 (0%)]\tLoss: 137.888750\n",
      "Train Epoch: 498 [100000/697932 (14%)]\tLoss: 138.288391\n",
      "Train Epoch: 498 [200000/697932 (29%)]\tLoss: 138.496625\n",
      "Train Epoch: 498 [300000/697932 (43%)]\tLoss: 135.400391\n",
      "Train Epoch: 498 [400000/697932 (57%)]\tLoss: 136.923109\n",
      "Train Epoch: 498 [500000/697932 (72%)]\tLoss: 140.406250\n",
      "Train Epoch: 498 [600000/697932 (86%)]\tLoss: 136.752672\n",
      "====> Epoch: 498 Average loss: 137.7030\n",
      "====> Test set loss: 139.0786\n",
      "Train Epoch: 499 [0/697932 (0%)]\tLoss: 137.633500\n",
      "Train Epoch: 499 [100000/697932 (14%)]\tLoss: 137.716266\n",
      "Train Epoch: 499 [200000/697932 (29%)]\tLoss: 137.572563\n",
      "Train Epoch: 499 [300000/697932 (43%)]\tLoss: 138.207938\n",
      "Train Epoch: 499 [400000/697932 (57%)]\tLoss: 137.397406\n",
      "Train Epoch: 499 [500000/697932 (72%)]\tLoss: 137.051500\n",
      "Train Epoch: 499 [600000/697932 (86%)]\tLoss: 137.414813\n",
      "====> Epoch: 499 Average loss: 137.6923\n",
      "====> Test set loss: 139.1037\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(0, num_epochs):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae,'./trained_models/latest_model_500_epochs_ltsp_10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capital A label is 10\n",
    "#lower case a label is 36\n",
    "def all_test_images_indexes_for_label(target_label):\n",
    "    indexes = []\n",
    "    for index in range(len(test_dataset)): \n",
    "        image, label = test_dataset[index]\n",
    "        if label == target_label:\n",
    "            indexes.append(index)\n",
    "    return indexes\n",
    "\n",
    "def master_image_label_map():\n",
    "    master_label = []\n",
    "    for index in range(len(test_dataset)): \n",
    "        image, label = test_dataset[index]\n",
    "        master_label.append(label)\n",
    "    return master_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 32, 4, 8, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "Label_Map = master_image_label_map()\n",
    "print(Label_Map[79:85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "labels_to_indexes = {}\n",
    "for label in range(62):\n",
    "    labels_to_indexes[label] = [index for index in range(len(Label_Map)) if Label_Map[index]==label]\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_latent_space_vector(Indexes):\n",
    "    total_sample = torch.zeros(Z_dim).cuda()\n",
    "    for index in Indexes:\n",
    "        test_image_A, test_target_A = test_dataset[index]\n",
    "\n",
    "        #Shape input into what the network wants\n",
    "        z = torch.flatten(test_image_A)\n",
    "        z = torch.tensor(z)\n",
    "        z = z.cuda()\n",
    "\n",
    "        #Map through the model to the latent space \n",
    "        latent_sample =  vae.encoder(z)[0]\n",
    "        total_sample = torch.add(latent_sample, total_sample)\n",
    "    \n",
    "    return total_sample/len(Indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1025795/2705388341.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#Generate dict of the mean differences between lowercase and uppercase letters one at a time\n",
    "#uses indexes of the capital letters\n",
    "lower_to_upper_dict = {}\n",
    "Upper_means = {}\n",
    "Lower_means = {}\n",
    "\n",
    "for offset in range(26):\n",
    "    A_indexes = labels_to_indexes[10 + offset]\n",
    "    a_indexes = labels_to_indexes[36 + offset]\n",
    "\n",
    "    A_mean = mean_latent_space_vector(A_indexes)\n",
    "    a_mean = mean_latent_space_vector(a_indexes)\n",
    "\n",
    "    lower_to_upper = A_mean-a_mean\n",
    "    lower_to_upper_dict[10+offset] = lower_to_upper\n",
    "    Upper_means[10+offset] = A_mean\n",
    "    Lower_means[36+offset] = a_mean\n",
    "\n",
    "    print(offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_uppercase_dict ={\n",
    "10:'A',\n",
    "11:'B',\n",
    "12:'C',\n",
    "13:'D',\n",
    "14:'E',\n",
    "15:'F',\n",
    "16:'G',\n",
    "17:'H',\n",
    "18:'I',\n",
    "19:'J',\n",
    "20:'K',\n",
    "21:'L',\n",
    "22:'M',\n",
    "23:'N',\n",
    "24:'O',\n",
    "25:'P',\n",
    "26:'Q',\n",
    "27:'R',\n",
    "28:'S',\n",
    "29:'T',\n",
    "30:'U',\n",
    "31:'V',\n",
    "32:'W',\n",
    "33:'X',\n",
    "34:'Y',\n",
    "35:'Z',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tensor_for_image(comb_view):\n",
    "    comb_view = torch.flip(comb_view,dims=[2])\n",
    "    comb_view = torch.rot90(comb_view,3,[2,3])\n",
    "    return comb_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function to make only the Mega image of all fractional case letters and first and mean\n",
    "def generate_fractional_composite(fractional_value, file_name):\n",
    "    Combined_View = torch.empty(0, 1, 28, 28).cuda()\n",
    "    for offset in range(26):\n",
    "        letter_index = 10 +offset\n",
    "        lower_index = 36 + offset\n",
    "\n",
    "        #Map through the model to the latent space and the whole way through\n",
    "        latent_sample = Lower_means[lower_index] \n",
    "        adjusted_latent = torch.add(latent_sample , ((fractional_value)*lower_to_upper_dict[letter_index]) )\n",
    "        direct_sample = vae.decoder(adjusted_latent).cuda()\n",
    "\n",
    "        comb_view = direct_sample.view(1, 1, 28, 28)\n",
    "        comb_view = fix_tensor_for_image(comb_view)\n",
    "        Combined_View = torch.cat((Combined_View, comb_view))\n",
    "\n",
    "    save_image(Combined_View, './examples/average_letter/'+file_name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mega_image_fractional_composite(fractional_value, file_name):\n",
    "    Combined_View = torch.empty(0, 1, 28, 28).cuda()\n",
    "    for offset in range(26):\n",
    "        letter_index = 10 +offset\n",
    "        lower_index = 36 + offset\n",
    "        A_indexes = labels_to_indexes[letter_index]\n",
    "        test_image_A, test_target_A = test_dataset[A_indexes[0]]\n",
    "\n",
    "        #Shape input into what the network wants\n",
    "        z = torch.flatten(test_image_A)#.cuda(k\n",
    "        z = torch.tensor(z)\n",
    "        z = z.cuda()\n",
    "\n",
    "        #Map through the model to the latent space and the whole way through\n",
    "        latent_sample = Lower_means[lower_index] \n",
    "\n",
    "        sample = vae.decoder(latent_sample)\n",
    "        adjusted_latent = torch.add(latent_sample , ((fractional_value)*lower_to_upper_dict[letter_index]) )\n",
    "        direct_sample = vae.decoder(adjusted_latent).cuda()\n",
    "\n",
    "        comb_tensor = torch.cat( (z, sample, direct_sample) ).cuda()\n",
    "        comb_view = comb_tensor.view(3, 1, 28, 28)\n",
    "        comb_view = fix_tensor_for_image(comb_view)\n",
    "        Combined_View = torch.cat((Combined_View, comb_view))\n",
    "\n",
    "    save_image(Combined_View, './examples/average_letter/'+file_name+'_mega_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_fractional_composite(0,'ltsp_'+str(Z_dim)+'_lower_case')\n",
    "generate_fractional_composite(1/2,'ltsp_'+str(Z_dim)+'_middle')\n",
    "generate_fractional_composite(1/4,str(Z_dim)+'_one_quarter')\n",
    "generate_fractional_composite(3/4,str(Z_dim)+'_three_quarter')\n",
    "generate_fractional_composite(1,str(Z_dim)+'_back_to_upper_from_lower')\n",
    "generate_fractional_composite(-1,str(Z_dim)+'_double_lower')\n",
    "generate_fractional_composite(2,str(Z_dim)+'_double_upper_from_lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 2.6568403244018555\n",
      "B 2.591315984725952\n",
      "D 2.8383989334106445\n",
      "E 1.1549440622329712\n",
      "G 2.649489402770996\n",
      "H 2.5897908210754395\n",
      "J 2.386988639831543\n",
      "L 2.8355443477630615\n",
      "N 2.5097568035125732\n",
      "Q 2.2703826427459717\n",
      "R 2.1110692024230957\n",
      "T 2.690157413482666\n",
      "Z 1.1872742176055908\n",
      "[2.6568403244018555, 2.591315984725952, 0.4602917730808258, 2.8383989334106445, 1.1549440622329712, 0.8251123428344727, 2.649489402770996, 2.5897908210754395, 0.8578781485557556, 2.386988639831543, 0.8886412382125854, 2.8355443477630615, 0.47433751821517944, 2.5097568035125732, 0.20054057240486145, 0.9953814148902893, 2.2703826427459717, 2.1110692024230957, 0.33319997787475586, 2.690157413482666, 0.8592143654823303, 0.4645264446735382, 0.9805564284324646, 0.849379301071167, 0.8087454438209534, 1.1872742176055908]\n"
     ]
    }
   ],
   "source": [
    "#Which letters are actually different from upper to lower\n",
    "Norms = []\n",
    "Upper_Lower_distinct_indexes = []\n",
    "for offset in range(26):\n",
    "    letter_index = 10 +offset\n",
    "    captalization_vect = lower_to_upper_dict[letter_index]\n",
    "    vect_norm = torch.norm(captalization_vect).item()\n",
    "    letter = index_to_uppercase_dict[letter_index]\n",
    "    Norms.append(vect_norm)\n",
    "    if vect_norm>1:\n",
    "        print(letter, vect_norm)\n",
    "        Upper_Lower_distinct_indexes.append(10+offset)\n",
    "print(Norms)\n",
    "\n",
    "#J and L are distinct wiht this process but F is not, in the paper they remove J and L and keep F as its own class when compressin in the By_Merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(Norms, bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([norm for norm in Norms if norm >=1 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.2202, -1.8399,  3.1680, -7.8220, -4.9963, -0.1423,  3.8954,  1.7211,\n",
      "        -0.1531, -5.8766], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3246, -0.1415,  0.2437, -0.6017, -0.3843, -0.0109,  0.2996,  0.1324,\n",
      "        -0.0118, -0.4520], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Make average capitalization vector\n",
    "mean_distinct_lower_upper_vector =  torch.zeros(Z_dim).cuda()\n",
    "for index in Upper_Lower_distinct_indexes:\n",
    "    mean_distinct_lower_upper_vector = torch.add( mean_distinct_lower_upper_vector, lower_to_upper_dict[index])\n",
    "\n",
    "print(mean_distinct_lower_upper_vector)\n",
    "mean_distinct_lower_upper_vector = mean_distinct_lower_upper_vector/len(Upper_Lower_distinct_indexes)\n",
    "print(mean_distinct_lower_upper_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1025795/2705388341.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "{0: tensor([-0.2731, -0.2948,  0.2545,  0.1822,  0.4262,  0.1211,  0.6376, -0.4310,\n",
      "         0.7739, -1.2287], device='cuda:0', grad_fn=<DivBackward0>), 1: tensor([ 0.0702,  0.3009, -0.0086,  0.4134,  0.7067,  0.1108, -0.0973, -0.2598,\n",
      "        -0.2323,  1.6920], device='cuda:0', grad_fn=<DivBackward0>), 2: tensor([ 1.4723,  0.2661,  0.2805, -0.4044,  0.0824, -0.1659,  0.2368, -0.6325,\n",
      "        -1.3759, -0.1048], device='cuda:0', grad_fn=<DivBackward0>), 3: tensor([-0.4123,  0.0420,  1.4925,  0.4160, -0.0469, -0.1949,  0.3203,  0.0063,\n",
      "        -1.0741, -0.4032], device='cuda:0', grad_fn=<DivBackward0>), 4: tensor([ 0.0022, -0.2533, -1.6269,  0.5975, -0.5334,  0.1050,  0.4124, -0.3482,\n",
      "         0.5745,  0.2033], device='cuda:0', grad_fn=<DivBackward0>), 5: tensor([-0.4266,  0.8054,  1.4433, -0.5436, -0.2026, -0.2172, -0.3625, -0.1252,\n",
      "         0.9899,  0.1192], device='cuda:0', grad_fn=<DivBackward0>), 6: tensor([ 0.5091, -0.4740,  0.3864,  0.1569,  0.9969,  0.2266, -1.2859, -0.6439,\n",
      "         0.6175, -0.4186], device='cuda:0', grad_fn=<DivBackward0>), 7: tensor([ 0.5852,  0.3990,  0.1659,  0.8742, -1.0372, -0.0264,  1.1381,  0.0385,\n",
      "        -0.1687,  0.6738], device='cuda:0', grad_fn=<DivBackward0>), 8: tensor([ 0.0156, -0.7361,  0.7309, -0.4167, -0.6489,  0.2282,  0.2348,  0.2445,\n",
      "         0.0747,  0.2972], device='cuda:0', grad_fn=<DivBackward0>), 9: tensor([-0.0225, -0.3475,  0.1449,  0.8777, -0.9395,  0.0537,  0.4548,  0.2379,\n",
      "         1.1121,  0.4207], device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "#Generate dict of the mean number\n",
    "Number_means = {}\n",
    "\n",
    "for offset in range(10):\n",
    "    num_indexes = labels_to_indexes[offset]\n",
    "    num_mean = mean_latent_space_vector(num_indexes)\n",
    "    Number_means[offset] = num_mean\n",
    "\n",
    "    print(offset)\n",
    "print(Number_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_mega_image_fractional_composite_mean_vector(fractional_value, file_name, include_numbers):\n",
    "    Combined_View = torch.empty(0, 1, 28, 28).cuda()\n",
    "    num_characters = 26\n",
    "    if include_numbers:\n",
    "        num_characters = 36\n",
    "    for offset in range(num_characters):\n",
    "\n",
    "        letter_index = 10 +offset\n",
    "        lower_index  = 36 +offset \n",
    "        if include_numbers:\n",
    "            letter_index = offset\n",
    "            lower_index  = 26 + offset \n",
    "\n",
    "\n",
    "        A_indexes = labels_to_indexes[letter_index]\n",
    "        test_image_A, test_target_A = test_dataset[A_indexes[0]]\n",
    "\n",
    "        #Shape input into what the network wants\n",
    "        z = torch.flatten(test_image_A)#.cuda(k\n",
    "        z = torch.tensor(z)\n",
    "        z = z.cuda()\n",
    "\n",
    "        #Map through the model to the latent space and the whole way through\n",
    "        if letter_index< 10:\n",
    "            latent_sample = Number_means[letter_index]\n",
    "        else:\n",
    "            latent_sample = Lower_means[lower_index] \n",
    "\n",
    "        sample = vae.decoder(latent_sample)\n",
    "        adjusted_latent = torch.add( latent_sample , ( fractional_value * mean_distinct_lower_upper_vector) )\n",
    "        direct_sample = vae.decoder(adjusted_latent).cuda()\n",
    "\n",
    "        comb_tensor = torch.cat( (z, sample, direct_sample) ).cuda()\n",
    "        comb_view = comb_tensor.view(3, 1, 28, 28)\n",
    "\n",
    "        comb_view = fix_tensor_for_image(comb_view)\n",
    "        Combined_View = torch.cat((Combined_View, comb_view))\n",
    "\n",
    "    save_image(Combined_View, './examples/average_figure/ltsp_'+str(Z_dim)+'_'+file_name+'_mega_image_mean_vector.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1025795/712455548.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(z)\n"
     ]
    }
   ],
   "source": [
    "generate_mega_image_fractional_composite_mean_vector(0,'lower_case',True)\n",
    "generate_mega_image_fractional_composite_mean_vector( 0.5 ,'middle',True)\n",
    "generate_mega_image_fractional_composite_mean_vector(1,'back_to_upper_from_lower',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_numbers_as_letter_caps(file_name, to_lower):\n",
    "    Combined_View = torch.empty(0, 1, 28, 28).cuda()\n",
    "\n",
    "    num_characters = 10 \n",
    "\n",
    "    for offset in range(26):\n",
    "        #Add letter at start of sequence to aid in readability\n",
    "        A_indexes = labels_to_indexes[10+offset]\n",
    "        test_image_A, test_target_A = test_dataset[A_indexes[0]]\n",
    "        z = torch.flatten(test_image_A)#.cuda(k\n",
    "        z = torch.tensor(z)\n",
    "        z = z.cuda()\n",
    "\n",
    "        comb_view = z.view(1, 1, 28, 28)\n",
    "\n",
    "        comb_view = fix_tensor_for_image(comb_view)\n",
    "        Combined_View = torch.cat((Combined_View, comb_view))\n",
    "\n",
    "\n",
    "\n",
    "        for number in range(num_characters):\n",
    "\n",
    "            letter_index = 10 +offset\n",
    "            lower_index  = 36 +offset \n",
    "\n",
    "            Number_indexes = labels_to_indexes[number]\n",
    "            test_image_A, test_target_A = test_dataset[Number_indexes[0]]\n",
    "\n",
    "            #Shape input into what the network wants\n",
    "            z = torch.flatten(test_image_A)#.cuda(k\n",
    "            z = torch.tensor(z)\n",
    "            z = z.cuda()\n",
    "\n",
    "            #use the number latent space values\n",
    "            latent_sample = Number_means[number]\n",
    "\n",
    "            sample = vae.decoder(latent_sample)\n",
    "            #adjust with the vector that goes from lower case to upper for that specific letter\n",
    "            if to_lower:\n",
    "                adjusted_latent = torch.add( latent_sample , (-1)*(lower_to_upper_dict[10+offset]) )\n",
    "            else:\n",
    "                adjusted_latent = torch.add( latent_sample , (lower_to_upper_dict[10+offset]) )\n",
    "\n",
    "            direct_sample = vae.decoder(adjusted_latent).cuda()\n",
    "\n",
    "            comb_tensor = torch.cat( (z, sample, direct_sample) ).cuda()\n",
    "            comb_view = comb_tensor.view(3, 1, 28, 28)\n",
    "\n",
    "            comb_view = fix_tensor_for_image(comb_view)\n",
    "            Combined_View = torch.cat((Combined_View, comb_view))\n",
    "\n",
    "    save_image(Combined_View, './examples/upper_case_numbers/ltsp_'+str(Z_dim)+'_'+file_name+'_.png', nrow = 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1025795/3189239840.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(z)\n",
      "/tmp/ipykernel_1025795/3189239840.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(z)\n"
     ]
    }
   ],
   "source": [
    "generate_numbers_as_letter_caps('letter_by_letter_to_upper', False)\n",
    "generate_numbers_as_letter_caps('letter_by_letter_to_lower', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
